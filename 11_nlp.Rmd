# Természetes-nyelv feldolgozás (NLP) és névelemfelismerés

A természetes-nyelv feldolgozása (Natural Language Processing, NLP) a nyelvészet és a mesterséges intelligencia közös területe, amely a számítógépes módszerek segítségével elemzi az emberek által használt (természetes) nyelveket. Azaz képes feldolgozni különböző szöveges dokumentumok tartalmát, kinyerni a bennük található információkat, kategorizálni és rendszerezni azokat. Angol nyelvű szövegek NLP elemzésére több R csomag is rendelkezésünre áll, ezek közül kettőt mutatunk be röviden. Mivel magyar nyelvű szövegek NLP elemzésre ezek a csomagok jelenleg nem alkalmasak bemutatjuk, hogyan végezhetjük el a magyar nyelvű szövegek mondatra és szavakra bontását, szófaji egyértelműsítését, morfológiai és szintaktikai elemzését az R program használata nélkül és azután a kapott fájlokkal hogyan végezhetünk az R program segítségével további elemzéseket.

A fejezeben részletesen foglalkozunk a névelem-felismeréssel (NER). Névelemnek azokat a tokensorozatokat nevezzük, amelyek valamely entitást egyedi módon jelölnek. A névelem-felismerés az infomációkinyerés részterülete, melynek lényege, hogy automatikusan felismerjük a struktúlálatlan szövegben szereplő tulajdonneveket, majd azokat kigyűjtsük, és típusonként (pl. személynév, földrajzi név, márkanév, stb.) csoportosítsuk. Bár a tulajdonnevek mellett névelemnek tekinthető még például a telefonszámok vagy az email címek is, a névelem-felismerés leginkább mégis a tulajdonnevek felismerésére irányul. A névelem-felismerés a számítógépes nyelvészetben a korai 1990-es évektől kezdve fontos feladatnak és megoldandó problémának számít.A névelem-felismerés többféle módon is megoldható, így péládul felügyelt tanulással, szótár alapú módszerekkel vagy kollokációk elemzésével. A névelem-felismerés körében két alapvető módszer alkalmazására van lehetőség. A szabályalapú módszer alkalmazása során előre megadott adatok alapján kerül kinyerésre az információ (ilyen szabály például a mondatközi nagybetű mint a tulajdonnév kezdete). A másik módszer a statisztikai tanulás, amikor a gép alkot szabályokat a kutató előzetes mintakódolása alapján. A névelemfelismerés során nehézséget okozhat a különböző névelemosztályok közötti gyakori átfedés, így például ha egy adott szó településnév és vezetéknév is lehet. A magyar nyelvű szövegekben a tulajdonnevek automatikus annotációjára jelenleg három módon van lehetőség: tulajdonnév-felismerő algoritmussal, szófaji címke szintjén történő megkülönböztetéssel, valamint szintaktikai szintű címkézéssel. Utóbbi kettőre példa a fejezetben is bemutatásra kerülő `magyarlanc` elemző, ami szófaji szinten megkülönbözteti a tulajdonneveket, a szintaxis szintjén pedig jelöli a többtagúakat. A tulajdonnév-felismerő algoritmusok megkeresik az adott szövegben a tulajdonneveket, majd azokat valamilyen kategóriába sorolják, ilyen magyar nyelvű algoritmus a `a szeged ner`, melynek alkalmazását szintén bemutatjuk.

Fontos különbséget tenni az angol névelem-felismerés (Named Entity Recognition -- NER) és a magyar tulajdonnév-felismerés között. A névelem-felismerésbe beletartozik minden olyan kifejezés amely a világ valamely entitására egyedi módon (unikálisan) referál (vö. Tikk et al. 2006: 90--98). Ezzel szemben a tulajdonnév-felismerés, kizárólag a tulajdonnevekre koncentrál.

A `magyarlanc`nyelvi előfeldolgozó eszköz a Szegedi Tudományegyetem fejlesztése (Zsibrita et al. 2013), ami magyar nyelvű `txt` formátumú fájlokat feldolgozva képes egy szöveg mondatokra és szavakra bontására, a szavak morfológiai elemzésére, szófaji egyértelműsítésére, emellett kétféle szintaktikai elemzést is képes hozzárendelni a mondatokhoz. A magyarlanc elérhető a [https://rgai.inf.u-szeged.hu/magyarlanc](https://rgai.inf.u-szeged.hu/magyarlanc) oldalon, az innen letölthető jar fájl segítségével a `txt` formátumú szövegfájlok elemzése parancssorból lehetséges.

A magyarlanchoz hasonlóan az UDPipe nevű elemző szintén képes magyar nyelvű nyers szövegek mondatra és szavakra bontására és szófaji elemzésére, azaz POS-taggelésére (Part of Speech-tagging) továbbá a mondatok függőségi elemzésére. Ez az elemző a Universal Dependencies nemzetközileg elismert annotációs sémán alapul (Straka és Straková 2017). A két nyelvi elemző hasonló funkcionalitásokkal rendelkezik az UDPipe technikailag könnyebben kezelhető, azonban kevésbé pontos elemzési eredményt, mivel jóval kisebb tanitó anyagon lett betanítva mint a `magyarlanc`.[^nlp-1]

[^nlp-1]: Az UDPipe elérhetősége: [http://lindat.mff.cuni.cz/services/udpipe](http://lindat.mff.cuni.cz/services/udpipe)

Az alábbiakban a `magyarlanc` és a `a szeged ner` működését és az álatuk létrehozott fájlokkal R-ben végezhető elemzésekre mutatunk példákat.

## A `magyarlanc` nyelvi elemző használata

Az elemző használatának részletes leírás megtalálható az <https://rgai.inf.u-szeged.hu/magyarlanc> oldalon, itt most csak vázlatosan ismeretjük. Fontos kiemelni, hogy a `magyarlanc` JAVA modulokból áll, így használatához szükséges, hogy a számítógépen megfelelő JAVA környezet legyen telepítve. Először fenti oldalról lekell töltenünk a `magyarlanc-3.0.jar` fájlt, majd bemásolni azt a abba a mappába, ahol az elemezni kívánt `txt` található. A parancssort Windows operációs rendszer alatt a számítógép kereső mezőjébe a `cmd` parancs beírásával tudjuk megnyitni. Ezután a parancsorban belépve abba a könyvtárba, ahol az elemezni kíván txt és a `magyarlanc-3.0.jar` elemző van, az alábbi parancs segítségével végezhetjük el az elemzést: `java -Xmx1G -jar magyarlanc-3.0.jar -mode morphparse -input in.txt -output out.txt`. Ahol az `in.txt` helyébe az elemezni kívánt `txt` nevét, az `out.txt` helyébe, pedig az elemzés eredményeként létrejövő fájl nevét kell megadni.

Példánkban a Magyar Országgyűlésben 2014 és 2018 között elhangzott véletlenszerűen kiválasztott 25 napirend előtti felszólalás korpuszán szemléltetjük az elemző működését. A 25 fájlt elemezhetjük egyesével, de ha ez a későbbi elemzéshez nem szükséges, a parancsorban a `copy *.txt eredmeny.txt` paranccsal egyesíthetjük azokat egy fájlba. Majd ezen az eredmeny.txt-n végezzük el az elemzést az alábbi paranccsal: `java -Xmx1G -jar magyarlanc-3.0.jar -mode morphparse -input eredmeny.txt -output eredmeny_out.txt`

Az elemzés eredméynül kapott `txt` fájlban láthatjuk, hogy az elemző elvégezte a szövegek mondatokrabontását, tokenizálását, lemmatizálását és POS-taggelését, azaz meghatározta a szavak szófaját.

```{r echo=FALSE}
knitr::include_graphics("figures/11-01_magyarlanc_kimenet.png")
```

Ezt követően célszerű a `txt` fájlt excelbe beolvasva oszlopokra tagolni, az oszlopokat fejléccel ellátni, majd `csv` fájlként elmenteni.

```{r echo=FALSE}
knitr::include_graphics("figures/11-02_napirend_elotti_magyarlanc.png")

```

Az így létrehozott `csv` fájlt ezután a korábban már megismert módon olvashatjuk be a `readr` csomag segítségével.

```{r}
library(readr)
library (dplyr)
```

```{r}
napirend_elotti <- read_delim("data/napirend_elotti_magyarlanc.csv", delim = ";")
```

Az így létrehozott data frame objektummal, mely esetünkben 17870 megfigyeést és 4 változót tartalmaz, ezután különböző műveleteket végezhetünk, a korábban már bemutatottak szerint, például `dplyr` csomag `filter` függvénye segítségével kiválgathatjuk az igéket, és elmenthetjük azokat egy újabb 1769 megfigyelést és 4 váltiozót tartalmazó objektumba.

```{r}
verb_napirend_elotti <- napirend_elotti %>%
  filter(POS_tag == "VERB")
```

## A `szeged ner` elemző használata

A `magyarlanc` nyelvi elemzőhöz hasonlóan használhatjuk a `szeged ner` elemzőt is, melynek részletes leírása maga a `ner.jar` elemző is megtalálható az alábbi oldalon <https://rgai.inf.u-szeged.hu/node/109>. Az elemző a fent bemutatott módon szintén parancssorból indítható az alábbi parancs használatával: `java -Xmx3G -jar ner.jar -mode predicate -input input.txt -output output.txt` Az elemző PER (személynév), LOC (hely(szín)), ORG (szervezet) és MISC (vegyes) címkét ad az egyes névelemeknek.

```{r echo=FALSE}
knitr::include_graphics("figures/11-03_ner.png")

```

A fentiekhez hasonlóan ezt a txt-t is átalakíthatjuk táblázattá, majd ezt a `csv` fájlt beolvashatjuk.

```{r}
napirend_elotti_ner <- read_delim("data/ner.csv", delim = ";")
```

Ezután pedig tetszőlegesen kiválogathatjuk például a helyek neveit. A filterezés eredményeként láthatjuk, hogy az elemző korpuszunkban 175 szót azonosított és címkézett fel helynévként.

```{r}
loc_napirend_elotti <- napirend_elotti_ner %>%
  filter(ner == "I-LOC")
```

## Angol nyelvű szövegek névelemfelismerése

Amennyiben angol nyelvű korpusszal dolgozunk több lehetőség is a rendelkezésünkre áll a névelemfelsimerés elvégzésére.

Ezek közül most röviden a `spacyr` használatát mutatjuk be. A `spaCy` nem egy `R`, hanem egy `Phyton` csomag, amely azonban az R `reticulate` csomag segítségével nagyon jól együttműködik a kötetben rendszeresen használt `quanteda` csomaggal. Használatához a már megszokott módon installálnunk kell a spacyr csomagot, majd beolvasnunk és tepeítenünk az angol nyelvi modellt.

```{r}
library(spacyr)
spacy_initialize(model = "en_core_web_sm")
```

A `spacy_parse()` függvény segítségével lehetőségünk van a szövekek tokenizálására, lemmatizálsára és POS-taggelésére.

```{r}
txt <- c(d1 = "spaCy is great at fast natural language processing.",
         d2 = "Mr. Smith spent two years in North Carolina.")

# process documents and obtain a data.table
parsedtxt <- spacy_parse(txt)

parsedtxt
```

Az elvégzett tokenizálás eredményéből data frame-t készíthetünk.

```{r}
spacy_tokenize(txt, remove_punct = TRUE, output = "data.frame") %>%
    tail()
```

Ugyancsak lehetőségünk van a különböző entitások, így például a tulajdonnevek kinyerésére

```{r}
parsedtxt <- spacy_parse(txt, lemma = FALSE, entity = TRUE, nounphrase = TRUE)
entity_extract(parsedtxt)
```

De a tulajdonneveken túl felcímkézhetjük a dátumokat, eseményeket is.

```{r}
entity_extract(parsedtxt, type = "all")
```

Az entity_consolidate() függvény segítségével arra is ehetőségünk van, hogy a több szóból álló entitásokat egy tokenként kezeljük.

```{r}
entity_consolidate(parsedtxt) %>%
    tail()
```

A `nounphrase_extract()` függvény lehetőséget ad az összetartozó kifejezések összefűzésére.

```{r}
nounphrase_extract(parsedtxt)
```

Majd képes arra, hogy ezeket az összetartozó kifejezéseket egyben kezelje.

```{r}
nounphrase_consolidate(parsedtxt)
```

Arra is lehetőség van, hogy az egyes kifejezések közötti függőségeket vizsgáljuk.

```{r}
spacy_parse(txt, dependency = TRUE, lemma = FALSE, pos = FALSE)
```

A spacyr alapvetően az angol nyelvi modellel működik, de arra is van lehetőség, hogy a spaCy egyéb beépített nyelvi modelljeit (német, spanyol, portugál) használjuk. Létezik magyar nyelvi modell is, ez azonban jelenleg még nincs integrálva a spaCy-be, hanem egy GitHub repozitoriból tölthető le. Ennek R-ben történő megvalósításához azonban haladó R ismeretek szükségesek, azért ennek leírásától jelen kötetben eltekintünk. A magyar nyelvi modell és leírása elérhető az alábbi linken: [https://github.com/oroszgy/spacy-hungarian-models](https://github.com/oroszgy/spacy-hungarian-models)
