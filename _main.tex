% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{book}
\usepackage{lmodern}
\usepackage{amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
  \usepackage{amssymb}
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Szövegbányászat és mesterséges intelligencia R-ben},
  pdfauthor={Sebők Miklós, Ring Orsolya},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\ifluatex
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-ident, #2 entry spacing
 {% don't indent paragraphs
  \setlength{\parindent}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1 \everypar{\setlength{\hangindent}{\cslhangindent}}\ignorespaces\fi
  % set entry spacing
  \ifnum #2 > 0
  \setlength{\parskip}{#2\baselineskip}
  \fi
 }%
 {}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{#1\hfill\break}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{#1}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{#1}\break}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\title{Szövegbányászat és mesterséges intelligencia R-ben}
\author{Sebők Miklós, Ring Orsolya}
\date{2021-04-12 15:34:53}

\begin{document}
\frontmatter
\maketitle

\mainmatter
\hypertarget{bevezetuxe9s}{%
\chapter{Bevezetés}\label{bevezetuxe9s}}

Jelen kötet a Kvantitatív szövegelemzés és szövegbányászat a
politikatudományban (L'Harmattan, 2016) című könyv folytatásaként és
egyben kiegészítéseként a szövegbányászat és a mesterséges intelligencia
társadalomtudományi alkalmazásának gyakorlatába nyújt bevezetést. A
szövegek kvantitatív elemzése (quantitative text analysis -- QTA) a
nemzetközi társadalomtudomány egyik leggyorsabban fejlődő irányzata. A
szövegek és más minőségi adatok (filmek, képek) elemzése annyiban
különbözik a mennyiségi (kvantitatív) adatokétól, hogy nyers formájukban
még nem alkalmasak arra, hogy statisztikai, illetve ökonometriai elemzés
alá vessük őket, s így további módszertani problémákat vetnek fel,
melyek speciális tárgyalása szükséges. A tervezett kötetben bemutatott
példák többsége a politikatudományhoz kapcsolódik, de más alkalmazási
területekre is kitér.

Míg az előző kötet az egyes kódolási eljárásokat, illetve ezek
kutatás-módszertani előnyeit és hátrányait ismertette, itt a
társadalomtudományi elemzésének során használható kvantitatív
szövegelemzés legfontosabb gyakorlati feladatait vesszük sorra. A
kézirat a magyar tankönyvpiacon az elsőnek számít a tekintetben, hogy a
társadalomtudományban használatos kvantitatív szövegelemzési eljárásokat
részletesen, lépésről-lépésre ismerteti, kezdve a megfelelő korpusz
kialakításához szükséges ismeretektől, a különböző szövegbányászati
módszerek (szózsák, dokumentum-kifejezés mátrix, a névelem-felismerés,
az osztályozás, illetve a csoportosítás feladataira), illetve az
egyszerűbb szövegösszehasonlítási-feladatok áttekintésén át, egészen a
felügyelt és felügyelet nélküli gépi tanulásig, a politikatudományi
vizsgálatok során leggyakrabban használatos R programnyelven készült
programok segítségével.

Az olvasó a két kötet együttes használatával olyan ismeretek birtokába
kerül, melyek révén képes lesz alkalmazni a kvantitatív szövegelemzés és
szövegbányászat legalapvetőbb eljárásait saját kutatására. Deduktív vagy
induktív felfedező logikája fényében dönthet az adatelemzés módjáról, és
a felkínált menüből kiválaszthatja a kutatási tervéhez legjobban
illeszkedő megoldásokat. A kötetet végigkísérő konkrét példák
segítségével pedig akár reprodukálhatja is ezen eljárásokat saját
kutatásában. Mindezt a kötet függelékében helyet kapó R-scriptek
részletes leírása is segíti majd. A kötet két fő célcsoportjaként így a
társadalomtudományi kutatói és felsőoktatási közösséget határozzuk meg,
valamint rögzítjük, hogy a kvantitatív szövegelemzés területén belül
elsődlegesen a dokumentum- és tartalomelemzési módszertanhoz
kapcsolódunk.

A könyvben ugyancsak helyet kap a fontosabb fogalmak magyar és angol
nyelvű szószedete, valamint a további olvasásra ajánlott szakirodalom
szerepeltetése. Az oktatásban való közvetlen alkalmazást segíthetik
továbbá a fejezetek végén megadott vizsgakérdések, illetve a kötet
honlapján (qta.tk.mta.hu) szereplő további információk:
gyakorlófeladatok (megoldásokkal), az egyes feladatokra alkalmazható
scriptek és kereskedelmi programok bemutatása, a témával kapcsolatos
prezentációk és további ajánlott irodalmak.

\hypertarget{a-kvantitatuxedv-szuxf6vegelemzuxe9s-uxe9s-szuxf6vegbuxe1nyuxe1szat-alapfogalmai}{%
\chapter{A kvantitatív szövegelemzés és szövegbányászat
alapfogalmai}\label{a-kvantitatuxedv-szuxf6vegelemzuxe9s-uxe9s-szuxf6vegbuxe1nyuxe1szat-alapfogalmai}}

elso fejezet

\hypertarget{az-adatkezeluxe9s-r-ben}{%
\chapter{Az adatkezelés R-ben}\label{az-adatkezeluxe9s-r-ben}}

\hypertarget{adatok-importuxe1luxe1sa-uxe9s-exportuxe1luxe1sa}{%
\section{Adatok importálása és
exportálása}\label{adatok-importuxe1luxe1sa-uxe9s-exportuxe1luxe1sa}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(readr)}
\FunctionTok{library}\NormalTok{(dplyr)}
\FunctionTok{library}\NormalTok{(gapminder)}
\FunctionTok{library}\NormalTok{(stringr)}
\end{Highlighting}
\end{Shaded}

Az adatok importálására az R alapfüggvénye mellett több package is
megoldást kínál. Ezek közül a könyv írásakor a legnépszerűbbek a
\texttt{readr} és a \texttt{rio} csomagok. A karakter kódolással a
legjobban a tapasztalataink szerint a \texttt{readr} csomag
\texttt{read\_csv()} megoldása bíkózik meg, ezért ezt fogjuk használni a
\texttt{.csv} állományok beolvasására. Amennyiben kihasználjuk az
RStudio projekt opcióját (lásd a
\protect\hyperlink{projektmunka}{Függelékben}) akkor elegendő csak az
elérni kívánt adatok relativ elérési útját megadni (relative path).
Ideális esetben az adataink egy csv fileban vannak (comma separated
values), ahol az egyes értékeket vesszők (vagy egyéb speciális karakter)
választják el. Ez esetben a \texttt{read\_delim()} függvényt használjuk.
A beolvasásnál egyből el is tároljuk az adatokat egy objektumban. A
\texttt{sep\ =} opcióval tudjuk a szeparátor karaktert beállítani, mert
előfordulhat hogy vessző helyett pontosvessző tagolja az adatainkat.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(}\StringTok{"data/adatfile.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Az R képes linkről letölteni fileokat, elég megadnunk egy működő elérési
útvonalat.

\textbf{placeholder link, cserelni majd mukodore}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df\_online }\OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{"https://www.qta.tk.mta.hu/adatok/adatfile.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Az R package ökoszisztémája kellően változatos ahhoz, hogy gyakorlatilag
bármilyen inputtal meg tudjon bírkózni. Az Excel fileokat a
\texttt{readxl} csomagot használva tudjuk betölteni (a csomagok
installálásával kapcsolatban lásd a
\protect\hyperlink{packages}{Függeléket}), a \texttt{read\_excel()}-t
használva. A leggyakoribb statisztikai programok formátumait pedig a
\texttt{haven} csomag tudja kezelni (például Stata, Spss, SAS). A
szintaxis itt is hasonló: \texttt{read\_stata}, \texttt{read\_spss},
\texttt{read\_sas}.

\hypertarget{szuxf6veges-dokumentumok-importuxe1luxe1sa}{%
\subsection{Szöveges dokumentumok
importálása}\label{szuxf6veges-dokumentumok-importuxe1luxe1sa}}

A nagy mennyiségű szöveges dokumentum (a legyakrabban előforduló
kiterjesztések: \texttt{.txt}, \texttt{.doc}, \texttt{.pdf},
\texttt{.json}, \texttt{.csv}, \texttt{.xml}, \texttt{.rtf},
\texttt{.odt}) betöltésére a legalkalmasabb a \texttt{readtext} package.
Az alábbi példa azt mutatja be, hogy hogyan tudunk beolvasni egy adott
mappából az összes .txt kiterjesztésű file-t, anélkül hogy bármilyen
loop-ot kellene írnunk, vagy egyenként megadni a file-ok neveit. A
\texttt{*} karakter az azt jelenti ebben a környezetben, hogy bármilyen
fájl, ami .txt-re végződik. Amennyiben a fájlok nevei tartalmaznak
valamilyen meta adatot tartalmaznak, akkor ezt be tudjuk allítani a
betöltés során. Ilyen meta adat lehet például egy parlamenti
felszólalásnál a felszólaló neve és a beszéd ideje és párttagsága
(például: \texttt{kovacsjanos\_1994\_fkgp.txt}).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df\_text }\OtherTok{\textless{}{-}} \FunctionTok{readtext}\NormalTok{(}
  \StringTok{"data/*.txt"}\NormalTok{,}
  \AttributeTok{docvarsfrom =} \StringTok{"filenames"}\NormalTok{,}
  \AttributeTok{dvsep =} \StringTok{"\_"}\NormalTok{,}
  \AttributeTok{docvarnames =} \FunctionTok{c}\NormalTok{(}\StringTok{"nev"}\NormalTok{, }\StringTok{"ev"}\NormalTok{, }\StringTok{"part"}\NormalTok{)}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{adatok-exportuxe1luxe1sa}{%
\section{Adatok exportálása}\label{adatok-exportuxe1luxe1sa}}

Az adatainkat R-ből a \texttt{write.csv()}-vel exportálhatjuk a kívánt
helyre, \texttt{.csv} formátumban. Az R rendelkezik saját, .Rds és .Rda
kiterjesztésű, tömörített fájlformátummal. Mivel ezeket csak az R-ben
nyithatjuk meg, érdemes a köztes, hosszadalmas számítást igénylő lépések
elmentésére használni, a \texttt{saveRDS()} és a \texttt{save()}
parancsokkal. Az \texttt{openxlsx} csomaggal \texttt{.xls} és
\texttt{.xlsx} Excel formátumokba is tudunk exportálni, hogyha
szükséges.

\hypertarget{a-pipe-operuxe1tor}{%
\section{A pipe operátor}\label{a-pipe-operuxe1tor}}

Az úgynevezett \emph{pipe} operátor alapjaiban határozta meg a modern R
fejlődését és a népszerű package ökoszisztéma, a \emph{tidyverse}, egyik
alapköve. Úgy gondoljuk, hogy a \emph{tidyverse} és a \emph{pipe}
egyszerűbbé teszi elsajátítani az R használatát, ezért mi is erre
helyezzük a hangsúlyt.\footnote{A \emph{tidyverse} megközelítés miatt a
  kötetben szereplő R kód követi a ``The tidyverse style guide''
  dokumentációt (\url{https://style.tidyverse.org/})} Vizuálisan a pipe
operátor így néz ki: \texttt{\%\textgreater{}\%} és arra szolgál hogy a
kódban több egymáshoz kapcsolódó műveletet egybefűzzűnk.\footnote{Az
  RStudio-ban a pipe operátor billentyű kombinációja a
  \texttt{Ctrl\ +\ Shift\ +\ M}} Technikailag a pipe a bal oldali elemet
adja meg a jobb oldali függvény első argumentumának. A lenti példa
ugyanazt a folyamatot írja le, az alap R (\emph{base R}) illetve a pipe
használatával.\footnote{Köszönjük Andrew Heissnek a kitűnő példát.}
Miközben a kódot olvassuk érdemes a pipe-ot ``\emph{és aztán}''-nak
fordítani.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{reggeli}\NormalTok{(}\FunctionTok{oltozkodes}\NormalTok{(}\FunctionTok{felkeles}\NormalTok{(}\FunctionTok{ebredes}\NormalTok{(en, }\AttributeTok{idopont =} \StringTok{"8:00"}\NormalTok{), }\AttributeTok{oldal =} \StringTok{"jobb"}\NormalTok{), }\AttributeTok{nadrag =} \ConstantTok{TRUE}\NormalTok{, }
    \AttributeTok{ing =} \ConstantTok{TRUE}\NormalTok{))}

\NormalTok{en }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{ebredes}\NormalTok{(}\AttributeTok{idopont =} \StringTok{"8:00"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{felkeles}\NormalTok{(}\AttributeTok{oldal =} \StringTok{"jobb"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{oltozkodes}\NormalTok{(}\AttributeTok{nadrag =} \ConstantTok{TRUE}\NormalTok{, }
    \AttributeTok{ing =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{reggeli}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

A fenti példa is jól mutatja, hogy a pipe a bal oldali elemet fogja a
jobb oldali függvény első elemének berakni. A fejezet további részeiben
még bőven fogunk gyakorlati példát találni a használatára. A fejezetben
bemutatott példák az alkalmazásoknak csak egy relatíve szűk körét
mutatják be, ezért érdemes átolvasni a csomagokhoz tartozó
dokumentációt, illetve ha van, akkor a működést demonstráló bemutató
oldalakat is.

\hypertarget{muveletek-a-date-framekkel}{%
\section{Muveletek a date framekkel}\label{muveletek-a-date-framekkel}}

A data frame az egyik leghasznosabb és leggyakrabban használt adat
tárolási mód az R-ben (a részletesebb leírás a
\protect\hyperlink{data-frame}{Függelékben} található) és ebben az
alfejezetben azt mutatjuk be a \texttt{dplyr} és \texttt{gapminder}
csomagok segíségével, hogy hogyan lehet hatékonyan dolgozni velük. A
\texttt{dplyr} az egyik legnépszerűbb R csomag, a \emph{tidyverse}
része. A \texttt{gapminder} csomag pedig a példa adatbázisunkat
tartalmazza, amiben a világ országainak különböző gazdasági és
társadalmi mutatói vannak.

\hypertarget{megfigyeluxe9sek-szux171ruxe9se-filter}{%
\subsection{\texorpdfstring{Megfigyelések szűrése:
\texttt{filter()}}{Megfigyelések szűrése: filter()}}\label{megfigyeluxe9sek-szux171ruxe9se-filter}}

A sorok (megfigyelések) szűréséhez a \texttt{dplyr} csomag
\texttt{filter()} parancsát használva lehetőségünk van arra hogy egy
vagy több kritérium alapján szűkítsük az adatbázisunkat. A lenti
példában azokat megfigyeléseket tartjuk meg, ahol az év 1962 és a
várható élettartam nagyobb mint 72 év.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapminder }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(year }\SpecialCharTok{==} \DecValTok{1962}\NormalTok{, lifeExp }\SpecialCharTok{\textgreater{}} \DecValTok{72}\NormalTok{)}
\CommentTok{\#\textgreater{} \# A tibble: 5 x 6}
\CommentTok{\#\textgreater{}   country     continent  year lifeExp      pop gdpPercap}
\CommentTok{\#\textgreater{}   \textless{}fct\textgreater{}       \textless{}fct\textgreater{}     \textless{}int\textgreater{}   \textless{}dbl\textgreater{}    \textless{}int\textgreater{}     \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{} 1 Denmark     Europe     1962    72.4  4646899    13583.}
\CommentTok{\#\textgreater{} 2 Iceland     Europe     1962    73.7   182053    10350.}
\CommentTok{\#\textgreater{} 3 Netherlands Europe     1962    73.2 11805689    12791.}
\CommentTok{\#\textgreater{} 4 Norway      Europe     1962    73.5  3638919    13450.}
\CommentTok{\#\textgreater{} 5 Sweden      Europe     1962    73.4  7561588    12329.}
\end{Highlighting}
\end{Shaded}

De ugyanígy leválogathatjuk a data frame-ből az adatokat akkor is hogyha
egy karakter változó alapján szeretnénk szűrni.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapminder }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(country }\SpecialCharTok{==} \StringTok{"Sweden"}\NormalTok{, year }\SpecialCharTok{\textgreater{}} \DecValTok{1990}\NormalTok{)}
\CommentTok{\#\textgreater{} \# A tibble: 4 x 6}
\CommentTok{\#\textgreater{}   country continent  year lifeExp     pop gdpPercap}
\CommentTok{\#\textgreater{}   \textless{}fct\textgreater{}   \textless{}fct\textgreater{}     \textless{}int\textgreater{}   \textless{}dbl\textgreater{}   \textless{}int\textgreater{}     \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{} 1 Sweden  Europe     1992    78.2 8718867    23880.}
\CommentTok{\#\textgreater{} 2 Sweden  Europe     1997    79.4 8897619    25267.}
\CommentTok{\#\textgreater{} 3 Sweden  Europe     2002    80.0 8954175    29342.}
\CommentTok{\#\textgreater{} 4 Sweden  Europe     2007    80.9 9031088    33860.}
\end{Highlighting}
\end{Shaded}

Itt tehát a data frame azon sorait szeretnénk látni, ahol az ország
megegyezik a „Sweden" karakterlánccal az év pedig nagyobb, mint 1990.

\hypertarget{vuxe1ltozuxf3k-kivuxe1logatuxe1sa-select}{%
\subsection{\texorpdfstring{Változók kiválogatása:
\texttt{select()}}{Változók kiválogatása: select()}}\label{vuxe1ltozuxf3k-kivuxe1logatuxe1sa-select}}

A \texttt{select()} függvény segítségével válogathatunk oszlopokat a
data frame-ből. A változók kiválasztására több megoldás is van. A
\texttt{dplyr} csomag tartalmaz apróbb kisegítő függvényeket, amik
megkönnyítik a nagy adatbázisok esetén a változók kiválogatását a nevük
alapján. Ezek a függvények a \texttt{contains()},
\texttt{starts\_with()}, \texttt{ends\_with()}, \texttt{matches()} és
beszédesen arra szolgálnak hogy bizonyos nevű változókat ne kelljen
egyenként felsorolni. A \texttt{select()}-en belüli változó sorrend
egyben az eredmény data frame változó sorrendjet is megadja. A negatív
kiválasztás is lehetséges, ebben az esetben egy \texttt{-} kell tennünk
a nemkívánt változó(k) elé (pl.:
\texttt{select(df,\ year,\ country,\ -continent}).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapminder }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(}\FunctionTok{contains}\NormalTok{(}\StringTok{"ea"}\NormalTok{), }\FunctionTok{starts\_with}\NormalTok{(}\StringTok{"co"}\NormalTok{), pop)}
\CommentTok{\#\textgreater{} \# A tibble: 1,704 x 4}
\CommentTok{\#\textgreater{}     year country     continent      pop}
\CommentTok{\#\textgreater{}    \textless{}int\textgreater{} \textless{}fct\textgreater{}       \textless{}fct\textgreater{}        \textless{}int\textgreater{}}
\CommentTok{\#\textgreater{}  1  1952 Afghanistan Asia       8425333}
\CommentTok{\#\textgreater{}  2  1957 Afghanistan Asia       9240934}
\CommentTok{\#\textgreater{}  3  1962 Afghanistan Asia      10267083}
\CommentTok{\#\textgreater{}  4  1967 Afghanistan Asia      11537966}
\CommentTok{\#\textgreater{}  5  1972 Afghanistan Asia      13079460}
\CommentTok{\#\textgreater{}  6  1977 Afghanistan Asia      14880372}
\CommentTok{\#\textgreater{}  7  1982 Afghanistan Asia      12881816}
\CommentTok{\#\textgreater{}  8  1987 Afghanistan Asia      13867957}
\CommentTok{\#\textgreater{}  9  1992 Afghanistan Asia      16317921}
\CommentTok{\#\textgreater{} 10  1997 Afghanistan Asia      22227415}
\CommentTok{\#\textgreater{} \# ... with 1,694 more rows}
\end{Highlighting}
\end{Shaded}

\hypertarget{uxfaj-vuxe1ltozuxf3k-luxe9trehozuxe1sa-mutate}{%
\subsection{\texorpdfstring{Új változók létrehozása:
\texttt{mutate()}}{Új változók létrehozása: mutate()}}\label{uxfaj-vuxe1ltozuxf3k-luxe9trehozuxe1sa-mutate}}

Az elemzési munkafolyamat elkerülhetetlen része hogy új változókat
hozzunk létre, vagy a meglévőket módosítsuk. Ezt a \texttt{mutate()}-el
tehetjuk meg, ahol a szintaxis a következő:
\texttt{mutate(data\ frame,\ uj\ valtozo\ =\ ertekek)}. Példaként
kiszámoljuk a Svéd GDP-t (milliárd dollárban) 1992-től kezdve. A
\texttt{mutate()} alkalmazásával részletesebben is foglalkozunk a
szövegek előkészítésével foglalkozó fejezetben.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapminder }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(country }\SpecialCharTok{==} \StringTok{"Sweden"}\NormalTok{, year }\SpecialCharTok{\textgreater{}=} \DecValTok{1992}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{gdp =}\NormalTok{ (gdpPercap }\SpecialCharTok{*}\NormalTok{ pop) }\SpecialCharTok{/} \DecValTok{10}\SpecialCharTok{\^{}}\DecValTok{9}\NormalTok{)}
\CommentTok{\#\textgreater{} \# A tibble: 4 x 7}
\CommentTok{\#\textgreater{}   country continent  year lifeExp     pop gdpPercap   gdp}
\CommentTok{\#\textgreater{}   \textless{}fct\textgreater{}   \textless{}fct\textgreater{}     \textless{}int\textgreater{}   \textless{}dbl\textgreater{}   \textless{}int\textgreater{}     \textless{}dbl\textgreater{} \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{} 1 Sweden  Europe     1992    78.2 8718867    23880.  208.}
\CommentTok{\#\textgreater{} 2 Sweden  Europe     1997    79.4 8897619    25267.  225.}
\CommentTok{\#\textgreater{} 3 Sweden  Europe     2002    80.0 8954175    29342.  263.}
\CommentTok{\#\textgreater{} 4 Sweden  Europe     2007    80.9 9031088    33860.  306.}
\end{Highlighting}
\end{Shaded}

\hypertarget{csoportonkuxe9nti-statisztikuxe1k-group_by-uxe9s-summarize}{%
\subsection{\texorpdfstring{Csoportonkénti statisztikák:
\texttt{group\_by()} és
\texttt{summarize()}}{Csoportonkénti statisztikák: group\_by() és summarize()}}\label{csoportonkuxe9nti-statisztikuxe1k-group_by-uxe9s-summarize}}

Az adataink részletesebb és alaposabb megismerésében segítenek a
különböző szintű leíró statisztikai adatok. A szintek megadására a
\texttt{group\_by()} használható, a csoportokon belüli számításokhoz
pedig a \texttt{summarize()}. A lenti példa azt illusztrálja, hogyha
kontinensenként csoportosítjuk a \texttt{gapminder} data framet, akkor a
\texttt{summarise()} használatával megkaphatjuk a megfigyelések számát,
illetve az átlagos per capita GDP-t. A \texttt{summarise()} a
\texttt{mutate()} közeli rokona, hasonló szintaxissal és logikával
használható. Ezt a függvény párost fogjuk majd használni a szöveges
adataink leíró statisztikáinál is a 4. fejezetben.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapminder }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(continent) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarise}\NormalTok{(}\AttributeTok{megfigyelesek =} \FunctionTok{n}\NormalTok{(), }\AttributeTok{atlag\_gdp =} \FunctionTok{mean}\NormalTok{(gdpPercap))}
\CommentTok{\#\textgreater{} \# A tibble: 5 x 3}
\CommentTok{\#\textgreater{}   continent megfigyelesek atlag\_gdp}
\CommentTok{\#\textgreater{}   \textless{}fct\textgreater{}             \textless{}int\textgreater{}     \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{} 1 Africa              624     2194.}
\CommentTok{\#\textgreater{} 2 Americas            300     7136.}
\CommentTok{\#\textgreater{} 3 Asia                396     7902.}
\CommentTok{\#\textgreater{} 4 Europe              360    14469.}
\CommentTok{\#\textgreater{} 5 Oceania              24    18622.}
\end{Highlighting}
\end{Shaded}

\hypertarget{munka-karakter-vektorokkaladatkezeles-4}{%
\section[Munka karakter vektorokkal]{\texorpdfstring{Munka karakter
vektorokkal\footnote{A könyv terjedelme miatt ezt a témát itt csak
  bemutatni tudjuk, de minden részletre kiterjedően nem tudunk
  elmélyülni benne. Kíváló online anyagok találhatóak az RStudio GitHub
  tárhelyén
  (\url{https://github.com/rstudio/cheatsheets/raw/master/strings.pdf}),
  illetve \protect\hyperlink{ref-wickham2016r}{Wickham and Grolemund}
  (\protect\hyperlink{ref-wickham2016r}{2016}) 14. fejezetében.}}{Munka karakter vektorokkal}}\label{munka-karakter-vektorokkaladatkezeles-4}}

A szöveges adatokkal (karakter stringekkel) való munka elkerülhetetlen
velejárója hogy a felesleges szövegelemeket, karaktereket el kell
távolítanunk ahhoz hogy az elemzésünk hatásfoka javuljon (erről
részletesebben a 3. fejezetben lesz szó). Erre a célra a
\texttt{stringr} csomagot fogjuk használni, kombinálva a korábban
bemutatott \texttt{mutate()}-el. A \texttt{stringr} függvények az
\texttt{str\_} előtaggal kezdődnek és eléggé beszédes nevekkel
rendelkeznek. Egy gyakran előforduló probléma, hogy extra szóközök
maradnak a szövegben, vagy bizonyos szavakról, karakterkombinációkról
tudjuk hogy nem kellenek az elemzésünkhoz. Ebben az esetben egy vagy
több \emph{regular expression} (regex) használatával tudjuk pontosan
kijelölni hogy a karakter sornak melyik részét akarjuk módosítani. A
legegyszerűbb formája a regexeknek, hogyha pontosan tudjuk milyen
szöveget akarunk megtalálni. A kísérletezésre az \texttt{str\_view()}-t
használjuk, ami megjeleníti hogy a megadott regex mintánk pontosan mit
jelöl.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{szoveg }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"gitar"}\NormalTok{, }\StringTok{"ukulele"}\NormalTok{, }\StringTok{"nagybogo"}\NormalTok{)}

\FunctionTok{str\_view}\NormalTok{(szoveg, }\AttributeTok{pattern =} \StringTok{"ar"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Az \emph{anchor}-okkal azt lehet megadni, hogy a karakter string elején
vagy végén szeretnénk egyezést találni. A string eleji anchor a
\texttt{\^{}}, a string végi pedig a \texttt{\$}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{str\_view}\NormalTok{(}\StringTok{"Dr. Doktor Dr."}\NormalTok{, }\AttributeTok{pattern =} \StringTok{"\^{}Dr."}\NormalTok{)}

\FunctionTok{str\_view}\NormalTok{(}\StringTok{"Dr. Doktor Dr."}\NormalTok{, }\AttributeTok{pattern =} \StringTok{"Dr.$"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Egy másik jellemző probléma, hogy olyan speciális karaktert akarunk
leírni a regex kifejezésünkkel, ami amúgy a regex szintaxisban használt.
Ilyen eset például a \texttt{.}, ami mint írásjel sokszor csak zaj, ám a
regex kotextusban a ``bármilyen karakter'' megfelelője.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{str\_view}\NormalTok{(}\StringTok{"Dr. Doktor Dr."}\NormalTok{, }\AttributeTok{pattern =} \StringTok{".k."}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Ahhoz hogy magát az írásjelet jelöljük, a
\texttt{\textbackslash{}\textbackslash{}} -t kell elé rakni.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{str\_view}\NormalTok{(}\StringTok{"Dr. Doktor Dr."}\NormalTok{, }\AttributeTok{pattern =} \StringTok{"}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{."}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Néhány hasznos regex kifejezés:

\begin{itemize}
\tightlist
\item
  \texttt{{[}:digit:{]}} - számok (123)
\item
  \texttt{{[}:alpha:{]}} - betűk (abc ABC)
\item
  \texttt{{[}:lower:{]}} - kisbetűk (abc)
\item
  \texttt{{[}:upper:{]}} - nagybetűk (ABC)
\item
  \texttt{{[}:alnum:{]}} - betűk és számok (123 abc ABC)
\item
  \texttt{{[}:punct:{]}} - központozás
  (\texttt{.!?\textbackslash{}()\{\}})
\item
  \texttt{{[}:graph:{]}} - betűk, számok és központozás (123 abc ABC
  \texttt{.!?\textbackslash{}()\{\}})
\item
  \texttt{{[}:space:{]}} - szóköz ( )
\item
  \texttt{{[}:blank:{]}} - szóköz és tabulálás
\item
  \texttt{{[}:cntrl:{]}} - kontrol karakterek
  (\texttt{\textbackslash{}n}, \texttt{\textbackslash{}r}, stb.)
\item
  \texttt{*} - bármi
\end{itemize}

\hypertarget{korpuszuxe9puxedtuxe9s-uxe9s-szuxf6vegelux151kuxe9szuxedtuxe9s}{%
\chapter{Korpuszépítés és
szövegelőkészítés}\label{korpuszuxe9puxedtuxe9s-uxe9s-szuxf6vegelux151kuxe9szuxedtuxe9s}}

\hypertarget{szuxf6vegbeszerzuxe9s}{%
\section{Szövegbeszerzés}\label{szuxf6vegbeszerzuxe9s}}

A szövebányászati elemzések egyik első lépése az elemzés alapjául
szolgáló korpusz megépítése. A korpuszt alkotó szövegek beszerzésének
egyik módja a webscarping, melynek során weboldalakról történik az
információ kinyerése.

A scrapelést végezhetjük R-ben az \texttt{rvest} csomomag segítségével.
Fejezetünkben a scrapelésnek csupán néhány alaplépését mutatjuk meg, a
folyamatról bővebb információ található például az alábbi
oldalakon:\url{https://cran.r-project.org/web/packages/rvest/rvest.pdf},
\url{https://rvest.tidyverse.org/}.

\begin{Shaded}
\begin{Highlighting}[]

\FunctionTok{library}\NormalTok{(rvest)}
\FunctionTok{library}\NormalTok{(readr)}
\FunctionTok{library}\NormalTok{(dplyr)}
\FunctionTok{library}\NormalTok{(lubridate)}
\FunctionTok{library}\NormalTok{(stringr)}
\FunctionTok{library}\NormalTok{(quanteda)}
\FunctionTok{library}\NormalTok{(quanteda.textmodels)}
\end{Highlighting}
\end{Shaded}

Majd a \texttt{read\_html()} függvény segítségével az adott weboldal
adatait kérjük le a szerverről. A \texttt{read\_html()} függvény
argumentuma az adott weblap URL-je.

Ha például a \texttt{poltextLAB} projekt honlapjáról szeretnénk adatokat
gyűjteni, azt az alábbi módon tehetjük meg:

\begin{Shaded}
\begin{Highlighting}[]

\NormalTok{r }\OtherTok{\textless{}{-}} \FunctionTok{read\_html}\NormalTok{(}\StringTok{"https://poltextlab.tk.hu/hu"}\NormalTok{)}

\NormalTok{r}
\CommentTok{\#\textgreater{} \{html\_document\}}
\CommentTok{\#\textgreater{} \textless{}html lang="hu" class="no{-}js"\textgreater{}}
\CommentTok{\#\textgreater{} [1] \textless{}head\textgreater{}\textbackslash{}n\textless{}meta http{-}equiv="Content{-}Type" content="text/html; charset=UTF{-}8 ...}
\CommentTok{\#\textgreater{} [2] \textless{}body class="index"\textgreater{}\textbackslash{}n\textbackslash{}n\textbackslash{}t\textless{}script\textgreater{}\textbackslash{}n\textbackslash{}t  (function(i,s,o,g,r,a,m)\{i[\textquotesingle{}Googl ...}
\end{Highlighting}
\end{Shaded}

Ezután a \texttt{html\_nodes()} függvény argumentumaként meg kell adnunk
azt a HTML címkét vagy CSS azonosítót, ami a legyűjteni kívánt elemeket
azonosítja a weboldalon. Ezeket az azonosítókat az adott weboldal
forráskódjának megtekintésével tudhatjuk meg, amire a különböző
böngészők különböző lehetőségeket kínálnak. Majd a \texttt{html\_text()}
függvény segítségével megkapjuk azokat a szövegeket, amely az adott
weblapon az adott azonosítóval rendelkeznek.

Példánkban a \url{https://poltextlab.tk.hu/hu} weboldalról azokat az
információkat szeretnénk kigyűjteni, amelyek az
\texttt{\textless{}title\textgreater{}} címke alatt szerepenek:

\begin{Shaded}
\begin{Highlighting}[]

\NormalTok{title }\OtherTok{\textless{}{-}} \FunctionTok{read\_html}\NormalTok{(}\StringTok{"https://poltextlab.tk.hu/hu"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{html\_nodes}\NormalTok{(}\StringTok{"title"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{html\_text}\NormalTok{()}


\NormalTok{title}
\CommentTok{\#\textgreater{} [1] "MTA TK Political and Legal Text Mining and Artificial Intelligence Laboratory (poltextLAB)"}
\end{Highlighting}
\end{Shaded}

A kigyűjtött információkat pedig ezután kiíratjuk egy \texttt{csv}
fájlba.

\begin{Shaded}
\begin{Highlighting}[]

\FunctionTok{write\_csv}\NormalTok{(title, }\StringTok{"title.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

A web scraping során az egyik nehézség, ha a weboldal letiltja az
automatikus letöltést, ezt kivédhetjük például különböző
böngészőbővítmények segítségével, illetve a fejléc (header) vagy a user
agent megváltoztatásával, de segíthet véletlenszerű proxy vagy VPN
szolgáltatás használata is, valamint ha az egyes kérések között időt
hagynunk. A weboldalakon legtöbbször a legyűjtött szövegekhez tartozó
különböző metaadatok is szerepelnek (például egy parlamenti beszéd
dátuma, az azt elmondó képviselő neve), melyeket érdemes a scarpelés
során szintén összegyűjteni. A scrapelés során fontos figyelnünk arra,
hogy később jól használható formában mentsük el az adatokat, például
\texttt{.csv},\texttt{.json} vagy \texttt{.txt} kiterjesztésekkel. A
karakterkódolási problémák elkerülése érdekében érdemes UTF-8 vagy
UTF-16-os kódolást alkalmazni, mivel ezek tartalmazzák a magyar nyelv
ékezetes karaktereit is. A karakterkódolással kapcsolatosan hasznos
további információk találhatóak az alábbi oldalon:
\url{http://www.cs.bme.hu/~egmont/utf8/}

Arra is van lehetőség, hogy az elemezni kívánt korpuszt papíron
keletkezett, majd szkennelt és szükség szerint optikai
karakterfelismerés (OCR, Optical Character Recognition) segítségével
feldolgozott szövegekből építsük fel. Azonban mivel ezeket a feladatokat
nem R-ben végezzük, ezekről itt nem szólunk bővebben. Az így beszerzett
és \texttt{.txt}, vagy \texttt{.csv} fájlá alakított szövegekből való
korpuszépítés a következő lépésekben megegyezik a weboldalakról gyűjtött
szövegekével.

\hypertarget{szuxf6vegelux151kuxe9szuxedtuxe9s}{%
\section{Szövegelőkészítés}\label{szuxf6vegelux151kuxe9szuxedtuxe9s}}

Az elemzéshez vezető következő lépés a szövegelőkészítés, amit a szöveg
tisztításával kell megkezdenünk. A szövegtisztításnél mindig járjunk el
körültekintően és az egyes lépéseket a kutatási kérdésünknek megfelelően
tervezzük meg, a folyamat során pedig időnként végezzünk ellenőrzést,
ezzel elkerülhetjük a kutatásunkhoz szükséges információk elvesztését.

Miután az elemezni kívánt szövegeinket beszereztük, majd a ``Szöveges
dokumentumok importálása''{[}BE KELL MAJD ÍRNI A VÉLGLEGES
FEJEZETSZÁMOT{]} című aljezetben leírtak szerint importáltuk,
következhetnek az alapvető előfeldolgozási lépések, ezek közé tartozik
például a scrapelés során a kopuszba került html címkék, számok és egyéb
zajok (például a speciális karakterek, írásjelek) eltávolítása a
korpuszból, valamint a kisbetűsítés, a tokenizálás, a szótövezés és a
stopszavazás.

\hypertarget{string-mux171veletek}{%
\subsection{String műveletek}\label{string-mux171veletek}}

A \texttt{stringr} csomag segítségével először eltávolíthatjuk a
felesleges \texttt{html} címkéket a kopruszból. Ehhez először
létrehozzuk a \texttt{text1} nevű objektumot ami egy karaktervektoból
áll.

\begin{Shaded}
\begin{Highlighting}[]

\NormalTok{text1 }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"MTA TK"}\NormalTok{, }\StringTok{"\textless{}font size=\textquotesingle{}6\textquotesingle{}\textgreater{} Political and Legal Text Mining and Artificial Intelligence Laboratory (poltextLAB)"}\NormalTok{)}

\NormalTok{text1}
\CommentTok{\#\textgreater{} [1] "MTA TK"                                                                                             }
\CommentTok{\#\textgreater{} [2] "\textless{}font size=\textquotesingle{}6\textquotesingle{}\textgreater{} Political and Legal Text Mining and Artificial Intelligence Laboratory (poltextLAB)"}
\end{Highlighting}
\end{Shaded}

Majd a \texttt{str\_replace\_all()}függvény segítségével eltávolítjuk
két html címke közötti szövegrészt. Ehhez a függvény argumentumában
létrehozunk egy regex kifejezést, aminek segítségével a függvény minden
\textless\textgreater{} közötti szövegrészt üres karakterekre cserél.
Ezután a \texttt{str\_to\_lower()}mindent kisbetűvé konvertál, majd a
\texttt{str\_trim()}eltávolítja a szóközöket a karekterláncok elejéről
és végéről.

\begin{Shaded}
\begin{Highlighting}[]

\NormalTok{text1 }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{str\_replace\_all}\NormalTok{(}\AttributeTok{pattern =} \StringTok{"\textless{}.*?\textgreater{}"}\NormalTok{, }\AttributeTok{replacement =} \StringTok{""}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{str\_to\_lower}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{str\_trim}\NormalTok{()}
\CommentTok{\#\textgreater{} [1] "mta tk"                                                                             }
\CommentTok{\#\textgreater{} [2] "political and legal text mining and artificial intelligence laboratory (poltextlab)"}
\end{Highlighting}
\end{Shaded}

\hypertarget{tokenizuxe1luxe1s-szuxf3tuxf6vezuxe9s-kisbetux171suxedtuxe9s-uxe9s-a-stopszavak-eltuxe1voluxedtuxe1sa}{%
\subsection{Tokenizálás, szótövezés, kisbetűsítés és a stopszavak
eltávolítása}\label{tokenizuxe1luxe1s-szuxf3tuxf6vezuxe9s-kisbetux171suxedtuxe9s-uxe9s-a-stopszavak-eltuxe1voluxedtuxe1sa}}

Az előkészítés következő lépésében tokenizáljuk, azaz egységeire bontjuk
az elemezni kívánt szöveget, a tokenek így pedig az egyes szavakat vagy
kifejezéseket fogják jelölni. Ennek eredményeként kapjuk meg az
n-gramokat, amik a vizsgált egységek (számok, betűk, szavak,
kifejezések) n-elemű sorozatát alkotják.

A következőkben a ``Példa az előkészítésre'' mondatot bontjuk először
tokenekre a \texttt{tokens()} függvénnyel, majd a tokeneket a
\texttt{tokens\_tolower()} segítségével kisbetűsítjük, a
\texttt{tokens\_wordstem()} függvénnyel pedig szótövezzük. Végezetül a
\texttt{quanteda} csomagban található magyar nyelvű stopszótár
segítségével, elvégezzük a stopszavak eltávolítását.Ehhez először
létrehozzuk az \texttt{sw} elenevezésű karaktervektort a magyar
stopszvakból. A \texttt{head()} függvény segítségével belenézhetünk a
szótárba, és a console-ra kiírathatjuk a szótár első hat szavát. Végül a
\texttt{tokens\_remove()}segítségével eltávolítjuk a stopszavakat.

\begin{Shaded}
\begin{Highlighting}[]

\NormalTok{text }\OtherTok{\textless{}{-}} \StringTok{"Példa az elokészítésre"}

\NormalTok{toks }\OtherTok{\textless{}{-}} \FunctionTok{tokens}\NormalTok{(text)}

\NormalTok{toks }\OtherTok{\textless{}{-}} \FunctionTok{tokens\_tolower}\NormalTok{(toks)}

\NormalTok{toks }\OtherTok{\textless{}{-}} \FunctionTok{tokens\_wordstem}\NormalTok{(toks)}

\NormalTok{toks}
\CommentTok{\#\textgreater{} Tokens consisting of 1 document.}
\CommentTok{\#\textgreater{} text1 :}
\CommentTok{\#\textgreater{} [1] "példa"        "az"           "elokészítésr"}

\NormalTok{sw }\OtherTok{\textless{}{-}} \FunctionTok{stopwords}\NormalTok{(}\StringTok{"hungarian"}\NormalTok{)}

\FunctionTok{head}\NormalTok{(sw)}
\CommentTok{\#\textgreater{} [1] "a"     "ahogy" "ahol"  "aki"   "akik"  "akkor"}

\FunctionTok{tokens\_remove}\NormalTok{(toks, sw)}
\CommentTok{\#\textgreater{} Tokens consisting of 1 document.}
\CommentTok{\#\textgreater{} text1 :}
\CommentTok{\#\textgreater{} [1] "példa"        "elokészítésr"}
\end{Highlighting}
\end{Shaded}

\hypertarget{stemmeluxe9s-vagy-lemmatizuxe1luxe1s}{%
\subsubsection{Stemmelés vagy
lemmatizálás}\label{stemmeluxe9s-vagy-lemmatizuxe1luxe1s}}

Ezt követi a szótövezés lépése, melynek során az alkalmazott stemmelő
algoritmus egyszerűen levágja a szavak összes toldalékát, a képzőket,
jelzőket és ragokat. A stemmelés helyett alkalmazhatunk lemmatizálást,
melynek során a szavakat a szótári alakjukra formáljuk. A stemming és
lemmatizálás közötti különbség abban rejlik, hogy a szótövezés során
csupán eltávolítjuk a szavak toldalékként azonosított végződéseit, hogy
ugyanannak a szónak különböző megjelenési formáit közös törzsre
redukáljuk, míg a lemmatizálás esetében rögtön az értelmes, szótári
formát kapjuk vissza. A két módszer közötti választás a kutatási kérdés
alapján meghozott kutatói döntésen
alapul.(\protect\hyperlink{ref-grimmer2013a}{\textbf{grimmer2013a?}})

\hypertarget{lemmatizuxe1luxe1s}{%
\paragraph{Lemmatizálás}\label{lemmatizuxe1luxe1s}}

Az alábbi példában egyetlen szó különböző alakjainak szótári alakra
hozásával szemléltetjük a lemmatizáslás működését.

Ehhez először a \texttt{text1} nevű objektumban tároljuk a lemmatizálni
kívánt szöveget, majd tokenizáljuk és eltávolítjuk a központozást.
Ezután definiáljuk azt a megfelelő szótövet és azt, hogy mely szavak
alakjait szeretnénk erre a szótőre egységesíteni majd a \texttt{rep()}
függvény segítségével elvégezzük a lemmatizálást, amely a korábban
definiált szólakokat az általunk megadott szótári alakkal helyettesíti.
Hosszabb szövegek lemmatizálásához előre létrehozott szótárakat
használhatunk, ilyen például a Wordnet, ami magyar nyelven is elérhető:
\url{https://github.com/mmihaltz/huwn} A magyar nyelvű szövegek
lemmatizálását elvégezhetjük a szövegek R-be való beolvasása előtt is a
\texttt{magyarlánc}nyelvi elemző segítségével, melyről a kötet
függelékében, a Magyar nyelvű NLP és nyelvtechnológiai eszközök között
szólunk részletesebben.

\begin{Shaded}
\begin{Highlighting}[]

\NormalTok{text1 }\OtherTok{\textless{}{-}} \StringTok{"Példa az elokészítésre. Az elokészítést a szövetisztítással kell megkezdenünk. Az elokészített korpuszon elemzést végzünk"}

\NormalTok{toks1 }\OtherTok{\textless{}{-}} \FunctionTok{tokens}\NormalTok{(text1, }\AttributeTok{remove\_punct =} \ConstantTok{TRUE}\NormalTok{)}

\NormalTok{elokészítés }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"elokészítésre"}\NormalTok{, }\StringTok{"elokészítést"}\NormalTok{, }\StringTok{"elokészített"}\NormalTok{)}

\NormalTok{lemma }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\StringTok{"elokészítés"}\NormalTok{, }\FunctionTok{length}\NormalTok{(elokészítés))}

\NormalTok{toks1 }\OtherTok{\textless{}{-}} \FunctionTok{tokens\_replace}\NormalTok{(toks1, elokészítés, lemma, }\AttributeTok{valuetype =} \StringTok{"fixed"}\NormalTok{)}

\NormalTok{toks1}
\CommentTok{\#\textgreater{} Tokens consisting of 1 document.}
\CommentTok{\#\textgreater{} text1 :}
\CommentTok{\#\textgreater{}  [1] "Példa"             "az"                "elokészítés"      }
\CommentTok{\#\textgreater{}  [4] "Az"                "elokészítés"       "a"                }
\CommentTok{\#\textgreater{}  [7] "szövetisztítással" "kell"              "megkezdenünk"     }
\CommentTok{\#\textgreater{} [10] "Az"                "elokészítés"       "korpuszon"        }
\CommentTok{\#\textgreater{} [ ... and 2 more ]}
\end{Highlighting}
\end{Shaded}

\hypertarget{stemmeluxe9s}{%
\paragraph{Stemmelés}\label{stemmeluxe9s}}

A fenti \texttt{text1} objektumban tárolt szöveg stemmelését az alábbiak
szerint tudjuk elvégezni. Megvizsgálva az előkészítés különböző
alakjainak lemmatizált és stemmelt változatát jól láthatjuk a két
módszer közötti különbséget.

\begin{Shaded}
\begin{Highlighting}[]

\NormalTok{text1 }\OtherTok{\textless{}{-}} \StringTok{"Példa az elokészítésre. Az elokészítést a szövetisztítással kell megkezdenünk. Az elokészített korpuszon elemzést végzünk"}

\NormalTok{toks2 }\OtherTok{\textless{}{-}} \FunctionTok{tokens}\NormalTok{(text1, }\AttributeTok{remove\_punct =} \ConstantTok{TRUE}\NormalTok{)}

\NormalTok{toks2 }\OtherTok{\textless{}{-}} \FunctionTok{tokens\_wordstem}\NormalTok{(toks2)}

\NormalTok{toks2}
\CommentTok{\#\textgreater{} Tokens consisting of 1 document.}
\CommentTok{\#\textgreater{} text1 :}
\CommentTok{\#\textgreater{}  [1] "Példa"           "az"              "elokészítésr"    "Az"             }
\CommentTok{\#\textgreater{}  [5] "elokészítést"    "a"               "szövetisztításs" "kell"           }
\CommentTok{\#\textgreater{}  [9] "megkezdenünk"    "Az"              "elokészített"    "korpuszon"      }
\CommentTok{\#\textgreater{} [ ... and 2 more ]}
\end{Highlighting}
\end{Shaded}

\hypertarget{dokumentum-kifejezuxe9s-muxe1trix-dtm}{%
\subsection{Dokumentum kifejezés mátrix
(DTM)}\label{dokumentum-kifejezuxe9s-muxe1trix-dtm}}

A szövegbányászati elemzések nagy részéhez szükségünk van arra, hogy a
szövegeinkből dokumentum kifejezés matrix-ot (DTM), vagy dokumentum
feature matrxi-ot (DFM) hozzunk létre. Ezzel a lépéssel alkaítjuk a
szövegeinket számokká, ami lehetővé teszi, hogy utána különböző
staisztikai műveleteket végezzünk velük.

A dokumentumk kifejezés mátrix minden sora egy dokumentum, minden
oszlopa egy kifejezés, az oszlopokban szereplő változók pedig az egyes
kifejezések számát mutatják meg az egyes dokumnetumokban. A legtöbb DTM
ritka mátrix, mivel a legtöbb dokumentum és kifejezés párosítása nem
történik meg, mivel a kifejezések nagy része csak néhány dokumentumban
szerepel, ezek értéke nulla lesz.

Az alábbi példában három egy-egy mondatos dokumentumon szemléltetjük a
fentieket. A korábban megismert módon előkészítjük, azaz kisbetűsítjük,
stemmeljük és stopszavazzuk a dokumentumokat, majd létrehozzuk belőlük a
sokumentum kifejezés mátrixot.

\begin{Shaded}
\begin{Highlighting}[]

\NormalTok{text }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}
  \AttributeTok{d1 =} \StringTok{"Ez egy példa az elofeldolgozásra"}\NormalTok{,}
  \AttributeTok{d2 =} \StringTok{"Egy másik lehetséges példa"}\NormalTok{,}
  \AttributeTok{d3 =} \StringTok{"Ez pedig egy harmadik példa"}
\NormalTok{)}

\NormalTok{dtm }\OtherTok{\textless{}{-}} \FunctionTok{dfm}\NormalTok{(}
\NormalTok{  text,}
  \AttributeTok{tolower =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{stem =} \ConstantTok{TRUE}\NormalTok{,}
  \AttributeTok{remove =} \FunctionTok{stopwords}\NormalTok{(}\StringTok{"hungarian"}\NormalTok{)}
\NormalTok{)}

\NormalTok{dtm}
\CommentTok{\#\textgreater{} Document{-}feature matrix of: 3 documents, 4 features (50.0\% sparse).}
\CommentTok{\#\textgreater{}     features}
\CommentTok{\#\textgreater{} docs példa elofeldolgozásra lehetség harmadik}
\CommentTok{\#\textgreater{}   d1     1                1        0        0}
\CommentTok{\#\textgreater{}   d2     1                0        1        0}
\CommentTok{\#\textgreater{}   d3     1                0        0        1}
\end{Highlighting}
\end{Shaded}

Egy másik szövegbányáaszati megközelítés a mátrixot nem DTM-nek, hanem
DFM-nek nevezi, például a \texttt{quanteda} csomag használata során nem
DTM-et, hanem DFM-et kell létrehoznunk.

\begin{Shaded}
\begin{Highlighting}[]

\NormalTok{text }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}
  \AttributeTok{d1 =} \StringTok{"Ez egy példa az elofeldolgozásra"}\NormalTok{,}
  \AttributeTok{d2 =} \StringTok{"Egy másik lehetséges példa"}\NormalTok{,}
  \AttributeTok{d3 =} \StringTok{"Ez pedig egy harmadik példa"}
\NormalTok{)}

\NormalTok{dfm }\OtherTok{\textless{}{-}} \FunctionTok{dfm}\NormalTok{(}
\NormalTok{  text,}
  \AttributeTok{tolower =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{stem =} \ConstantTok{TRUE}\NormalTok{,}
  \AttributeTok{remove =} \FunctionTok{stopwords}\NormalTok{(}\StringTok{"hungarian"}\NormalTok{)}
\NormalTok{)}

\NormalTok{dfm}
\CommentTok{\#\textgreater{} Document{-}feature matrix of: 3 documents, 4 features (50.0\% sparse).}
\CommentTok{\#\textgreater{}     features}
\CommentTok{\#\textgreater{} docs példa elofeldolgozásra lehetség harmadik}
\CommentTok{\#\textgreater{}   d1     1                1        0        0}
\CommentTok{\#\textgreater{}   d2     1                0        1        0}
\CommentTok{\#\textgreater{}   d3     1                0        0        1}
\end{Highlighting}
\end{Shaded}

\hypertarget{suxfalyozuxe1s}{%
\subsection{Súlyozás}\label{suxfalyozuxe1s}}

A dokumentum kifejezés mátrix lehet egy egyszerű bináris mátrix, ami
csak azt az információt tartalmazza, hogy egy adott szó előfordul-e egy
adott dokumentumban. Míg az egyszerű bináris mátrixban ugyanakkora súlya
van egy szónak ha egyszer és ha tízszer szerepel, készíthetünk olyan
mátrixot is, ahol egy szónak annál nagyobb a súlya egy dokumentumban,
minél többször fordul elő. A szógyakoriság (term frequency, TM) szerint
súlyozott TD mátrixnál azt is figyelembe vesszük, hogy az adott szó hány
dokumentumban szerepel. Minél több dokumentumban szerepel egy szó, annál
kisebb a jelentősége. Ilyen szavak például a névelők, amelyek sok
dokumentumban előfordulnak ugyan, de nem sok tartalmi jelentőséggel
bírnak. Két szó közül általában az a fontosabb, amelyik koncentráltan,
kevés dokumentumban, de azokon belül nagy gyakorisággal fordul elő. A
dokumentum gyakorisági érték (document frequency, df) egy szó ritkaságát
jellemzi egy korpuszon belül, azaz megadja, hogy mekkora megkülönböztető
ereje van egy szónak a dokumentum tartalmára vonatkozóan. A súlyozási
sémákban általában a dokumentum gyakorisági érték inverzével számolnak
(inverse document frequency, idf) ez a leggyakrabban használt td-idf
súlyozás (term frequency \& inverse document frequency. Az így súlyozott
TD mátrix egy-egy cellájában található érték azt mutatja, hogy egy adott
szónak mekkora a jelentősége egy adott dokumentumban. A tf -idf súlyozás
értéke tehát magas azon szavak esetén, amelyek az adott dokumentumban
gyakran fordulnak elő, míg a teljes korpuszban ritkán, alacsonyabb azon
szavak esetén, amelyek az adott dokumentumban ritkábban, vagy a
korpuszban gyakrabban fordulnak elő és kicsi azon szavaknál, amelyek a
korpusz lényegében összes dokumentumában előfordulnak
(\protect\hyperlink{ref-Tikk2007:33-37}{\textbf{Tikk2007:33-37?}})

Az alábbiakban az 1999-es törvényszöveken szemlétetjük hogy egy 125
dokumentumból létrehozott mátrix segítségével milyen alapvető
statisztikai műveleteket végezhetünk.\footnote{Az itt használt kódok az
  alábbiakon alapulnak:
  \url{http://www.akosmate.com/QTA_SZISZ_2019/week03_descriptives_i/session3_r_script.html},
  \url{https://rdrr.io/cran/quanteda/man/dfm_weight.html},
  \url{https://rdrr.io/cran/quanteda/man/dfm_tfidf.html}}

Ehhez először importáljuk a törvények egy \texttt{.csv} kiterjesztésű
fájlból. A \texttt{read\_csv()} használatának az az előnye, hogy
alapbeállításként UTF-8 formátumban importálja be a szöveges oszlopokat.

\begin{Shaded}
\begin{Highlighting}[]

\NormalTok{lawtext\_df }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(}\StringTok{"data/lawtext\_1999.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Majd az importált fájlokból létrehozzuk a korpusz
\texttt{lawtext\_corpus} néven. Ezt követi a dokumnetum kifejezés mátrix
kialakítása (mivel a \texttt{quanteda} csomaggal dolgozunk, \texttt{dfm}
mátrixot hozunk létre), és ezzel egy lépésben, elvégezzük az alapvető
szövegtisztitó lépéseket is.

\begin{Shaded}
\begin{Highlighting}[]

\NormalTok{lawtext\_corpus }\OtherTok{\textless{}{-}} \FunctionTok{corpus}\NormalTok{(lawtext\_df)}

\NormalTok{lawtext\_dfm }\OtherTok{\textless{}{-}} \FunctionTok{dfm}\NormalTok{(}
\NormalTok{  lawtext\_corpus,}
  \AttributeTok{tolower =} \ConstantTok{TRUE}\NormalTok{,}
  \AttributeTok{remove =} \FunctionTok{stopwords}\NormalTok{(}\StringTok{"hungarian"}\NormalTok{),}
  \AttributeTok{stem =} \ConstantTok{TRUE}\NormalTok{,}
  \AttributeTok{remove\_punct =} \ConstantTok{TRUE}\NormalTok{,}
  \AttributeTok{remove\_symbols =} \ConstantTok{TRUE}\NormalTok{,}
  \AttributeTok{remove\_numbers =} \ConstantTok{TRUE}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

A \texttt{topfeatures} függvény segítségével megnézhetjük a mátrix
leggyakoribb szavait a függvény argumentumában a dokumnetum kifejezés
mátrix nevét és a kívánt kifejezésszámot megadva.

\begin{Shaded}
\begin{Highlighting}[]

\FunctionTok{topfeatures}\NormalTok{(lawtext\_dfm, }\DecValTok{15}\NormalTok{)}
\CommentTok{\#\textgreater{}       the        of  szerzodo        to         b        ha       and  kiadások }
\CommentTok{\#\textgreater{}      7902      5665      3619      3290      2831      2794      2712      2447 }
\CommentTok{\#\textgreater{}   törvéni        in következo  muködési        or       évi        is }
\CommentTok{\#\textgreater{}      2385      2253      2178      2038      2034      1908      1864}
\end{Highlighting}
\end{Shaded}

Mivel látható, hogy a szövegekben sok angol kifejezés is volt egy
következő lépcsőben, az angol stopszavakat is eltávolitjuk.

\begin{Shaded}
\begin{Highlighting}[]

\NormalTok{lawtext\_dfm\_2 }\OtherTok{\textless{}{-}} \FunctionTok{dfm}\NormalTok{(lawtext\_dfm, }\AttributeTok{remove =} \FunctionTok{stopwords}\NormalTok{(}\StringTok{"english"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

Majd ismét megnézzük a leggyakoribb 15 kifejezést.

\begin{Shaded}
\begin{Highlighting}[]

\FunctionTok{topfeatures}\NormalTok{(lawtext\_dfm\_2, }\DecValTok{15}\NormalTok{)}
\CommentTok{\#\textgreater{}      szerzodo             b            ha      kiadások       törvéni }
\CommentTok{\#\textgreater{}          3619          2831          2794          2447          2385 }
\CommentTok{\#\textgreater{}     következo      muködési           évi         állam             c }
\CommentTok{\#\textgreater{}          2178          2038          1908          1718          1713 }
\CommentTok{\#\textgreater{} meghatározott   költségveté      államban           lép           fél }
\CommentTok{\#\textgreater{}          1654          1637          1622          1616          1533}
\end{Highlighting}
\end{Shaded}

Ezután tf-idf súlyozású statisztikát készítünk, a dokumentum kifejezés
mátrix alapján. Ehhez először létrehozzuk a \texttt{lawtext\_tfidf} nevű
objektumot, majd a \texttt{textstat\_frequency} függvény segítségével,
és kilistázzuk annak első 10 elemét.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lawtext\_tfidf }\OtherTok{\textless{}{-}} \FunctionTok{dfm\_tfidf}\NormalTok{(lawtext\_dfm\_2)}

\FunctionTok{textstat\_frequency}\NormalTok{(lawtext\_tfidf, }\AttributeTok{force =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{n =} \DecValTok{10}\NormalTok{)}
\CommentTok{\#\textgreater{}         feature frequency rank docfreq group}
\CommentTok{\#\textgreater{} 1      kiadások 2120.2303    1      17   all}
\CommentTok{\#\textgreater{} 2  felhalmozási 1448.3465    2       7   all}
\CommentTok{\#\textgreater{} 3      szerzodo 1378.5012    3      52   all}
\CommentTok{\#\textgreater{} 4   költségveté 1302.8556    4      20   all}
\CommentTok{\#\textgreater{} 5         shall 1291.1619    5      14   all}
\CommentTok{\#\textgreater{} 6      államban 1223.7785    6      22   all}
\CommentTok{\#\textgreater{} 7        részes 1155.9688    7      13   all}
\CommentTok{\#\textgreater{} 8      muködési 1101.7581    8      36   all}
\CommentTok{\#\textgreater{} 9        articl  967.8961    9      14   all}
\CommentTok{\#\textgreater{} 10        parti  845.2246   10      20   all}
\end{Highlighting}
\end{Shaded}

\hypertarget{informuxe1ciuxf3-visszakeresuxe9s-uxe9s-informuxe1ciuxf3kinyeruxe9s-szuxf6vegek-reprezentuxe1luxe1sa-a-vektortuxe9rben-leuxedruxf3-statisztika}{%
\chapter{Információ-visszakeresés és információkinyerés, szövegek
reprezentálása a vektortérben, leíró
statisztika}\label{informuxe1ciuxf3-visszakeresuxe9s-uxe9s-informuxe1ciuxf3kinyeruxe9s-szuxf6vegek-reprezentuxe1luxe1sa-a-vektortuxe9rben-leuxedruxf3-statisztika}}

A szövegbányászati feladatok két altípusa a keresés és a rendszerezés. A
keresés során olyan szövegeket keresünk, amelyekben egy adott kifejezés
előfordul, a rendszerezés során pedig a szövegeket hasonlítjuk össze
egymással és egy előre megadott, vagy egy előzetesen nem ismert
kategóriarendszer csoportjaihoz soroljuk őket. Az
információ-visszakeresés (information retrieval), ami például a webes
keresőprogramok egyik jellemző tevékenysége, során a cél, hogy a
korpuszból visszakeressük a kereső információigénye szempontjából
releváns információkat, mely keresés alapulhat metaadatokon vagy teljes
szöveges indexelésen.
(\protect\hyperlink{ref-tikk2007:63}{\textbf{tikk2007:63?}};
\protect\hyperlink{ref-russel2005a:742}{\textbf{russel2005a:742?}}) Az
információkinyerés (information extraction) esetén a cél, hogy a
strukturálatlan szövegekből strukturált adatokat állítsunk elő. Azaz az
információkinyerés során nem a felhasználó által keresett információt
keressük meg és lokalizáljuk, hanem az adott kérdés szempontjából
releváns információkat gyűjtjük ki a dokumentumokból. aAz
információkinyerés alternatív megoldása segítségével már képesek
lehetünk a kifejezések közötti kapcsolatok elemzésére, tendenciák és
minták felismerésére és az információk összekapcsolás révén új
információk létrehozására. Azaz a segítségével strukturálatlan
szövegekből is előállíthatunk strukturált információkat
(\protect\hyperlink{ref-kwartler2017}{\textbf{kwartler2017?}};
\protect\hyperlink{ref-schuxfctze2008}{\textbf{schütze2008?}} ;
\protect\hyperlink{ref-tikk2007a:63-81}{\textbf{tikk2007a:63-81?}})

\hypertarget{a-szuxf6vegek-reprezentuxe1luxe1sa-a-vektortuxe9rben---szuxf3zsuxe1k-modell}{%
\section{A szövegek reprezentálása a vektortérben - szózsák
modell}\label{a-szuxf6vegek-reprezentuxe1luxe1sa-a-vektortuxe9rben---szuxf3zsuxe1k-modell}}

A szövegbányászati vizsgálatok során folyó szövegek, azaz
strukturálatlan vagy részben strukturált dokumentumok elemzésére kerül
sor, melyekből a kutatási kérdéseink szempontjából releváns, látens
összefüggéseket nyerünk ki, amelyek már strukturált szerkezetűek. A
dokumentumok reprezentálásnak három legelterjedtebb módja a
halmazelmélet alapú, az algebrai és a valószínűségi modell. A
halmazelméleti modellek a dokumentumok hasonlóságát halmazelmélet, a
valószínűségi modellek pedig feltételes valószínűségi becslés alapján
határozzák meg. Az algebrai modellek a dokumentumokat vektorként vagy
mátrixként ábrázolják és algebrai műveletek segítségével hasonlítják
össze. A vektortérmodell sokdimenziós vektortérben ábrázolja a
dokumentumokat, úgy hogy a dokumentumokat vektorokkal reprezentálja, a
vektortér dimenziói pedig a dokumentumok összességében előforduló egyedi
szavak. A modell alkalmazása során azok a dokumentumok hasonlítanak
egymásra, amelyeknek a szókészlete átfedi egymást, és a hasonlóság
mértéke az átfedéssel arányos. A vektortérmodellben a
dokumentumgyűjteményt a szó-dokumentum mátrixszal (term-document matrix)
reprezentáljuk, a mátrixban a sorok száma megegyezik az egyedi szavak
számával, az oszlopokat pedig a dokumentumvektorok alkotják. Az egyedi
szavak összességét szórátnak nevezzük. Mivel mátrixban az egyedi szavak
száma általában igen nagy, ezért a mátrix hatékony kezeléséhez annak
mérte különböző eljárásokkal csökkenthető. Fontos tudni, hogy a
dokumentumok vektortér reprezentációjában a szavak szövegen belüli
sorrendjére és pozíciójára vonatkozó információ nem található meg.
(\protect\hyperlink{ref-russel2005b:742-744}{\textbf{russel2005b:742-744?}};
\protect\hyperlink{ref-kwartler2017:20}{\textbf{kwartler2017:20?}};
\protect\hyperlink{ref-welbers2017}{\textbf{welbers2017?}}) A
vektortérmodellt szózsák (bag of words) modellnek is nevezzük, melynek
segítségével a fent leírtak szerint az egyes szavak gyakoriságát
vizsgálhatjuk meg egy adott korpuszon belül.

A szó-dokumentum mátrix lehet egy egyszerű bináris mátrix, ami csak azt
az információt tartalmazza, hogy egy adott szó előfordul-e egy adott
dokumentumban. Míg az egyszerű bináris mátrixban ugyanakkora súlya van
egy szónak ha egyszer és ha tízszer szerepel, készíthetünk olyan
mátrixot is, ahol egy szónak annál nagyobb a súlya egy dokumentumban,
minél többször fordul elő. Emellett a mártixot a dokumentumok hossza
szerint is normálhatjuk. Az így súlyozott mátrixban nem azt vizsgáljuk,
hogy egy szó hányszor egy dokumentumban, hanem ezt a számot viszonyítjuk
az adott dokumentum szavainak a számához. A szógyakoriság (term
frequency, TM) szerint súlyozott TD mátrixnál azt is figyelembe vesszük,
hogy az adott szó hány dokumentumban szerepel. Minél több dokumentumban
szerepel egy szó, annál kisebb a jelentősége. Ilyen szavak például a
névelők, amelyek sok dokumentumban előfordulnak ugyan, de nem sok
tartalmi jelentőséggel bírnak. Két szó közül általában az a fontosabb,
amelyik koncentráltan, kevés dokumentumban, de azokon belül nagy
gyakorisággal fordul elő. A dokumentum gyakorisági érték (document
frequency, df) egy szó ritkaságát jellemzi egy korpuszon belül, azaz
megadja, hogy mekkora megkülönböztető ereje van egy szónak a dokumentum
tartalmára vonatkozóan. A súlyozási sémákban általában a dokumentum
gyakorisági érték inverzével számolnak (inverse document frequency, idf)
ez a leggyakrabban használt td-idf súlyozás (term frequency \& inverse
document frequency. Az így súlyozott TD mátrix egy-egy cellájában
található érték azt mutatja, hogy egy adott szónak mekkora a jelentősége
egy adott dokumentumban. A tf -idf súlyozás értéke tehát magas azon
szavak esetén, amelyek az adott dokumentumban gyakran fordulnak elő, míg
a teljes korpuszban ritkán, alacsonyabb azon szavak esetén, amelyek az
adott dokumentumban ritkábban, vagy a korpuszban gyakrabban fordulnak
elő és kicsi azon szavaknál, amelyek a korpusz lényegében összes
dokumentumában előfordulnak
(\protect\hyperlink{ref-tikk2007:33-37}{\textbf{tikk2007:33-37?}};
\protect\hyperlink{ref-grimmer2013}{\textbf{grimmer2013?}};
\protect\hyperlink{ref-welbers2017}{\textbf{welbers2017?}})

\hypertarget{leuxedruxf3-statisztika}{%
\section{Leíró statisztika}\label{leuxedruxf3-statisztika}}

Fejezetünkben nyolc véletlenszerűen kiválasztott magyar miniszterelnöki
beszéd vizsgálatát végezzük el, amihez az alábbi csomagokat használjuk:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(readtext)}
\FunctionTok{library}\NormalTok{(dplyr)}
\FunctionTok{library}\NormalTok{(lubridate)}
\FunctionTok{library}\NormalTok{(stringr)}
\FunctionTok{library}\NormalTok{(ggplot2)}
\FunctionTok{library}\NormalTok{(quanteda)}
\FunctionTok{library}\NormalTok{(GGally)}
\FunctionTok{library}\NormalTok{(tidytext)}
\FunctionTok{library}\NormalTok{(tidyverse)}
\end{Highlighting}
\end{Shaded}

Első lépésben a már ismertetett módon a \texttt{readtext\ ()}
segítségével beolvassuk a beszédek txt formátumú változatát, utf-8
karakterkódolással.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{texts }\OtherTok{\textless{}{-}} \FunctionTok{readtext}\NormalTok{(}\StringTok{"data/mineln/*.txt"}\NormalTok{, }\AttributeTok{encoding =} \StringTok{"UTF{-}8"}\NormalTok{)}
\FunctionTok{head}\NormalTok{(texts)}
\CommentTok{\#\textgreater{} readtext object consisting of 6 documents and 0 docvars.}
\CommentTok{\#\textgreater{} \# Description: df[,2] [6 x 2]}
\CommentTok{\#\textgreater{}   doc\_id                    text               }
\CommentTok{\#\textgreater{} * \textless{}chr\textgreater{}                     \textless{}chr\textgreater{}              }
\CommentTok{\#\textgreater{} 1 antall\_jozsef\_1990.txt    "\textbackslash{}"Elnök Úr! \textbackslash{}"..."}
\CommentTok{\#\textgreater{} 2 bajnai\_gordon\_2009.txt    "\textbackslash{}"Tisztelt E\textbackslash{}"..."}
\CommentTok{\#\textgreater{} 3 boross\_peter\_1993.txt     "\textbackslash{}"Elnök Úr! \textbackslash{}"..."}
\CommentTok{\#\textgreater{} 4 gyurcsany\_ferenc\_2005.txt "\textbackslash{}"Mélyen tis\textbackslash{}"..."}
\CommentTok{\#\textgreater{} 5 horn\_gyula\_1994.txt       "\textbackslash{}"Köszönöm, \textbackslash{}"..."}
\CommentTok{\#\textgreater{} 6 medgyessy\_peter\_2002.txt  "\textbackslash{}"Mélyen tis\textbackslash{}"..."}
\end{Highlighting}
\end{Shaded}

Ezt követően az ``Adarkezelés R-ben'' fejezetben ismertetett
\texttt{mutate()} függvény használazával két csoportra osztjuk a
beszédeket. Ehhez először a \texttt{string\_extract()}segítségével
meghatározzuk, hogy a kettéosztáshoz hasznáni kívánt új változó a
doc\_id legyen a \texttt{{[}\^{}\textbackslash{}\textbackslash{}.{]}*}
regex segítségével leválasztva arról a \texttt{.txt} kiterjesztést, majd
a \texttt{str\_sub()} függvénnyel megmondjuk, hogy a miniszterelnökök
neve a \texttt{doc\_id} háturló számított hatodik karakteréig tart.
Ezután kialakítjuk a két csoportot, azaz az \texttt{if\_else()}
segítségével meghatározzuk, hogy ha ``antall\_jozsef,''
``boross\_peter,'' ``orban\_viktor'' beszédeiről van szó azokat a jobb
csoportba tegye, a maradékot pedig a bal csoportba.

Ezt követően azt is meghatározzuk, hogy melyik beszédnek mi a dátuma.
Ehhez szintén a \texttt{str\_sub()} függvényt használjuk, majd a
lubridate segítségével alakítjuk ki a kívánt dátumformátumot\footnote{A
  mintába nem került be Rogán Antal, akinek csak egy darab napirend
  előtti felszólalása volt.}.

Majd a \texttt{glimpse()} függvény segítsével megtekintjük, hogy milyen
változtatásokat végeztünk az adattáblánkon. Láthatjuk, hogy míg korábban
8 dokumentumunk és 2 változónk volt, az átalakítás eredményeként a 8
dokumentum mellett már 5 változót találunk. Ezzel a lépéssel tehát
kialakítottuk azokat a változókat, amelyekre az elemzés során szükségünk
lesz.

\begin{Shaded}
\begin{Highlighting}[]

\NormalTok{texts }\OtherTok{\textless{}{-}}\NormalTok{ texts }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{mutate}\NormalTok{(}\AttributeTok{doc\_id =} \FunctionTok{str\_extract}\NormalTok{(doc\_id, }\StringTok{"[\^{}}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{.]*"}\NormalTok{), }\AttributeTok{mineln =} \FunctionTok{str\_sub}\NormalTok{(doc\_id, }
    \AttributeTok{end =} \SpecialCharTok{{-}}\DecValTok{6}\NormalTok{), }\AttributeTok{wing =} \FunctionTok{if\_else}\NormalTok{(mineln }\SpecialCharTok{\%in\%} \FunctionTok{c}\NormalTok{(}\StringTok{"antall\_jozsef"}\NormalTok{, }\StringTok{"boross\_peter"}\NormalTok{, }\StringTok{"orban\_viktor"}\NormalTok{), }
    \StringTok{"jobb"}\NormalTok{, }\StringTok{"bal"}\NormalTok{))}

\NormalTok{texts}\SpecialCharTok{$}\NormalTok{year }\OtherTok{\textless{}{-}} \FunctionTok{str\_sub}\NormalTok{(texts}\SpecialCharTok{$}\NormalTok{doc\_id, }\AttributeTok{start =} \SpecialCharTok{{-}}\DecValTok{2}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{str\_c}\NormalTok{(}\StringTok{"{-}01{-}01"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{ lubridate}\SpecialCharTok{::}\FunctionTok{ymd}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} 
\NormalTok{    lubridate}\SpecialCharTok{::}\FunctionTok{year}\NormalTok{()}

\FunctionTok{glimpse}\NormalTok{(texts)}
\CommentTok{\#\textgreater{} Rows: 8}
\CommentTok{\#\textgreater{} Columns: 5}
\CommentTok{\#\textgreater{} $ doc\_id \textless{}chr\textgreater{} "antall\_jozsef\_1990", "bajnai\_gordon\_2009", "boross\_peter\_19...}
\CommentTok{\#\textgreater{} $ text   \textless{}chr\textgreater{} "Elnök Úr! Tisztelt Országgyulés! Hölgyeim és Uraim! Honfitá...}
\CommentTok{\#\textgreater{} $ mineln \textless{}chr\textgreater{} "antall\_jozsef", "bajnai\_gordon", "boross\_peter", "gyurcsany...}
\CommentTok{\#\textgreater{} $ wing   \textless{}chr\textgreater{} "jobb", "bal", "jobb", "bal", "bal", "bal", "jobb", "jobb"}
\CommentTok{\#\textgreater{} $ year   \textless{}dbl\textgreater{} 1990, 2009, 1993, 2005, 1994, 2002, 1995, 2018}
\end{Highlighting}
\end{Shaded}

Ezt követően a további lépések elvégzéséhez létrehozzuk a
\texttt{quanteda} korpuszt, majd a \texttt{summary()} függvény
segítségével megtekinthetjük a korpusz alaovető satisztikai jellemzőit,
láthatjuk például, hogy az egyes dokumentumok hány tokenből vagy
mondatból állnak.

\begin{Shaded}
\begin{Highlighting}[]

\NormalTok{corpus\_mineln }\OtherTok{\textless{}{-}} \FunctionTok{corpus}\NormalTok{(texts)}

\FunctionTok{summary}\NormalTok{(corpus\_mineln)}
\CommentTok{\#\textgreater{} Corpus consisting of 8 documents, showing 8 documents:}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}                   Text Types Tokens Sentences           mineln wing year}
\CommentTok{\#\textgreater{}     antall\_jozsef\_1990  3745   9408       431    antall\_jozsef jobb 1990}
\CommentTok{\#\textgreater{}     bajnai\_gordon\_2009  1391   3277       201    bajnai\_gordon  bal 2009}
\CommentTok{\#\textgreater{}      boross\_peter\_1993  1552   3170       179     boross\_peter jobb 1993}
\CommentTok{\#\textgreater{}  gyurcsany\_ferenc\_2005  2963  10267       454 gyurcsany\_ferenc  bal 2005}
\CommentTok{\#\textgreater{}        horn\_gyula\_1994  1704   4372       226       horn\_gyula  bal 1994}
\CommentTok{\#\textgreater{}   medgyessy\_peter\_2002  1021   2362        82  medgyessy\_peter  bal 2002}
\CommentTok{\#\textgreater{}      orban\_viktor\_1995  1810   4287       212     orban\_viktor jobb 1995}
\CommentTok{\#\textgreater{}      orban\_viktor\_2018   933   1976       126     orban\_viktor jobb 2018}
\end{Highlighting}
\end{Shaded}

Mivel az elemzés során a korpuszon belül két csoportra osztva szeretnénk
összehasonlításokat tenni, az alábbiakban két alkorpuszt alakítunk ki.

\begin{Shaded}
\begin{Highlighting}[]

\NormalTok{mineln\_jobb }\OtherTok{\textless{}{-}} \FunctionTok{corpus\_subset}\NormalTok{(corpus\_mineln, mineln }\SpecialCharTok{\%in\%} \FunctionTok{c}\NormalTok{(}\StringTok{"antall\_jozsef"}\NormalTok{, }\StringTok{"boross\_peter"}\NormalTok{, }
    \StringTok{"orban\_viktor"}\NormalTok{))}

\NormalTok{mineln\_bal }\OtherTok{\textless{}{-}} \FunctionTok{corpus\_subset}\NormalTok{(corpus\_mineln, mineln }\SpecialCharTok{\%in\%} \FunctionTok{c}\NormalTok{(}\StringTok{"horn\_gyula"}\NormalTok{, }\StringTok{"gyurcsany\_ferenc"}\NormalTok{, }
    \StringTok{"medgyessy\_peter"}\NormalTok{, }\StringTok{"bajnai\_gordon"}\NormalTok{))}

\FunctionTok{summary}\NormalTok{(mineln\_jobb)}
\CommentTok{\#\textgreater{} Corpus consisting of 4 documents, showing 4 documents:}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}                Text Types Tokens Sentences        mineln wing year}
\CommentTok{\#\textgreater{}  antall\_jozsef\_1990  3745   9408       431 antall\_jozsef jobb 1990}
\CommentTok{\#\textgreater{}   boross\_peter\_1993  1552   3170       179  boross\_peter jobb 1993}
\CommentTok{\#\textgreater{}   orban\_viktor\_1995  1810   4287       212  orban\_viktor jobb 1995}
\CommentTok{\#\textgreater{}   orban\_viktor\_2018   933   1976       126  orban\_viktor jobb 2018}

\FunctionTok{summary}\NormalTok{(mineln\_bal)}
\CommentTok{\#\textgreater{} Corpus consisting of 4 documents, showing 4 documents:}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}                   Text Types Tokens Sentences           mineln wing year}
\CommentTok{\#\textgreater{}     bajnai\_gordon\_2009  1391   3277       201    bajnai\_gordon  bal 2009}
\CommentTok{\#\textgreater{}  gyurcsany\_ferenc\_2005  2963  10267       454 gyurcsany\_ferenc  bal 2005}
\CommentTok{\#\textgreater{}        horn\_gyula\_1994  1704   4372       226       horn\_gyula  bal 1994}
\CommentTok{\#\textgreater{}   medgyessy\_peter\_2002  1021   2362        82  medgyessy\_peter  bal 2002}
\end{Highlighting}
\end{Shaded}

A korábban létrehozott ``jobb'' és ``bal'' változó segítségével nem csak
az egyes dokumentumokat, hanem a két csoportba sorolt beszédket is
összehaonlíthatjuk egymással.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(corpus\_mineln) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(wing) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarise}\NormalTok{(}\AttributeTok{mean\_wordcount =} \FunctionTok{mean}\NormalTok{(Tokens), }\AttributeTok{std\_dev =} \FunctionTok{sd}\NormalTok{(Tokens), }\AttributeTok{min\_wordc =} \FunctionTok{min}\NormalTok{(Tokens), }\AttributeTok{max\_wordc =} \FunctionTok{max}\NormalTok{(Tokens))}
\CommentTok{\#\textgreater{} \# A tibble: 2 x 5}
\CommentTok{\#\textgreater{}   wing  mean\_wordcount std\_dev min\_wordc max\_wordc}
\CommentTok{\#\textgreater{}   \textless{}chr\textgreater{}          \textless{}dbl\textgreater{}   \textless{}dbl\textgreater{}     \textless{}int\textgreater{}     \textless{}int\textgreater{}}
\CommentTok{\#\textgreater{} 1 bal            5070.   3561.      2362     10267}
\CommentTok{\#\textgreater{} 2 jobb           4710.   3271.      1976      9408}
\end{Highlighting}
\end{Shaded}

A \texttt{textstat\_collocations()} függvény segítségével együtt
előforduló szókapcsolatokat kereshetünk. A függvény argumentumai közül a
\texttt{size} a szókapcsolatok hossza, a \texttt{min\_count} pedig a
minimális előfordulásuk száma. Miután a szókapcsolatokat megkeresük a
korábban már megismert \texttt{head()} függvény segítségével
megnézhetünk közülük tetszőleges számút\footnote{A
  \texttt{quanteda.textplots} csomag több megoldást is kínál az ábrák
  elkészítésére. Mivel ezek a megoldások kifejezetten a quanteda
  elemzések ábrázolására készültek, ezért rövid egysoros függvényekkel
  tudunk gyorsan ábrákat készíteni. A hátrányuk, hogy kevésbé tudjuk
  ``személyre szabni'' az ábráinkat, mint a \texttt{ggplot2} példák
  esetében. A \texttt{quanteda.textplots} megoldásokat ezen a linken
  demonstrálják a csomag készítői:
  \url{https://quanteda.io/articles/pkgdown/examples/plotting.html}}.

\begin{Shaded}
\begin{Highlighting}[]

\NormalTok{corpus\_mineln }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{textstat\_collocations}\NormalTok{(}
    \AttributeTok{size =} \DecValTok{3}\NormalTok{,}
    \AttributeTok{min\_count =} \DecValTok{6}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{head}\NormalTok{(}\AttributeTok{n =} \DecValTok{10}\NormalTok{)}
\CommentTok{\#\textgreater{}             collocation count count\_nested length    lambda         z}
\CommentTok{\#\textgreater{} 1           a kormány a    30            0      3 1.7266498 3.5500939}
\CommentTok{\#\textgreater{} 2         az új kormány    13            0      3 4.7126130 2.9870558}
\CommentTok{\#\textgreater{} 3         az a politika     6            0      3 3.9239765 2.4659912}
\CommentTok{\#\textgreater{} 4          a kormány az     6            0      3 2.6826277 1.7954739}
\CommentTok{\#\textgreater{} 5          a száz lépés     9            0      3 3.5817972 1.5956086}
\CommentTok{\#\textgreater{} 6     a magyar gazdaság    14            0      3 2.5135668 1.5757358}
\CommentTok{\#\textgreater{} 7          ez a program     9            0      3 1.9371894 1.2837433}
\CommentTok{\#\textgreater{} 8  tisztelt hölgyeim és    31            0      3 2.2327116 0.9596371}
\CommentTok{\#\textgreater{} 9             hogy ez a    10            0      3 0.4617372 0.9032165}
\CommentTok{\#\textgreater{} 10        hogy a magyar    18            0      3 0.6903168 0.7832561}
\end{Highlighting}
\end{Shaded}

A szókapcsolatok listázásánál is láthattuk, hogy a korpuszunk még minden
szót tartalmaz, ezért találtunk például ``hogy ez a'' összetételt. A
következőkben eltávolítjuk az ilyen funkció nélküli stopszavakat a
korpuszból, amihez saját stopszólistát használunk. Először beolvassuk és
egy \texttt{custom\_stopwords} nevű objektumban tároljuk a stopszavakat,
majd a \texttt{tokens()} függvény segítségével tokenizáljuk a korpuszt
és a \texttt{tokens\_select()} használatával eltávolítjuk a
stopszavakat.

Ha ezután újra megnézzük a kollokációkat, jól látható a stopszavak
eltávolításának eredménye:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{custom\_stopwords }\OtherTok{\textless{}{-}} \FunctionTok{readLines}\NormalTok{(}\StringTok{"data/stopwords.txt"}\NormalTok{, }\AttributeTok{encoding =} \StringTok{"UTF{-}8"}\NormalTok{)}

\NormalTok{corpus\_mineln }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{tokens}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{tokens\_select}\NormalTok{(}\AttributeTok{pattern =}\NormalTok{ custom\_stopwords, }\AttributeTok{selection =} \StringTok{"remove"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{textstat\_collocations}\NormalTok{(}
    \AttributeTok{size =} \DecValTok{3}\NormalTok{,}
    \AttributeTok{min\_count =} \DecValTok{6}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{head}\NormalTok{(}\AttributeTok{n =} \DecValTok{10}\NormalTok{)}
\CommentTok{\#\textgreater{}                   collocation count count\_nested length    lambda         z}
\CommentTok{\#\textgreater{} 1          taps MSZP soraiból     7            0      3 {-}1.848559 {-}1.003837}
\CommentTok{\#\textgreater{} 2     tisztelt hölgyeim uraim    31            0      3 {-}3.217896 {-}1.087495}
\CommentTok{\#\textgreater{} 3 taps kormánypártok soraiban    13            0      3 {-}1.884367 {-}1.102199}
\CommentTok{\#\textgreater{} 4 közbeszólás fidesz soraiból    12            0      3 {-}4.371498 {-}1.949939}
\CommentTok{\#\textgreater{} 5          taps MSZP soraiban     9            0      3 {-}4.711439 {-}2.780059}
\end{Highlighting}
\end{Shaded}

A korpuszon további elemzése előtt fontos, hogy ne csak a stopszavakat
távolítsuk el, hanem az egyéb alapvető szövegtisztító lépéseket is
elvégezzük. Azaz a \texttt{tokens\_select()} segítségével eltávolítsuk a
számokat, a központozást, az elválasztó karaktereket, mint például a
szóközöket, tabulátorokat, sortöréseket. Ezután a
\texttt{tokens\_ngrams()} segítségével \texttt{ngarm}-okat hozunk létre
a tokenekből, majd kialakítjuk a dokumentumk kifejezés mátrixot
(\texttt{dfm}) és elvégezzük a \texttt{tf-idf} szerinti súlyozást. A
\texttt{dfm\_tfidf()}függvény kiszámolja a dokumentum gyakoriság inzverz
súlyozását. A függvény alapértelmezés szerint a normalizált kifejezések
gyakoriságát használja a dokumentumon belüli relatív kifejezés
gyakoriság helyett, ezt írjuk felül a \texttt{schem\_\_tf\ =\ "prop"}
használatával. Végül a \texttt{textstat\_frequency()} segítségével
gyakorisági statisztikát készíthetünk a korábban meghatározott
(példánkban két és három tagú) \texttt{ngram}-okról.

\begin{Shaded}
\begin{Highlighting}[]

\NormalTok{corpus\_mineln }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{tokens}\NormalTok{(}
    \AttributeTok{remove\_numbers =} \ConstantTok{TRUE}\NormalTok{, }
    \AttributeTok{remove\_punct =} \ConstantTok{TRUE}\NormalTok{, }
    \AttributeTok{remove\_separators =} \ConstantTok{TRUE}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{tokens\_select}\NormalTok{(}\AttributeTok{pattern =}\NormalTok{ custom\_stopwords, }\AttributeTok{selection =} \StringTok{"remove"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{tokens\_ngrams}\NormalTok{(}\AttributeTok{n =} \DecValTok{2}\SpecialCharTok{:}\DecValTok{3}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{dfm}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{dfm\_tfidf}\NormalTok{(}\AttributeTok{scheme\_tf =} \StringTok{"prop"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{textstat\_frequency}\NormalTok{(}\AttributeTok{n =} \DecValTok{10}\NormalTok{, }\AttributeTok{force =} \ConstantTok{TRUE}\NormalTok{)}
\CommentTok{\#\textgreater{}                        feature   frequency rank docfreq group}
\CommentTok{\#\textgreater{} 1            tisztelt\_hölgyeim 0.002788904    1       4   all}
\CommentTok{\#\textgreater{} 2      tisztelt\_hölgyeim\_uraim 0.002788904    1       4   all}
\CommentTok{\#\textgreater{} 3            fordítsanak\_hátat 0.002439685    3       1   all}
\CommentTok{\#\textgreater{} 4              fidesz\_soraiból 0.002151922    4       1   all}
\CommentTok{\#\textgreater{} 5                    taps\_mszp 0.001757918    5       2   all}
\CommentTok{\#\textgreater{} 6          magyarország\_európa 0.001457380    6       1   all}
\CommentTok{\#\textgreater{} 7    tisztelt\_képviselotársaim 0.001439932    7       2   all}
\CommentTok{\#\textgreater{} 8       kormánypártok\_soraiban 0.001430247    8       2   all}
\CommentTok{\#\textgreater{} 9           taps\_kormánypártok 0.001293617    9       2   all}
\CommentTok{\#\textgreater{} 10 taps\_kormánypártok\_soraiban 0.001293617    9       2   all}
\end{Highlighting}
\end{Shaded}

\hypertarget{a-szuxf6vegek-lexikai-diverzituxe1sa}{%
\section{A szövegek lexikai
diverzitása}\label{a-szuxf6vegek-lexikai-diverzituxe1sa}}

Az alábbiakban a korpuszunkat alkotó szövegek lexikai diverzitásat
vizsgáljuk. Ehhez a \texttt{quanteda} csomag
\texttt{textstat\_lexdiv()}függvényét használjuk. Mivel ez a függvény
\texttt{dfm}-et elemez, először a \texttt{corpus\_mineln} nevű
korpuszunkból létrehozzuk a \texttt{mineln\_dfm} nevű \texttt{dfm}-et,
amelyen elvégezzük a korábban már megismert alapvető tisztító lépéseket.
A \texttt{textstat\_lexdiv()} függvény eredménye szintén egy
\texttt{dfm}, így azt \texttt{arrange()}parancs argumentumában a
\texttt{desc} megadásával csökkenő sorba is rendezhetjük.
A\texttt{textstat\_lexdiv()} különböző indexek segítségével számítja ki
a szövegek lexikai különbözöségét, példánkban a \texttt{CTTR} indexet
használjuk\footnote{Azért nem a Vona Gábor beszédét választottuk, mert
  az gyaníthatóan egy kiugró érték ami nem reprezentálja a sokaságot
  megfelően.}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mineln\_dfm }\OtherTok{\textless{}{-}}\NormalTok{ corpus\_mineln }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{tokens}\NormalTok{(}\AttributeTok{remove\_punct =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{remove\_separators =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{remove\_hyphens =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{dfm}\NormalTok{(}\AttributeTok{remove =}\NormalTok{ custom\_stopwords)}

\NormalTok{mineln\_dfm }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{textstat\_lexdiv}\NormalTok{(}\AttributeTok{measure =} \StringTok{"CTTR"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{arrange}\NormalTok{(}\FunctionTok{desc}\NormalTok{(CTTR))}
\CommentTok{\#\textgreater{}                document     CTTR}
\CommentTok{\#\textgreater{} 1    antall\_jozsef\_1990 32.99078}
\CommentTok{\#\textgreater{} 2 gyurcsany\_ferenc\_2005 26.14422}
\CommentTok{\#\textgreater{} 3     orban\_viktor\_1995 23.35548}
\CommentTok{\#\textgreater{} 4       horn\_gyula\_1994 22.25547}
\CommentTok{\#\textgreater{} 5     boross\_peter\_1993 21.98656}
\CommentTok{\#\textgreater{} 6    bajnai\_gordon\_2009 19.93214}
\CommentTok{\#\textgreater{} 7  medgyessy\_peter\_2002 16.81246}
\CommentTok{\#\textgreater{} 8     orban\_viktor\_2018 16.24532}
\end{Highlighting}
\end{Shaded}

A kiszámolt értéket hozzáadhatjuk a \texttt{dfm}-hez is.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dfm\_lexdiv }\OtherTok{\textless{}{-}}\NormalTok{ mineln\_dfm}

\NormalTok{cttr\_score }\OtherTok{\textless{}{-}} \FunctionTok{unlist}\NormalTok{(}\FunctionTok{textstat\_lexdiv}\NormalTok{(dfm\_lexdiv, }\AttributeTok{measure =} \StringTok{"CTTR"}\NormalTok{)[, }\DecValTok{2}\NormalTok{])}

\FunctionTok{docvars}\NormalTok{(dfm\_lexdiv, }\StringTok{"cttr"}\NormalTok{) }\OtherTok{\textless{}{-}}\NormalTok{ cttr\_score}

\FunctionTok{docvars}\NormalTok{(dfm\_lexdiv)}
\CommentTok{\#\textgreater{}             mineln wing year     cttr}
\CommentTok{\#\textgreater{} 1    antall\_jozsef jobb 1990 32.99078}
\CommentTok{\#\textgreater{} 2    bajnai\_gordon  bal 2009 19.93214}
\CommentTok{\#\textgreater{} 3     boross\_peter jobb 1993 21.98656}
\CommentTok{\#\textgreater{} 4 gyurcsany\_ferenc  bal 2005 26.14422}
\CommentTok{\#\textgreater{} 5       horn\_gyula  bal 1994 22.25547}
\CommentTok{\#\textgreater{} 6  medgyessy\_peter  bal 2002 16.81246}
\CommentTok{\#\textgreater{} 7     orban\_viktor jobb 1995 23.35548}
\CommentTok{\#\textgreater{} 8     orban\_viktor jobb 2018 16.24532}
\end{Highlighting}
\end{Shaded}

A fenti elemzést elvégezhetjük úgy is, hogy valamennyi indexálást egyben
megkapjuk. Ehhez a \texttt{textstat\_lexdiv()} függvény argumentumába a
\texttt{measure\ =\ "all"} kifejezést kell megadnunk.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mineln\_dfm }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{textstat\_lexdiv}\NormalTok{(}\AttributeTok{measure =} \StringTok{"all"}\NormalTok{)}
\CommentTok{\#\textgreater{}                document       TTR         C        R     CTTR        U}
\CommentTok{\#\textgreater{} 1    antall\_jozsef\_1990 0.6465054 0.9490329 46.65601 32.99078 72.92298}
\CommentTok{\#\textgreater{} 2    bajnai\_gordon\_2009 0.7283044 0.9566410 28.18830 19.93214 73.23764}
\CommentTok{\#\textgreater{} 3     boross\_peter\_1993 0.7209677 0.9565427 31.09369 21.98656 75.23509}
\CommentTok{\#\textgreater{} 4 gyurcsany\_ferenc\_2005 0.5563859 0.9301449 36.97351 26.14422 52.17985}
\CommentTok{\#\textgreater{} 5       horn\_gyula\_1994 0.7142122 0.9555469 31.47399 22.25547 73.97126}
\CommentTok{\#\textgreater{} 6  medgyessy\_peter\_2002 0.7110912 0.9514261 23.77641 16.81246 62.75886}
\CommentTok{\#\textgreater{} 7     orban\_viktor\_1995 0.7224880 0.9574810 33.02964 23.35548 78.08616}
\CommentTok{\#\textgreater{} 8     orban\_viktor\_2018 0.7529538 0.9584932 22.97435 16.24532 71.52920}
\CommentTok{\#\textgreater{}           S        K        I            D         Vm      Maas      lgV0}
\CommentTok{\#\textgreater{} 1 0.9601534 11.21473 419.0858 0.0009296389 0.02871363 0.1171029 11.191310}
\CommentTok{\#\textgreater{} 2 0.9616371 16.40817 459.3906 0.0009739104 0.02691146 0.1168511 10.429595}
\CommentTok{\#\textgreater{} 3 0.9624951 18.51659 355.0407 0.0013147316 0.03325578 0.1152895 10.725349}
\CommentTok{\#\textgreater{} 4 0.9440104 11.86397 291.9314 0.0009601654 0.02791768 0.1384359  9.233313}
\CommentTok{\#\textgreater{} 5 0.9618001 12.60022 571.6996 0.0007454724 0.02321726 0.1162702 10.656921}
\CommentTok{\#\textgreater{} 6 0.9553276 26.48161 251.3022 0.0017552766 0.03728672 0.1262300  9.420533}
\CommentTok{\#\textgreater{} 7 0.9637924 16.50145 400.1580 0.0011722374 0.03143078 0.1131652 11.019123}
\CommentTok{\#\textgreater{} 8 0.9610435 26.17792 313.3935 0.0015453380 0.03451461 0.1182383  9.980932}
\CommentTok{\#\textgreater{}      lgeV0}
\CommentTok{\#\textgreater{} 1 25.76894}
\CommentTok{\#\textgreater{} 2 24.01503}
\CommentTok{\#\textgreater{} 3 24.69603}
\CommentTok{\#\textgreater{} 4 21.26049}
\CommentTok{\#\textgreater{} 5 24.53847}
\CommentTok{\#\textgreater{} 6 21.69158}
\CommentTok{\#\textgreater{} 7 25.37247}
\CommentTok{\#\textgreater{} 8 22.98195}
\end{Highlighting}
\end{Shaded}

Ha pedig arra vagyunk kíváncsiak, hogy a kapott értékek hogyan
viszonyulanak egymáshoz, azt a \texttt{cor()} függvény segítésével
számolhatjuk ki.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{div\_df }\OtherTok{\textless{}{-}}\NormalTok{ mineln\_dfm }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{textstat\_lexdiv}\NormalTok{(}\AttributeTok{measure =} \StringTok{"all"}\NormalTok{)}


\FunctionTok{cor}\NormalTok{(div\_df[, }\DecValTok{2}\SpecialCharTok{:}\DecValTok{13}\NormalTok{])}
\CommentTok{\#\textgreater{}             TTR          C           R        CTTR           U           S}
\CommentTok{\#\textgreater{} TTR   1.0000000  0.9709934 {-}0.64927227 {-}0.64927227  0.75866675  0.85148414}
\CommentTok{\#\textgreater{} C     0.9709934  1.0000000 {-}0.44988787 {-}0.44988787  0.88841537  0.95162677}
\CommentTok{\#\textgreater{} R    {-}0.6492723 {-}0.4498879  1.00000000  1.00000000 {-}0.02424963 {-}0.16264543}
\CommentTok{\#\textgreater{} CTTR {-}0.6492723 {-}0.4498879  1.00000000  1.00000000 {-}0.02424963 {-}0.16264543}
\CommentTok{\#\textgreater{} U     0.7586668  0.8884154 {-}0.02424963 {-}0.02424963  1.00000000  0.98430655}
\CommentTok{\#\textgreater{} S     0.8514841  0.9516268 {-}0.16264543 {-}0.16264543  0.98430655  1.00000000}
\CommentTok{\#\textgreater{} K     0.5991452  0.4294223 {-}0.83367217 {-}0.83367217  0.01275208  0.16142157}
\CommentTok{\#\textgreater{} I     0.2327750  0.3698611  0.26241321  0.26241321  0.58486310  0.52740696}
\CommentTok{\#\textgreater{} D     0.4013304  0.2514823 {-}0.65214634 {-}0.65214634 {-}0.10697212  0.01957486}
\CommentTok{\#\textgreater{} Vm    0.3075452  0.1968097 {-}0.47355632 {-}0.47355632 {-}0.07691131  0.01930842}
\CommentTok{\#\textgreater{} Maas {-}0.7882881 {-}0.9112332  0.05759202  0.05759202 {-}0.99701921 {-}0.99354677}
\CommentTok{\#\textgreater{} lgV0  0.3571139  0.5682834  0.45841359  0.45841359  0.87598404  0.79330142}
\CommentTok{\#\textgreater{}                K          I           D          Vm        Maas       lgV0}
\CommentTok{\#\textgreater{} TTR   0.59914525  0.2327750  0.40133039  0.30754517 {-}0.78828811  0.3571139}
\CommentTok{\#\textgreater{} C     0.42942231  0.3698611  0.25148227  0.19680971 {-}0.91123321  0.5682834}
\CommentTok{\#\textgreater{} R    {-}0.83367217  0.2624132 {-}0.65214634 {-}0.47355632  0.05759202  0.4584136}
\CommentTok{\#\textgreater{} CTTR {-}0.83367217  0.2624132 {-}0.65214634 {-}0.47355632  0.05759202  0.4584136}
\CommentTok{\#\textgreater{} U     0.01275208  0.5848631 {-}0.10697212 {-}0.07691131 {-}0.99701921  0.8759840}
\CommentTok{\#\textgreater{} S     0.16142157  0.5274070  0.01957486  0.01930842 {-}0.99354677  0.7933014}
\CommentTok{\#\textgreater{} K     1.00000000 {-}0.5873634  0.94208077  0.84481216 {-}0.06058855 {-}0.4082192}
\CommentTok{\#\textgreater{} I    {-}0.58736335  1.0000000 {-}0.77504336 {-}0.82248673 {-}0.56958764  0.6634351}
\CommentTok{\#\textgreater{} D     0.94208077 {-}0.7750434  1.00000000  0.96943443  0.06563582 {-}0.4269281}
\CommentTok{\#\textgreater{} Vm    0.84481216 {-}0.8224867  0.96943443  1.00000000  0.04532617 {-}0.3156220}
\CommentTok{\#\textgreater{} Maas {-}0.06058855 {-}0.5695876  0.06563582  0.04532617  1.00000000 {-}0.8557245}
\CommentTok{\#\textgreater{} lgV0 {-}0.40821917  0.6634351 {-}0.42692805 {-}0.31562199 {-}0.85572445  1.0000000}
\end{Highlighting}
\end{Shaded}

A kapott értékeket a \texttt{ggcorr()} függvény segítségével
ábrázolhatjuk is. Ha a függvény argumentumában a \texttt{label\ =\ TRUE}
szerepel, a kapott ábrán a kiszámított értékek is szerepelnek.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggcorr}\NormalTok{(div\_df[, }\DecValTok{2}\SpecialCharTok{:}\DecValTok{13}\NormalTok{], }\AttributeTok{label =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{_main_files/figure-latex/unnamed-chunk-48-1} \end{center}

Ezt követően azt is megvizsgálhatjuk, hogy a korpusz szövei mennyire
könnyen olvashatóak. Ehhez a \texttt{Flesch.Kincaid} pontszámot
használjuk, ami a szavak és mondatok hossza alapján határozza meg a
szöveg olvashatóságát. Ehhez \texttt{textstat\_readability()} függvényt
használjuk, mely a korpuszunkat elemzi.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{corpus\_mineln }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{textstat\_readability}\NormalTok{(}\AttributeTok{measure =} \StringTok{"Flesch.Kincaid"}\NormalTok{)}
\CommentTok{\#\textgreater{}                document Flesch.Kincaid}
\CommentTok{\#\textgreater{} 1    antall\_jozsef\_1990       16.48512}
\CommentTok{\#\textgreater{} 2    bajnai\_gordon\_2009       10.92243}
\CommentTok{\#\textgreater{} 3     boross\_peter\_1993       15.40159}
\CommentTok{\#\textgreater{} 4 gyurcsany\_ferenc\_2005       13.55911}
\CommentTok{\#\textgreater{} 5       horn\_gyula\_1994       13.77918}
\CommentTok{\#\textgreater{} 6  medgyessy\_peter\_2002       15.81893}
\CommentTok{\#\textgreater{} 7     orban\_viktor\_1995       13.04284}
\CommentTok{\#\textgreater{} 8     orban\_viktor\_2018       11.39180}
\end{Highlighting}
\end{Shaded}

Ezután a kiszámított értékkel kiegészítjük a korpuszt

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{docvars}\NormalTok{(corpus\_mineln, }\StringTok{"f\_k"}\NormalTok{) }\OtherTok{\textless{}{-}} \FunctionTok{textstat\_readability}\NormalTok{(corpus\_mineln, }\AttributeTok{measure =} \StringTok{"Flesch.Kincaid"}\NormalTok{)[, }
    \DecValTok{2}\NormalTok{]}

\FunctionTok{docvars}\NormalTok{(corpus\_mineln)}
\CommentTok{\#\textgreater{}             mineln wing year      f\_k}
\CommentTok{\#\textgreater{} 1    antall\_jozsef jobb 1990 16.48512}
\CommentTok{\#\textgreater{} 2    bajnai\_gordon  bal 2009 10.92243}
\CommentTok{\#\textgreater{} 3     boross\_peter jobb 1993 15.40159}
\CommentTok{\#\textgreater{} 4 gyurcsany\_ferenc  bal 2005 13.55911}
\CommentTok{\#\textgreater{} 5       horn\_gyula  bal 1994 13.77918}
\CommentTok{\#\textgreater{} 6  medgyessy\_peter  bal 2002 15.81893}
\CommentTok{\#\textgreater{} 7     orban\_viktor jobb 1995 13.04284}
\CommentTok{\#\textgreater{} 8     orban\_viktor jobb 2018 11.39180}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{docvars}\NormalTok{(corpus\_mineln, }\StringTok{"f\_k"}\NormalTok{) }\OtherTok{\textless{}{-}} \FunctionTok{textstat\_readability}\NormalTok{(corpus\_mineln, }\AttributeTok{measure =} \StringTok{"Flesch.Kincaid"}\NormalTok{)[, }
    \DecValTok{2}\NormalTok{]}

\FunctionTok{docvars}\NormalTok{(corpus\_mineln)}
\CommentTok{\#\textgreater{}             mineln wing year      f\_k}
\CommentTok{\#\textgreater{} 1    antall\_jozsef jobb 1990 16.48512}
\CommentTok{\#\textgreater{} 2    bajnai\_gordon  bal 2009 10.92243}
\CommentTok{\#\textgreater{} 3     boross\_peter jobb 1993 15.40159}
\CommentTok{\#\textgreater{} 4 gyurcsany\_ferenc  bal 2005 13.55911}
\CommentTok{\#\textgreater{} 5       horn\_gyula  bal 1994 13.77918}
\CommentTok{\#\textgreater{} 6  medgyessy\_peter  bal 2002 15.81893}
\CommentTok{\#\textgreater{} 7     orban\_viktor jobb 1995 13.04284}
\CommentTok{\#\textgreater{} 8     orban\_viktor jobb 2018 11.39180}
\end{Highlighting}
\end{Shaded}

Majd a \texttt{ggplot2} segítségével vizualizálhatjuk az eredményt.
Ehhez az olvashatósági pontszámmal kiegészített korpuszból data fram-et
alakítunk ki, majd beállítjuk az ábrázolás paramétereit. Azaz, hogy a
két tengelyen az év illetve az olvashatósági pontszám szerepeljen, a
színezés különböztesse meg a jobb és a bal oldalt, az egyes
dokumentumokat ponttal jelöljük, a jobb és bal oldali beszédeket
vonallal kötjük össze, az ábrára fekete színnel felíratjuk a
miniszterelnökök nevét, valamint, hogy az x tengely beosztása az egyes
beszédek dátumához igazodjon. A \texttt{theme\_minimal()} függvénnyel
pedig azt határozzuk meg, hogy mindez fehér hátteret kapjon.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{corpus\_df }\OtherTok{\textless{}{-}} \FunctionTok{docvars}\NormalTok{(corpus\_mineln)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(corpus\_df, }\FunctionTok{aes}\NormalTok{(year, f\_k, }\AttributeTok{color =}\NormalTok{ wing)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{size =} \DecValTok{2}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{linetype =}\NormalTok{ wing), }\AttributeTok{size =} \DecValTok{1}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_text}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{label =}\NormalTok{ mineln), }\AttributeTok{color =} \StringTok{"black"}\NormalTok{, }\AttributeTok{nudge\_y =} \FloatTok{0.15}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_x\_continuous}\NormalTok{(}\AttributeTok{breaks =}\NormalTok{ corpus\_df}\SpecialCharTok{$}\NormalTok{year) }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{_main_files/figure-latex/unnamed-chunk-53-1} 

}

\caption{Az olvashatósági index alakulása}\label{fig:unnamed-chunk-53}
\end{figure}

\hypertarget{uxf6sszehasonluxedtuxe1s4}{%
\section[Összehasonlítás]{\texorpdfstring{Összehasonlítás\footnote{(\protect\hyperlink{ref-schuxfctze2008a:294-307}{\textbf{schütze2008a:294-307?}})}}{Összehasonlítás}}\label{uxf6sszehasonluxedtuxe1s4}}

A fentiekben láthattuk az eltéréseket a jobb és bal oldali beszédeken
belül, sőt ugyanahhoz a miniszterelnökhöz tartozó két beszéd között is.
A következőkben \texttt{textstat\_dist()} és \texttt{textstat\_simil()}
függvények segítségével megvizsgáljuk, valójában mennyire hasonlítanak
vagy különböznek ezek a beszédek. Mindkét függvény bemenete
\texttt{dmf}, melyből először egy súlyozott \texttt{dfm}-et készítünk,
majd elvégezzük az összehasonlítást először a \texttt{jaccard}-féle
hasonlóság alapján.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mineln\_dfm }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{dfm\_weight}\NormalTok{(}\StringTok{"prop"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{textstat\_simil}\NormalTok{(}\AttributeTok{margin =} \StringTok{"documents"}\NormalTok{, }\AttributeTok{method =} \StringTok{"jaccard"}\NormalTok{)}
\CommentTok{\#\textgreater{} textstat\_simil object; method = "jaccard"}
\CommentTok{\#\textgreater{}                       antall\_jozsef\_1990 bajnai\_gordon\_2009 boross\_peter\_1993}
\CommentTok{\#\textgreater{} antall\_jozsef\_1990                1.0000             0.0559            0.1011}
\CommentTok{\#\textgreater{} bajnai\_gordon\_2009                0.0559             1.0000            0.0564}
\CommentTok{\#\textgreater{} boross\_peter\_1993                 0.1011             0.0564            1.0000}
\CommentTok{\#\textgreater{} gyurcsany\_ferenc\_2005             0.0798             0.0850            0.0604}
\CommentTok{\#\textgreater{} horn\_gyula\_1994                   0.0694             0.0592            0.0613}
\CommentTok{\#\textgreater{} medgyessy\_peter\_2002              0.0404             0.0690            0.0473}
\CommentTok{\#\textgreater{} orban\_viktor\_1995                 0.0778             0.0626            0.0631}
\CommentTok{\#\textgreater{} orban\_viktor\_2018                 0.0362             0.0617            0.0401}
\CommentTok{\#\textgreater{}                       gyurcsany\_ferenc\_2005 horn\_gyula\_1994}
\CommentTok{\#\textgreater{} antall\_jozsef\_1990                   0.0798          0.0694}
\CommentTok{\#\textgreater{} bajnai\_gordon\_2009                   0.0850          0.0592}
\CommentTok{\#\textgreater{} boross\_peter\_1993                    0.0604          0.0613}
\CommentTok{\#\textgreater{} gyurcsany\_ferenc\_2005                1.0000          0.0683}
\CommentTok{\#\textgreater{} horn\_gyula\_1994                      0.0683          1.0000}
\CommentTok{\#\textgreater{} medgyessy\_peter\_2002                 0.0684          0.0587}
\CommentTok{\#\textgreater{} orban\_viktor\_1995                    0.0734          0.0621}
\CommentTok{\#\textgreater{} orban\_viktor\_2018                    0.0503          0.0494}
\CommentTok{\#\textgreater{}                       medgyessy\_peter\_2002 orban\_viktor\_1995 orban\_viktor\_2018}
\CommentTok{\#\textgreater{} antall\_jozsef\_1990                  0.0404            0.0778            0.0362}
\CommentTok{\#\textgreater{} bajnai\_gordon\_2009                  0.0690            0.0626            0.0617}
\CommentTok{\#\textgreater{} boross\_peter\_1993                   0.0473            0.0631            0.0401}
\CommentTok{\#\textgreater{} gyurcsany\_ferenc\_2005               0.0684            0.0734            0.0503}
\CommentTok{\#\textgreater{} horn\_gyula\_1994                     0.0587            0.0621            0.0494}
\CommentTok{\#\textgreater{} medgyessy\_peter\_2002                1.0000            0.0650            0.0504}
\CommentTok{\#\textgreater{} orban\_viktor\_1995                   0.0650            1.0000            0.0583}
\CommentTok{\#\textgreater{} orban\_viktor\_2018                   0.0504            0.0583            1.0000}
\end{Highlighting}
\end{Shaded}

Majd a \texttt{textstat\_dist()} függvény segítségével kiszámoljuk a
dokumentumok egymástól való különbözőségét.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mineln\_dfm }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{textstat\_dist}\NormalTok{(}\AttributeTok{margin =} \StringTok{"documents"}\NormalTok{, }\AttributeTok{method =} \StringTok{"euclidean"}\NormalTok{)}
\CommentTok{\#\textgreater{} textstat\_dist object; method = "euclidean"}
\CommentTok{\#\textgreater{}                       antall\_jozsef\_1990 bajnai\_gordon\_2009 boross\_peter\_1993}
\CommentTok{\#\textgreater{} antall\_jozsef\_1990                     0              162.8             134.1}
\CommentTok{\#\textgreater{} bajnai\_gordon\_2009                   163                  0              84.6}
\CommentTok{\#\textgreater{} boross\_peter\_1993                    134               84.6                 0}
\CommentTok{\#\textgreater{} gyurcsany\_ferenc\_2005                186              137.8             149.7}
\CommentTok{\#\textgreater{} horn\_gyula\_1994                      164               80.1              88.0}
\CommentTok{\#\textgreater{} medgyessy\_peter\_2002                 160               68.1              81.8}
\CommentTok{\#\textgreater{} orban\_viktor\_1995                    139               84.7              79.7}
\CommentTok{\#\textgreater{} orban\_viktor\_2018                    167               67.3              85.4}
\CommentTok{\#\textgreater{}                       gyurcsany\_ferenc\_2005 horn\_gyula\_1994}
\CommentTok{\#\textgreater{} antall\_jozsef\_1990                      186           163.6}
\CommentTok{\#\textgreater{} bajnai\_gordon\_2009                      138            80.1}
\CommentTok{\#\textgreater{} boross\_peter\_1993                       150            88.0}
\CommentTok{\#\textgreater{} gyurcsany\_ferenc\_2005                     0           147.0}
\CommentTok{\#\textgreater{} horn\_gyula\_1994                         147               0}
\CommentTok{\#\textgreater{} medgyessy\_peter\_2002                    143            75.9}
\CommentTok{\#\textgreater{} orban\_viktor\_1995                       147            89.6}
\CommentTok{\#\textgreater{} orban\_viktor\_2018                       148            74.8}
\CommentTok{\#\textgreater{}                       medgyessy\_peter\_2002 orban\_viktor\_1995 orban\_viktor\_2018}
\CommentTok{\#\textgreater{} antall\_jozsef\_1990                   160.2             139.2             167.4}
\CommentTok{\#\textgreater{} bajnai\_gordon\_2009                    68.1              84.7              67.3}
\CommentTok{\#\textgreater{} boross\_peter\_1993                     81.8              79.7              85.4}
\CommentTok{\#\textgreater{} gyurcsany\_ferenc\_2005                142.6             146.9             147.9}
\CommentTok{\#\textgreater{} horn\_gyula\_1994                       75.9              89.6              74.8}
\CommentTok{\#\textgreater{} medgyessy\_peter\_2002                     0              77.5              60.7}
\CommentTok{\#\textgreater{} orban\_viktor\_1995                     77.5                 0              83.6}
\CommentTok{\#\textgreater{} orban\_viktor\_2018                     60.7              83.6                 0}
\end{Highlighting}
\end{Shaded}

Ezután vizualizálhatjuk is a dokumentumok egymástól való távolságát egy
olyan dendogram segítségével, amely megmutatja nekünk a lehetséges
dokumentumpárokat.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dist }\OtherTok{\textless{}{-}}\NormalTok{ mineln\_dfm }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{textstat\_dist}\NormalTok{(}\AttributeTok{margin =} \StringTok{"documents"}\NormalTok{, }\AttributeTok{method =} \StringTok{"euclidean"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(}\FunctionTok{hclust}\NormalTok{(}\FunctionTok{as.dist}\NormalTok{(dist)))}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{_main_files/figure-latex/unnamed-chunk-57-1} 

}

\caption{A dokumentumok csoportosítása a távolságuk alapján}\label{fig:unnamed-chunk-57}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mineln\_dfm }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{textstat\_simil}\NormalTok{(}\AttributeTok{y =}\NormalTok{ mineln\_dfm[, }\FunctionTok{c}\NormalTok{(}\StringTok{"kormány"}\NormalTok{)], }\AttributeTok{margin =} \StringTok{"features"}\NormalTok{, }\AttributeTok{method =} \StringTok{"correlation"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{head}\NormalTok{(}\AttributeTok{n =} \DecValTok{10}\NormalTok{)}
\CommentTok{\#\textgreater{}                 kormány}
\CommentTok{\#\textgreater{} elnök        {-}0.1185449}
\CommentTok{\#\textgreater{} tisztelt     {-}0.5401371}
\CommentTok{\#\textgreater{} országgyulés  0.8082763}
\CommentTok{\#\textgreater{} hölgyeim     {-}0.3580776}
\CommentTok{\#\textgreater{} uraim        {-}0.3580776}
\CommentTok{\#\textgreater{} honfitársaim  0.8648335}
\CommentTok{\#\textgreater{} ünnepi        0.8737759}
\CommentTok{\#\textgreater{} pillanatban   0.8737759}
\CommentTok{\#\textgreater{} állok         0.6864778}
\CommentTok{\#\textgreater{} magyar        0.7530170}
\end{Highlighting}
\end{Shaded}

Arra is van lehetőségünk, hogy a két alkorpuszt hasonlítsuk össze
egymással. Ehhez a \texttt{textstat\_keyness()} függvényt haszáljuk,
melynek a bemenete a \texttt{dfm}. A függvény argumentumában a
\texttt{target\ =} után kell szerepletnük, hogy mely alkorpusz a
viszonyítási alap. Az összehasonlítás eredményét a 'textplot\_keyness()`
függvény segítségével ábrázolhatjuk, ami megjeleníti a két alkorpusz
leggyakoribb kifejezéseit.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dfm }\OtherTok{\textless{}{-}} \FunctionTok{dfm}\NormalTok{(}
\NormalTok{  corpus\_mineln,}
  \AttributeTok{groups =} \StringTok{"wing"}\NormalTok{, }
  \AttributeTok{remove =}\NormalTok{ custom\_stopwords,}
  \AttributeTok{remove\_punct =} \ConstantTok{TRUE}
\NormalTok{)}

\NormalTok{result\_keyness }\OtherTok{\textless{}{-}} \FunctionTok{textstat\_keyness}\NormalTok{(dfm, }\AttributeTok{target =} \StringTok{"jobb"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{textplot\_keyness}\NormalTok{(result\_keyness)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{_main_files/figure-latex/unnamed-chunk-60-1} 

}

\caption{A korpuszok legfontosabb kifejezései}\label{fig:unnamed-chunk-60}
\end{figure}

Ha az egyes miniszterelnökök beszédeinek leggyakoribb kifejezéseit
szeretnénk összehasonlítani, azt a \texttt{textstat\_frequency()}
függvény segítségével tehetjük meg, melynek bemnete a megtisztított és
súlyozott \texttt{dfm}. Az összehasonlítás eredményét pedig a
\texttt{ggplot2} segítségével ábrázolhatjuk is.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dfm\_weight }\OtherTok{\textless{}{-}}\NormalTok{ corpus\_mineln }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{dfm}\NormalTok{(}
    \AttributeTok{remove =}\NormalTok{ custom\_stopwords, }
    \AttributeTok{tolower =} \ConstantTok{TRUE}\NormalTok{, }
    \AttributeTok{remove\_punct =} \ConstantTok{TRUE}\NormalTok{, }
    \AttributeTok{stem =} \ConstantTok{TRUE}\NormalTok{, }
    \AttributeTok{remove\_symbols =} \ConstantTok{TRUE}\NormalTok{, }
    \AttributeTok{remove\_numbers =} \ConstantTok{TRUE}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{dfm\_weight}\NormalTok{(}\AttributeTok{scheme =} \StringTok{"prop"}\NormalTok{)}

\NormalTok{freq\_weight }\OtherTok{\textless{}{-}} \FunctionTok{textstat\_frequency}\NormalTok{(dfm\_weight, }\AttributeTok{n =} \DecValTok{5}\NormalTok{, }\AttributeTok{groups =} \StringTok{"mineln"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ freq\_weight, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =} \FunctionTok{nrow}\NormalTok{(freq\_weight)}\SpecialCharTok{:}\DecValTok{1}\NormalTok{, }\AttributeTok{y =}\NormalTok{ frequency)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ group, }\AttributeTok{scales =} \StringTok{"free"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{coord\_flip}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{scale\_x\_continuous}\NormalTok{(}
    \AttributeTok{breaks =} \FunctionTok{nrow}\NormalTok{(freq\_weight)}\SpecialCharTok{:}\DecValTok{1}\NormalTok{,}
    \AttributeTok{labels =}\NormalTok{ freq\_weight}\SpecialCharTok{$}\NormalTok{feature}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{x =} \ConstantTok{NULL}\NormalTok{, }
    \AttributeTok{y =} \StringTok{"Relative frequency"}
\NormalTok{    )}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{_main_files/figure-latex/unnamed-chunk-62-1} 

}

\caption{Leggyakoribb kifejezések a miniszterelnöki beszédekben}\label{fig:unnamed-chunk-62}
\end{figure}

\hypertarget{kifejezuxe9sek-kontextusba-helyezuxe9se}{%
\section{Kifejezések kontextusba
helyezése}\label{kifejezuxe9sek-kontextusba-helyezuxe9se}}

Arra is lehetőségünk van, hogy egyes kulcszavakat a korpuszon belül
szövekörnyezetükben vizsgáljunk meg. Ehhez a \texttt{kwic()} függvényt
használjuk, az argumentumok között a \texttt{pattern\ =} kifejezés után
megadva azt a szót, amelyet vizsgálni szeretnénk, a `window =' után
pedig megadhatjuk hogy az adott szó hány szavas környezetére vagyunk
kíváncsiak.

\begin{Shaded}
\begin{Highlighting}[]

\FunctionTok{kwic}\NormalTok{(corpus\_mineln, }\AttributeTok{pattern =} \StringTok{"válság*"}\NormalTok{, }\AttributeTok{valuetype =} \StringTok{"glob"}\NormalTok{, }\AttributeTok{window =} \DecValTok{3}\NormalTok{, }\AttributeTok{case\_insensitive =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{head}\NormalTok{(}\DecValTok{5}\NormalTok{)}
\CommentTok{\#\textgreater{}                                                                               }
\CommentTok{\#\textgreater{}  [antall\_jozsef\_1990, 1167]                     Átfogó és mély |  válságba   |}
\CommentTok{\#\textgreater{}  [antall\_jozsef\_1990, 1283]                  kell hárítanunk a |  válságot   |}
\CommentTok{\#\textgreater{}  [antall\_jozsef\_1990, 2772]              és a lakásgazdálkodás |  válságos   |}
\CommentTok{\#\textgreater{}  [antall\_jozsef\_1990, 5226]          gazdaság egészét juttatta |  válságba   |}
\CommentTok{\#\textgreater{}  [antall\_jozsef\_1990, 5286] gazdaság reménytelenül eladósodott | válsággócai |}
\CommentTok{\#\textgreater{}                          }
\CommentTok{\#\textgreater{}  süllyedtünk a nyolcvanas}
\CommentTok{\#\textgreater{}  , de csakis             }
\CommentTok{\#\textgreater{}  helyzetbe került.       }
\CommentTok{\#\textgreater{}  , és amellyel           }
\CommentTok{\#\textgreater{}  ellen. A}
\end{Highlighting}
\end{Shaded}

\hypertarget{szuxf3tuxe1ralapuxfa-elemzuxe9sek-uxe9rzelem-elemzuxe9s}{%
\chapter{Szótáralapú elemzések,
érzelem-elemzés}\label{szuxf3tuxe1ralapuxfa-elemzuxe9sek-uxe9rzelem-elemzuxe9s}}

A szótár alapú szentiment elemzés egy egyszerű ötleten alapul. Hogyha
tudjuk hogy egyes szavak milyen érzelmeket, érzéseket, információt
hordoznak, akkor minél gyakoribb egy-egy érzelem kategóriához tartozó
szó, akkor a szentiment annél inkább jellemző lesz a dokumentumra amit
vizsgálunk. Természetesen itt is jó pár dolognak kell teljesülnie ahhoz
hogy az elemzésünk eredménye megbízható legyen. Mivel a szótár alapú
elemzés az adott szentiment kategórián belüli kulcsszavak gyakoriságán
alapul, ezért van aki nem tekinti statisztikai elemzésnek (lásd például
\protect\hyperlink{ref-young2012affective}{Young and Soroka}
(\protect\hyperlink{ref-young2012affective}{2012})). A tágabb
kvantitatív szövegelemzési kontextusban az osztályozáson
(classification) belül a felügyelt módszerekhez hasonlóan itt is ismert
kategóriákkal dolgozunk (pl.: egy kulcsszó az ``öröm'' kategóriába
tartozik), csak egyszerűbb módszertannal
(\protect\hyperlink{ref-grimmer2013text}{Grimmer and Stewart 2013a}).

A kulcsszavakra építés miatt a módszer a kvalitatív és kvantitatív
kutatási vonalak találkozásának is tekinthető, hiszen egy-egy szónak az
érzelmi töltete nem mindig ítélhető meg objektíven. Mint minden módszer
esetében, amiről ebben a tankönyvben szó van, itt is kiemelten fontos
hogy ellenőrízzük hogy a használt szótár kategóriák és kulcsszavak
fedik-e a valóságot. Más szavakkal: \emph{validate, validate, validate}.
\textbf{A módszer előnyei:}

\begin{itemize}
\tightlist
\item
  Tökéletesen megbízható: nincsen probabilisztikus eleme a
  számításoknak, mint például a Support Vector alapú osztályozásnál,
  illetve az emberi szövegkódolásnál előforduló problémákat is
  elkerüljük így.
\item
  Képesek vagyunk vele mérni a szöveg látens dimenzióit.
\item
  Széles körben alkalmazható, egyszerűen számolható. A
  politikatudományon és számítogépes nyelvtudományokon belül nagyon sok
  kész szótár elérhető, amik különböző módszerekkel készültek és
  különböző területet fednek le (pl.: populizmus, pártprogramok policy
  tartalma, érzelmek, gazdasági tartalom.)\footnote{A lehetséges,
    területspecifikus szótáralkotási módszerekről részletesebben ezekben
    a cikkekben lehet olvasni:
    \protect\hyperlink{ref-laver2000estimating}{Laver and Garry}
    (\protect\hyperlink{ref-laver2000estimating}{2000});
    \protect\hyperlink{ref-young2012affective}{Young and Soroka}
    (\protect\hyperlink{ref-young2012affective}{2012});
    \protect\hyperlink{ref-loughran2011}{Loughran and McDonald}
    (\protect\hyperlink{ref-loughran2011}{2011});
    \protect\hyperlink{ref-muxe1tuxe92021}{Máté, Sebők, and Barczikay}
    (\protect\hyperlink{ref-muxe1tuxe92021}{2021})}
\item
  Relatíve könnyen adaptálható egyik nyelvi környezetből másikba.
\end{itemize}

\textbf{A módszer lehetéges hátrányai:}

\begin{itemize}
\tightlist
\item
  A szótár hatékonysága és validitása azon múlik hogy mennyire egyezik a
  szótár és a viszgálni kívánt dokumentum területe. Például jellemző
  hiba, hogy gazdasági bizonytalanságot szeretnék tőzsdei jelentések
  alapján vizsgálni a kutatók egy általános szentimet szótár
  használatával.
\item
  A terület-specifikus szótár építése egy kvalitatív folyamat (lsd. a
  labjegyzetben), éppen ezért gyakran idő és emberi erőforrás igényes.
\item
  A szózsák alapú elemzéseknél a kontextus elvész (ez gyakran igaz a
  bigram és trigramok használatánál is) a kulcsszavak esetében. Erre egy
  triviális példa a tagadás a mondatban: \emph{``nem vagyok boldog''}
  esetén egy általános szentiment szótár a tagadás miatt
  félreosztályozná a mondat érzelmi töltését.
\end{itemize}

Az elemzés sikere több faktortól is függ. Fontos hogy a korpuszban lévő
dokumentumokat körültekintően tisztítsuk meg az elemzés elején (lásd a
4. fejezetet a szövegelőkészítésről). A következő lépésben meg kell
bizonyosodnunk arról, hogy a kiválasztott szentiment szótár alkalmazható
a korpuszunkra. Amennyiben nem találunk alkalmas szótárat, akkor a saját
szótár validálására kell figyelni. A negyedik fejezetben leírtak itt is
érvényesek, érdemes a dokumentum-kifejezés mátrixot súlyozni valamilyen
módon.

\hypertarget{szuxf3tuxe1rak-az-r-ben}{%
\section{Szótárak az R-ben}\label{szuxf3tuxe1rak-az-r-ben}}

A szótár alapú elemzéshez a \texttt{quanteda} csomagot fogjuk használni,
illetve a 3. fejezetben már megismert \texttt{readr}, \texttt{stringr},
\texttt{dplyr} tidyverse csomagokat.\footnote{A szentiment elemzéshez
  gyakran használt csomag még a tidytext. Az online is szabadon elérhető
  \protect\hyperlink{ref-silge2017text}{Silge and Robinson}
  (\protect\hyperlink{ref-silge2017text}{2017}) 2. fejezetében
  részletesen is bemutatják a szerzők a tidytext munkafolyamatot
  (\url{https://www.tidytextmining.com/sentiment.html}).}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(readr)}
\FunctionTok{library}\NormalTok{(stringr)}
\FunctionTok{library}\NormalTok{(dplyr)}
\FunctionTok{library}\NormalTok{(ggplot2)}
\FunctionTok{library}\NormalTok{(quanteda)}
\FunctionTok{library}\NormalTok{(quanteda.dictionaries)}
\end{Highlighting}
\end{Shaded}

Mielőtt a két esettanulmányt bemutatnánk, vizsgáljuk meg hogy hogyan néz
ki egy szentiment szótár az R-ben. A szótárt kézzel úgy tudjuk
létrehozni, hogy egy listán belül létrehozzuk karaktervektorként a
kategóriákat és a kulcsszavakat és ezt a listát a quanteda dictionary
függvényével eltároljuk.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{szentiment\_szotar }\OtherTok{\textless{}{-}} \FunctionTok{dictionary}\NormalTok{(}
  \FunctionTok{list}\NormalTok{(}
    \AttributeTok{pozitiv =} \FunctionTok{c}\NormalTok{(}\StringTok{"jó"}\NormalTok{, }\StringTok{"boldog"}\NormalTok{, }\StringTok{"öröm"}\NormalTok{),}
    \AttributeTok{negativ =} \FunctionTok{c}\NormalTok{(}\StringTok{"rossz"}\NormalTok{, }\StringTok{"szomorú"}\NormalTok{, }\StringTok{"lehangoló"}\NormalTok{)}
\NormalTok{    )}
\NormalTok{  )}

\NormalTok{szentiment\_szotar}
\CommentTok{\#\textgreater{} Dictionary object with 2 key entries.}
\CommentTok{\#\textgreater{} {-} [pozitiv]:}
\CommentTok{\#\textgreater{}   {-} jó, boldog, öröm}
\CommentTok{\#\textgreater{} {-} [negativ]:}
\CommentTok{\#\textgreater{}   {-} rossz, szomorú, lehangoló}
\end{Highlighting}
\end{Shaded}

A quanteda, quanteda.corpora és tidytext R csomagok több széles körben
használt szentiment szótárat tartalmaznak, így nem kell kézzel
replikálni minden egyes szótárat amit használni szeretnénk.

A szentiment elemzési munkafolyamat amit a részfejezetben bemutatunk a
következő lépésekből áll:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  dokumentumok betöltése
\item
  szöveg előkészítése
\item
  a korpusz létrehozása
\item
  dokumentum-kifejezés mátrix
\item
  szótár betöltése
\item
  a dokumentum-kifejezés mátrix szűrése a szótárban lévő kulcsszavakkal
\item
  az eredmény vizualizálása, további felhasználása
\end{enumerate}

A fejezetben két különböző korpuszt fogunk elemezni: a 2006-os Magyar
Nemzet címlapjainak egy 252 cikkből álló mintájának szentimentjét
vizsgáljuk egy magyar szentiment szótárral. A második korpusz a Magyar
Nemzeti Bank angol nyelvű sajtóközleményeiből áll, amin bemutatjuk egy
széles körben használt gazdasági szótár használatát.

\hypertarget{magyar-nemzet-cikkek}{%
\section{Magyar Nemzet cikkek}\label{magyar-nemzet-cikkek}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mn\_minta }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(}\StringTok{"data/magyar\_nemzet\_small.csv"}\NormalTok{)}

\FunctionTok{summary}\NormalTok{(mn\_minta)}
\CommentTok{\#\textgreater{}      doc\_id           text              doc\_date         }
\CommentTok{\#\textgreater{}  Min.   :   1.0   Length:2834        Min.   :2006{-}01{-}02  }
\CommentTok{\#\textgreater{}  1st Qu.: 709.2   Class :character   1st Qu.:2006{-}03{-}29  }
\CommentTok{\#\textgreater{}  Median :1417.5   Mode  :character   Median :2006{-}06{-}28  }
\CommentTok{\#\textgreater{}  Mean   :1417.5                      Mean   :2006{-}06{-}28  }
\CommentTok{\#\textgreater{}  3rd Qu.:2125.8                      3rd Qu.:2006{-}09{-}26  }
\CommentTok{\#\textgreater{}  Max.   :2834.0                      Max.   :2006{-}12{-}29}
\end{Highlighting}
\end{Shaded}

A \texttt{read\_csv()} segítségével beolvassuk a Magyar Nemzet adatbázis
egy kisebb részét, ami az esetünkben a 2006-os cimlapokon szereplő hírek
. A \texttt{summary()}, ahogy a neve is mutatja, egy gyors
áttekinténtést nyújt a betöltött adatbázisról. Látjuk, hogy 2834 sorbol
(megfigyelés) és 3 oszlopból (változó) áll. Az első ránézésre látszik
hogy a text változónk tartalmazza a szövegeket, és hogy tisztításra
szorulnak.

Az első szöveget megnézve látjuk, hogy a standard előkészítési lépések
mellett a sortörést (\texttt{\textbackslash{}n}) is ki kell törölnünk.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mn\_minta}\SpecialCharTok{$}\NormalTok{text[}\DecValTok{1}\NormalTok{]}
\CommentTok{\#\textgreater{} [1] "Hat fovárosi képviselo öt percnél is kevesebbet beszélt egy év alatt a közgyulésben.\textbackslash{}n\textbackslash{}n\textbackslash{}n\textbackslash{}n\textbackslash{}n\textbackslash{}n\textbackslash{}n\textbackslash{}n\textbackslash{}n\textbackslash{}n\textbackslash{}n"}
\end{Highlighting}
\end{Shaded}

Habár a \texttt{quanteda} is lehetőséget ad néhány elékészítő lépésre,
érdemes ezt olyan céleszközzel tenni ami nagyobb rugalmasságot ad a
kezünkbe. Mi erre a célra a \texttt{stringr} csomagot használjuk. Első
lépésben kitöröljük a sortöréseket (\texttt{\textbackslash{}n}), a
központozást, számokat, kisbetűsítünk minden szót. Előfordulhat hogy
(számunkra nehezen látható) extra szóközök maradnak a szövegben. Ezeket
az \texttt{str\_squish()}-el tüntetjük el. A szöveg eleji és végi extra
szóközöket (ún. leading vagy trailing white space) az
\texttt{str\_trim()} vágja le.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mn\_tiszta }\OtherTok{\textless{}{-}}\NormalTok{ mn\_minta }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{text =} \FunctionTok{str\_remove\_all}\NormalTok{(}\AttributeTok{string =}\NormalTok{ text, }\AttributeTok{pattern =} \StringTok{"}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{),}
    \AttributeTok{text =} \FunctionTok{str\_remove\_all}\NormalTok{(}\AttributeTok{string =}\NormalTok{ text, }\AttributeTok{pattern =} \StringTok{"[:punct:]"}\NormalTok{),}
    \AttributeTok{text =} \FunctionTok{str\_remove\_all}\NormalTok{(}\AttributeTok{string =}\NormalTok{ text, }\AttributeTok{pattern =} \StringTok{"[:digit:]"}\NormalTok{),}
    \AttributeTok{text =} \FunctionTok{str\_to\_lower}\NormalTok{(text),}
    \AttributeTok{text =} \FunctionTok{str\_trim}\NormalTok{(text),}
    \AttributeTok{text =} \FunctionTok{str\_squish}\NormalTok{(text)}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

A szöveg sokkal jobban néz ki, habár észrevehetjük hogy maradhattak
benne problémás részek, főleg a sortörés miatt, ami sajnos hol egyes
szavak közepén van (a jobbik eset), vagy pedig pont szóhatáron, ez
esetben a két szó sajnos összevonódik. Az egyszerűség kedvéért
feltételezzük hogy ez kellően ritkán fordul elő ahhoz hogy ne
befolyásolja az elemzésünk eredményét.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mn\_tiszta}\SpecialCharTok{$}\NormalTok{text[}\DecValTok{1}\NormalTok{]}
\CommentTok{\#\textgreater{} [1] "hat fovárosi képviselo öt percnél is kevesebbet beszélt egy év alatt a közgyulésben"}
\end{Highlighting}
\end{Shaded}

Miután kész a tiszta(bb) szövegünk, kreálunk egy korpuszt a quanteda
\texttt{corpus()} fuggvenyevel. A létrehozott corpus objektum a szöveg
mellett egyéb dokumentum meta adatokat is tud tárolni (dátum, író, hely,
stb.) Ezeket mi is hozzáadhatjuk (erre majd látunk példát nemsokára)
illetve amikor létrehozzuk a korpuszt a data frame-ünkből, akkor
autómatikusan meta adatokként tárolódnak az változóink. Jelen esetben az
egyetlen dokument változónk az a dátum lesz a szöveg mellett. A korpusz
dokumentum változóihoz a \texttt{docvars()} segíségével tudunk
hozzáférni.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mn\_corpus }\OtherTok{\textless{}{-}} \FunctionTok{corpus}\NormalTok{(mn\_tiszta)}

\FunctionTok{head}\NormalTok{(}\FunctionTok{docvars}\NormalTok{(mn\_corpus), }\DecValTok{5}\NormalTok{)}
\CommentTok{\#\textgreater{}     doc\_date}
\CommentTok{\#\textgreater{} 1 2006{-}01{-}02}
\CommentTok{\#\textgreater{} 2 2006{-}01{-}02}
\CommentTok{\#\textgreater{} 3 2006{-}01{-}02}
\CommentTok{\#\textgreater{} 4 2006{-}01{-}02}
\CommentTok{\#\textgreater{} 5 2006{-}01{-}02}
\end{Highlighting}
\end{Shaded}

A következő lépés a dokument-kifejezés mátrix létrehozása a
\texttt{dfm()} függvénnyel (ami a \emph{document-feature matrix}
rövidítése). Előszőr tokenekre bontjuk a szövegeket a
\texttt{tokens()}-el, és aztán ezt a tokenizált szózsákot kapja meg a
dfm inputnak. A sornak a végén a létrehozott mátrixunkat TF-IDF
módszerrel súlyozzuk a \texttt{dfm\_tfidf()} használatával.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mn\_dfm }\OtherTok{\textless{}{-}}\NormalTok{ mn\_corpus }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{tokens}\NormalTok{(}\AttributeTok{what =} \StringTok{"word"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{dfm}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{dfm\_tfidf}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

A cikkek szentimentjét egy magyar szótárral fogjuk becsülni, amit a
Társadalomtudmányi Kutatóközpont CSS-RECENS és a POLTEXTLab kutatói
készítették.\footnote{A szótár elérhető a könyv online verziójának a
  GitHub repozitorijából. (LINK)} Két dimenziót tarlamaz (pozitív és
negatív), 2299 pozitív és 2588 negatív kulcsszóval. Ez nem számít
kirívóan nagynak a szótárak között, mivel az adott kategóriák minél
teljesebb lefedése a cél. Azt is látjuk, hogy a kulcsszavak egyszavas
tokenek (szóval nem érdemes bigramokat és trigramokat készítenünk a
tokenizálás során), illetve nem szótövek (így szótöveznünk sem kell).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{poltext\_szotar }\OtherTok{\textless{}{-}} \FunctionTok{read\_rds}\NormalTok{(}\StringTok{"data/poltext\_dict.Rds"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{poltext\_szotar}
\CommentTok{\#\textgreater{} Dictionary object with 2 key entries.}
\CommentTok{\#\textgreater{} {-} [positive]:}
\CommentTok{\#\textgreater{}   {-} abszolút, ad, adaptív, adekvát, adócsökkentés, adókedvezmény, adomány, adományoz, adóreform, adottság, adottságú, áfacsökkentés, agilis, agytröszt, áhított, ajándék, ajándékoz, ajánl, ajánlott, akadálytalan [ ... and 2,279 more ]}
\CommentTok{\#\textgreater{} {-} [negative]:}
\CommentTok{\#\textgreater{}   {-} aberrált, abnormális, abnormalitás, abszurd, abszurditás, ádáz, adócsalás, adócsaló, adós, adósság, áfacsalás, áfacsaló, affér, aggasztó, aggodalom, aggódik, aggódás, agresszió, agresszíven, agresszivitás [ ... and 2,568 more ]}
\end{Highlighting}
\end{Shaded}

Az egyes dokumentumok szentimentjét a \texttt{dfm\_lookup()} becsüli,
ahol az előző lépésben létrehozott súlyozott dfm az input és a magyar
szentimentszótár a dictionary. Egy gyors pillantás az eredményre és
látjuk hogy minden dokumentumhoz készült egy pozitív és egy negatív
értéket. A TF-IDF súlyozás miatt nem látunk egész számokat (a súlyozás
nélkül a sima szófrekvenciát kapnánk).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mn\_szentiment }\OtherTok{\textless{}{-}} \FunctionTok{dfm\_lookup}\NormalTok{(mn\_dfm, }\AttributeTok{dictionary =}\NormalTok{ poltext\_szotar)}

\FunctionTok{head}\NormalTok{(mn\_szentiment, }\DecValTok{5}\NormalTok{)}
\CommentTok{\#\textgreater{} Document{-}feature matrix of: 5 documents, 2 features (40.0\% sparse) and 1 docvar.}
\CommentTok{\#\textgreater{}     features}
\CommentTok{\#\textgreater{} docs   positive  negative}
\CommentTok{\#\textgreater{}    1  0          0       }
\CommentTok{\#\textgreater{}    2  0.8375026 12.497973}
\CommentTok{\#\textgreater{}    3  0          0       }
\CommentTok{\#\textgreater{}    4 21.1044299  6.449036}
\CommentTok{\#\textgreater{}    5 11.0358129  8.131890}
\end{Highlighting}
\end{Shaded}

Ahhoz hogy fel tudjuk használni a kapott eredményt, érdemes
dokumentumváltozóként eltárolni a korpuszban. Ezt a fent már használt
\texttt{docvars()} segítségével tudjuk megtenni, ahol a második
argumentumkét az új változó nevét adjuk meg stringként.

\begin{Shaded}
\begin{Highlighting}[]

\FunctionTok{docvars}\NormalTok{(mn\_corpus, }\StringTok{"pos"}\NormalTok{) }\OtherTok{\textless{}{-}} \FunctionTok{as.numeric}\NormalTok{(mn\_szentiment[, }\DecValTok{1}\NormalTok{])}
\FunctionTok{docvars}\NormalTok{(mn\_corpus, }\StringTok{"neg"}\NormalTok{) }\OtherTok{\textless{}{-}} \FunctionTok{as.numeric}\NormalTok{(mn\_szentiment[, }\DecValTok{2}\NormalTok{])}

\FunctionTok{head}\NormalTok{(}\FunctionTok{docvars}\NormalTok{(mn\_corpus), }\DecValTok{5}\NormalTok{)}
\CommentTok{\#\textgreater{}     doc\_date        pos       neg}
\CommentTok{\#\textgreater{} 1 2006{-}01{-}02  0.0000000  0.000000}
\CommentTok{\#\textgreater{} 2 2006{-}01{-}02  0.8375026 12.497973}
\CommentTok{\#\textgreater{} 3 2006{-}01{-}02  0.0000000  0.000000}
\CommentTok{\#\textgreater{} 4 2006{-}01{-}02 21.1044299  6.449036}
\CommentTok{\#\textgreater{} 5 2006{-}01{-}02 11.0358129  8.131890}
\end{Highlighting}
\end{Shaded}

Végül a kapott korpuszt a kiszámolt szentiment értékekkel a
\texttt{quanteda}-ban lévő \texttt{convert()} fügvénnyel data frame-é
alakítjuk. A convert függvény dokumentációját érdemes elolvasni, mert
ennek segítségével tudjuk a \texttt{quanteda}-ban elkeszült
objektumainkat átalakítani úgy, hogy azt más csomagok is tudják
használni.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mn\_df }\OtherTok{\textless{}{-}} \FunctionTok{convert}\NormalTok{(mn\_corpus, }\AttributeTok{to =} \StringTok{"data.frame"}\NormalTok{)}


\FunctionTok{summary}\NormalTok{(mn\_df)}
\CommentTok{\#\textgreater{}     doc\_id              text              doc\_date               pos        }
\CommentTok{\#\textgreater{}  Length:2834        Length:2834        Min.   :2006{-}01{-}02   Min.   : 0.000  }
\CommentTok{\#\textgreater{}  Class :character   Class :character   1st Qu.:2006{-}03{-}29   1st Qu.: 0.000  }
\CommentTok{\#\textgreater{}  Mode  :character   Mode  :character   Median :2006{-}06{-}28   Median : 2.373  }
\CommentTok{\#\textgreater{}                                        Mean   :2006{-}06{-}28   Mean   : 4.074  }
\CommentTok{\#\textgreater{}                                        3rd Qu.:2006{-}09{-}26   3rd Qu.: 6.280  }
\CommentTok{\#\textgreater{}                                        Max.   :2006{-}12{-}29   Max.   :35.648  }
\CommentTok{\#\textgreater{}       neg        }
\CommentTok{\#\textgreater{}  Min.   : 0.000  }
\CommentTok{\#\textgreater{}  1st Qu.: 0.000  }
\CommentTok{\#\textgreater{}  Median : 2.037  }
\CommentTok{\#\textgreater{}  Mean   : 3.528  }
\CommentTok{\#\textgreater{}  3rd Qu.: 5.348  }
\CommentTok{\#\textgreater{}  Max.   :39.096}
\end{Highlighting}
\end{Shaded}

Mielőtt vizualizálnánk az eredményt érdemes a napi szintre aggregálni a
szentimentet és egy nettó értéket kalkulálni.\footnote{A csoportosított
  adatokkal való munka bővebb bemutatását lsd. a Függelékben}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mn\_df }\OtherTok{\textless{}{-}}\NormalTok{ mn\_df }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(doc\_date) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarise}\NormalTok{(}
    \AttributeTok{daily\_pos =} \FunctionTok{sum}\NormalTok{(pos),}
    \AttributeTok{daily\_neg =} \FunctionTok{sum}\NormalTok{(neg),}
    \AttributeTok{net\_daily =}\NormalTok{ daily\_pos }\SpecialCharTok{{-}}\NormalTok{ daily\_neg}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

A plot alapján egyértelmű trendet nem lehet megállapítani és még a
2006-os év végi turbulens belpolitikai események sem feltétlenül
jelennek meg markánsan. Ennek az oka abban is kereshető, hogy egy
napilap címlapját ritkán dominálja teljes egészében a belpolitika és így
a negatív és pozitív szentimentek kioltják egymást. Természetesen
messzemenő következtetéseket egy ábra alapján nem érdemes levonni, de az
elemzésünk azt mutatha hogy a nyári hónapok alatt kevesebb volt az
igazán negatív címlap, ellenben az év eleje és vége tartalmazta a minta
alsó szélső értékeit.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(mn\_df, }\FunctionTok{aes}\NormalTok{(doc\_date, net\_daily)) }\SpecialCharTok{+} \FunctionTok{geom\_line}\NormalTok{() }\SpecialCharTok{+} \FunctionTok{labs}\NormalTok{(}\AttributeTok{y =} \StringTok{"Szentiment"}\NormalTok{, }\AttributeTok{x =} \ConstantTok{NULL}\NormalTok{, }
    \AttributeTok{caption =} \StringTok{"Adatforrás: https://cap.tk.hu/"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{_main_files/figure-latex/unnamed-chunk-80-1} 

}

\caption{Magyar Nemzet címlap szentimentje}\label{fig:unnamed-chunk-80}
\end{figure}

\hypertarget{mnb-sajtuxf3kuxf6zlemuxe9nyek}{%
\section{MNB sajtóközlemények}\label{mnb-sajtuxf3kuxf6zlemuxe9nyek}}

A második esettanulmányban a kotextuális szótár elemzést mutatjuk be egy
angol nyelvű korpusz és specializált szótár segítségével. A korpusz az
MNB kamatdöntéseit kísérő nemzetközi sajtóközleményei és a szótár pedig
a \protect\hyperlink{ref-loughran2011}{Loughran and McDonald}
(\protect\hyperlink{ref-loughran2011}{2011}) pénzügyi
szentimentszótár.\footnote{A témával részletesebben is foglalkoztunk a
  \protect\hyperlink{ref-muxe1tuxe92021}{Máté, Sebők, and Barczikay}
  (\protect\hyperlink{ref-muxe1tuxe92021}{2021}) tanulmányban, ahol egy
  saját monetáris szentiment szótárt mutatunk be. Az implementáció és a
  hozzá tartozó R forráskód a nyilvános
  \url{https://doi.org/10.6084/m9.figshare.13526156.v1} linken.} A
szótár a \texttt{quanteda.dictionaries} csomag részeként elérhető,
illetve a tankönyv honlapján is megtalálható.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{penzugy\_szentiment}
\CommentTok{\#\textgreater{} Dictionary object with 9 key entries.}
\CommentTok{\#\textgreater{} {-} [NEGATIVE]:}
\CommentTok{\#\textgreater{}   {-} abandon, abandoned, abandoning, abandonment, abandonments, abandons, abdicated, abdicates, abdicating, abdication, abdications, aberrant, aberration, aberrational, aberrations, abetting, abnormal, abnormalities, abnormality, abnormally [ ... and 2,335 more ]}
\CommentTok{\#\textgreater{} {-} [POSITIVE]:}
\CommentTok{\#\textgreater{}   {-} able, abundance, abundant, acclaimed, accomplish, accomplished, accomplishes, accomplishing, accomplishment, accomplishments, achieve, achieved, achievement, achievements, achieves, achieving, adequately, advancement, advancements, advances [ ... and 334 more ]}
\CommentTok{\#\textgreater{} {-} [UNCERTAINTY]:}
\CommentTok{\#\textgreater{}   {-} abeyance, abeyances, almost, alteration, alterations, ambiguities, ambiguity, ambiguous, anomalies, anomalous, anomalously, anomaly, anticipate, anticipated, anticipates, anticipating, anticipation, anticipations, apparent, apparently [ ... and 277 more ]}
\CommentTok{\#\textgreater{} {-} [LITIGIOUS]:}
\CommentTok{\#\textgreater{}   {-} abovementioned, abrogate, abrogated, abrogates, abrogating, abrogation, abrogations, absolve, absolved, absolves, absolving, accession, accessions, acquirees, acquirors, acquit, acquits, acquittal, acquittals, acquittance [ ... and 883 more ]}
\CommentTok{\#\textgreater{} {-} [CONSTRAINING]:}
\CommentTok{\#\textgreater{}   {-} abide, abiding, bound, bounded, commit, commitment, commitments, commits, committed, committing, compel, compelled, compelling, compels, comply, compulsion, compulsory, confine, confined, confinement [ ... and 164 more ]}
\CommentTok{\#\textgreater{} {-} [SUPERFLUOUS]:}
\CommentTok{\#\textgreater{}   {-} aegis, amorphous, anticipatory, appertaining, assimilate, assimilating, assimilation, bifurcated, bifurcation, cessions, cognizable, concomitant, correlative, deconsolidation, delineation, demonstrable, demonstrably, derecognized, derecognizes, derivatively [ ... and 36 more ]}
\CommentTok{\#\textgreater{} [ reached max\_nkey ... 3 more keys ]}
\end{Highlighting}
\end{Shaded}

A szentiment szótár 9 kategóriából áll. A legtöbb kulcsszó a negatív
dimenzióhoz van (2355).

A munkamenet hasonló a Magyar Nemzetes példához:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  adat betöltés
\item
  szövegtisztítás
\item
  korpusz
\item
  tokenek
\item
  kulcs kontextuális tokenek szűrése
\item
  dfm előállítás és szentiment számítás
\item
  az eredmény vizualizálása, további felhasználása
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mnb\_pr }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(}\StringTok{"data/mnb\_pr\_corpus.csv"}\NormalTok{)}

\FunctionTok{summary}\NormalTok{(mnb\_pr)}
\CommentTok{\#\textgreater{}       date                text                 id              year     }
\CommentTok{\#\textgreater{}  Min.   :2005{-}01{-}24   Length:180         Min.   :  1.00   Min.   :2005  }
\CommentTok{\#\textgreater{}  1st Qu.:2008{-}10{-}14   Class :character   1st Qu.: 45.75   1st Qu.:2008  }
\CommentTok{\#\textgreater{}  Median :2012{-}07{-}10   Mode  :character   Median : 90.50   Median :2012  }
\CommentTok{\#\textgreater{}  Mean   :2012{-}07{-}08                      Mean   : 90.50   Mean   :2012  }
\CommentTok{\#\textgreater{}  3rd Qu.:2016{-}03{-}30                      3rd Qu.:135.25   3rd Qu.:2016  }
\CommentTok{\#\textgreater{}  Max.   :2019{-}12{-}17                      Max.   :180.00   Max.   :2019}
\end{Highlighting}
\end{Shaded}

Az adatbázisunk 180 megfigyelésből és 4 változóbol áll. Az egyetlen
lényeges dokumentum meta adat itt is a szövegek megjelenési ideje.

A szövegeket ugyanazokkal a standard eszközökkel kezeljük mint a Magyar
Nemzet esetében. Érdemes minden esetben ellenőrízni, hogy az R kód amit
használunk az tényleg azt csinálja-e mint amit szeretnénk hogy
csináljon. Ez hatványozottan igaz abban az esetben, amikor szövegekkel
és regular expressionökkel dolgozunk.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mnb\_tiszta }\OtherTok{\textless{}{-}}\NormalTok{ mnb\_pr }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{text =} \FunctionTok{str\_remove\_all}\NormalTok{(}\AttributeTok{string =}\NormalTok{ text, }\AttributeTok{pattern =} \StringTok{"[:cntrl:]"}\NormalTok{),}
    \AttributeTok{text =} \FunctionTok{str\_remove\_all}\NormalTok{(}\AttributeTok{string =}\NormalTok{ text, }\AttributeTok{pattern =} \StringTok{"[:punct:]"}\NormalTok{),}
    \AttributeTok{text =} \FunctionTok{str\_remove\_all}\NormalTok{(}\AttributeTok{string =}\NormalTok{ text, }\AttributeTok{pattern =} \StringTok{"[:digit:]"}\NormalTok{),}
    \AttributeTok{text =} \FunctionTok{str\_to\_lower}\NormalTok{(text),}
    \AttributeTok{text =} \FunctionTok{str\_trim}\NormalTok{(text),}
    \AttributeTok{text =} \FunctionTok{str\_squish}\NormalTok{(text)}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

Miután rendelkezésre állnak a tiszta dokumentumaink, egy
karaktervektorba gyüjtjuk azokat a kulcsszavakat amelyek környékén
szeretnénk megfigyelni a szentiment alakulását. A példa kedvéért mi az
\texttt{unemp*}, \texttt{growth}, \texttt{gdp}, \texttt{inflation*}
szótöveket és szavakat választottuk. A \texttt{tokens\_keep()} megtartja
a kulcsszavainkat és egy általunk megadott +/- n tokenes környezetüket
(jelen esetben 10). A szentiment elemzést pedig már ezen a jóval kisebb
mátrixon fogjuk lefuttatni. A \texttt{phrase()} segítségével több szóból
álló kifejezéséket is vizsgálhatunk. Ilyen szókapcsolat például az
\emph{Európai Unió} is, ahol lényeges hogy egyben kezeljük a két szót.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mnb\_corpus }\OtherTok{\textless{}{-}} \FunctionTok{corpus}\NormalTok{(mnb\_tiszta)}

\NormalTok{gazdasag }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"unemp*"}\NormalTok{, }\StringTok{"growth"}\NormalTok{, }\StringTok{"gdp"}\NormalTok{, }\StringTok{"inflation*"}\NormalTok{, }\StringTok{"inflation expectation*"}\NormalTok{)}

\NormalTok{mnb\_token }\OtherTok{\textless{}{-}} \FunctionTok{tokens}\NormalTok{(mnb\_corpus) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{tokens\_keep}\NormalTok{(}\AttributeTok{pattern =} \FunctionTok{phrase}\NormalTok{(gazdasag), }\AttributeTok{window =} \DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

A szentimentet most is egy súlyozott dfm-ből számoljuk. A kész eredményt
hozzáadjuk a korpuszhoz majd data framet hozunk létre belőle. A 9
kategóriából 5-öt adunk választunk csak ki, amelyeknek jegybanki
környezetben értelmezhető tartalma van.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mnb\_szentiment }\OtherTok{\textless{}{-}} \FunctionTok{tokens\_lookup}\NormalTok{(mnb\_token, }\AttributeTok{dictionary =}\NormalTok{ penzugy\_szentiment) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{dfm}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{dfm\_tfidf}\NormalTok{()}

\FunctionTok{docvars}\NormalTok{(mnb\_corpus, }\StringTok{"negative"}\NormalTok{) }\OtherTok{\textless{}{-}} \FunctionTok{as.numeric}\NormalTok{(mnb\_szentiment[, }\StringTok{"negative"}\NormalTok{])}
\FunctionTok{docvars}\NormalTok{(mnb\_corpus, }\StringTok{"positive"}\NormalTok{) }\OtherTok{\textless{}{-}} \FunctionTok{as.numeric}\NormalTok{(mnb\_szentiment[, }\StringTok{"positive"}\NormalTok{])}
\FunctionTok{docvars}\NormalTok{(mnb\_corpus, }\StringTok{"uncertainty"}\NormalTok{) }\OtherTok{\textless{}{-}} \FunctionTok{as.numeric}\NormalTok{(mnb\_szentiment[, }\StringTok{"uncertainty"}\NormalTok{])}
\FunctionTok{docvars}\NormalTok{(mnb\_corpus, }\StringTok{"constraining"}\NormalTok{) }\OtherTok{\textless{}{-}} \FunctionTok{as.numeric}\NormalTok{(mnb\_szentiment[, }\StringTok{"constraining"}\NormalTok{])}
\FunctionTok{docvars}\NormalTok{(mnb\_corpus, }\StringTok{"superfluous"}\NormalTok{) }\OtherTok{\textless{}{-}} \FunctionTok{as.numeric}\NormalTok{(mnb\_szentiment[, }\StringTok{"superfluous"}\NormalTok{])}

\NormalTok{mnb\_df }\OtherTok{\textless{}{-}} \FunctionTok{convert}\NormalTok{(mnb\_corpus, }\AttributeTok{to =} \StringTok{"data.frame"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

A célunk hogy szentiment kategóriánkénti bontásban mutassuk be az
elemzésünk eredményét, de előtte egy kicsit alakítani kell a data
frame-n, hogy a második fejezetben is tárgyalt \emph{tidy} formára
hozzuk. A különböző szentiment értékeket tartalmazó oszlopokat fogjuk
átrendezni úgy hogy kreálunk egy ``sent\_type'' változót ahol a
kategória nevet fogjuk eltárolni és egy ``sent\_score'' változót, ahol a
szentiment értéket. Ehhez a \texttt{tidyr}-ben található
\texttt{pivot\_longer()} -t használjuk.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mnb\_df }\OtherTok{\textless{}{-}}\NormalTok{ mnb\_df }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{pivot\_longer}\NormalTok{(}
    \AttributeTok{cols =}\NormalTok{ negative}\SpecialCharTok{:}\NormalTok{superfluous,}
    \AttributeTok{names\_to =} \StringTok{"sent\_type"}\NormalTok{,}
    \AttributeTok{values\_to =} \StringTok{"sent\_score"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

Az átalakítás után már könnyedén tudjuk kategóriákra bontva
megjeleníteni az MNB közlemények különböző látens dimenzióit. Fontos
emlékezni arra, hogy ez az eredmény a kulcsszavaink +/- 10 tokenes
környezetében lévő szavak szentimentjét mérik. Ami érdekes eredmény,
hogy a felesleges ``töltelék'' szövegek (superflous kategória) szinte
soha nem fordulnak elő a kulcsszavaink körül. A többi érték is nagyjából
megfelel a várakozásainknak, habár a 2008-as gazdasági válság nem tűnik
kiugró pontnak. Azonban a 2010 utáni európai válság már láthatóan
megjelnik az idősorainkban.

A szótár amit használtunk az alapvetően az Egyesült Államokban a tőzsdén
kereskedett cégek publikus beszámolóiból készült így elképzelhető, hogy
egyes jegybanki környezetben sokat használt kifejezés nincs benne. A
validálása a kapott eredményeknek ezért is nagyon fontos, illetve
érdemes azzal is tisztában lenni hogy a szótáras módszer nem tökéletes
(ahogy az emberi vagy más gépi kódolás sem).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(mnb\_df, }\FunctionTok{aes}\NormalTok{(date, sent\_score)) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{y =} \StringTok{"Szentiment"}\NormalTok{,}
    \AttributeTok{x =} \ConstantTok{NULL}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{sent\_type, }\AttributeTok{ncol =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{_main_files/figure-latex/unnamed-chunk-88-1} 

}

\caption{Magyar Nemzeti Bank közleményeinek szentimentje}\label{fig:unnamed-chunk-88}
\end{figure}

\hypertarget{feluxfcgyelet-nuxe9lkuxfcli-tanuluxe1s-topik-modellezuxe9s-magyar-tuxf6rvuxe9nyszuxf6vegeken}{%
\chapter{Felügyelet nélküli tanulás: Topik modellezés magyar
törvényszövegeken}\label{feluxfcgyelet-nuxe9lkuxfcli-tanuluxe1s-topik-modellezuxe9s-magyar-tuxf6rvuxe9nyszuxf6vegeken}}

A klaszterezés egy adathalmaz pontjainak, rekordjainak hasonlóság
alapján való csoportosítása, ami szinte minden nagyméretű adathalmaz
leíró modellezésére alkalmas. A klaszterezés során az adatpontokat
diszjunkt halmazokba, azaz klaszterekbe soroljuk, hogy az elemeknek egy
olyan partíciója jöjjön létre, amelyben a közös csoportokba kerülő
elempárok lényegesen hasonlóbbak egymáshoz, mint azok a pontpárok,
melyek két különböző csoportba sorolódtak. Klaszterezés során a
megfelelő csoportok kialakítása nem egyértelmű feladat, mivel a
különböző adatok eltérő jelentése és felhasználása miatt
adathalmazonként más szempontokat kell figyelembe vennünk. Egy
klaszterezési feladat megoldásához ismernünk kell a különböző
algoritmusok alapvető tulajdonságait és mindig szükség van az
eredményként kapott klaszterezés kiértékelésére. Mivel egy klaszterezés
az adatpontok hasonlóságából indul ki, ezért az eljárás során az első
fontos lépés az adatpontok páronkénti hasonlóságát lehető legjobban
megragadó hasonlósági függvény kiválasztása
\protect\hyperlink{ref-tan2011a}{Tan, Steinbach, and Kumar}
(\protect\hyperlink{ref-tan2011a}{2011}). Számos klaszterezési eljárás
létezik, melyek között az egyik leggyakoribb különbségtétel, hogy a
klaszterek egymásba ágyazottak vagy sem. Ez alapján beszélhetünk
hierarchikus és felosztó klaszterezésről.

A hierarchikus klaszterezés egymásba ágyazott klaszterek egy fába
rendezett halmaza, azaz ahol a klaszterek alklaszterekkel rendelkeznek.
A fa minden csúcsa (klasztere), a levélcsúcsokat kivéve, a gyermekei
(alklaszterei) uniója, és a fa gyökere az összes objektumot tartalmazó
klaszter. Felosztó (partitional) klaszterezés esetén az adathalmazt
olyan, nem átfedő alcsoportokra bontjuk, ahol minden adatobjektum
pontosan egy részhalmazba kerül \protect\hyperlink{ref-tan2011a}{Tan,
Steinbach, and Kumar} (\protect\hyperlink{ref-tan2011a}{2011}),
\protect\hyperlink{ref-tikk2007}{Tikk}
(\protect\hyperlink{ref-tikk2007}{2007a}). A klaszterezési eljárások
között aszerint is különbséget tehetünk, hogy azok egy objektumot csak
egy vagy több klaszterbe is beilleszthetnek. Ez alapján beszélhetünk
kizáró (exclusive), illetve nem-kizáró (non exclusive), vagy átfedő
(overlapping) klaszterezésről. Az előbbi minden objektumot csak egyetlen
klaszterhez rendel hozzá, az utóbbi esetén egy pont több klaszterbe is
beleillik. Fuzzy klaszterezés esetén minden objektum minden klaszterbe
beletartozik egy tagsági súly erejéig, melynek értéke 0 (egyáltalán nem
tartozik bele) és 1 (teljesen beletartozik) közé esik. A klasztereknek
is különböző típusai vannak, így beszélhetünk prototípus-alapú,
gráf-alapú vagy sűrűség-alapú klaszterekről.

A prototípus-alapú klaszter olyan objektumokat tartalmazó halmaz,
amelynek mindegyik objektuma jobban hasonlít a klasztert definiáló
objektumhoz, mint bármelyik másik klasztert definiáló objektumhoz. A
prototípus-alapú klaszter klaszterek közül a K-közép klaszter az egyik
leggyakrabban alkalmazott. A K-közép klaszterezési módszer első lépése K
darab kezdő középpontot kijelölése, ahol K a klaszterek kívánt számával
egyenlő. Ezután minden adatpontot a hozzá legközelebb eső középponthoz
rendelünk. Az így képzett csoportok lesznek a kiinduló klaszterek.
Ezután újra meghatározzuk mindegyik klaszter középpontját a klaszterhez
rendelt pontok alapján. A hozzárendelési és frissítési lépéseket
felváltva folytatjuk addig, amíg egyetlen pont sem vált klasztert, vagy
ameddig a középpontok ugyanazok nem maradnak
\protect\hyperlink{ref-tan2011a}{Tan, Steinbach, and Kumar}
(\protect\hyperlink{ref-tan2011a}{2011}).

\hypertarget{k-kuxf6zuxe9p-klaszterezuxe9s-kvalitatuxedv-adatokkal}{%
\section{K közép klaszterezés kvalitatív
adatokkal}\label{k-kuxf6zuxe9p-klaszterezuxe9s-kvalitatuxedv-adatokkal}}

A K közép klaszterezés tehát a dokumentumokat alkotó szavak alapján
keresi meg a felhasználó által megadott számú (K) klasztert, amelyeket a
középpontjaik képviselnek, és így rendezi a dokumentumokat csoportokba.
A klaszterezés vagy csoportosítás egy induktív kategorizálás, ami akkor
hasznos, amikor nem állnak a kutató rendelkezésére előzetesen ismert
csoportok, amelyek szerint a vizsgált dokumentumokat rendezni tudná.
Hiszen ebben az esetben a korpusz elemeinek rendezéséhez nem határozunk
meg előzetesen csoportokat, hanem az eljárás során olyan különálló
csoportokat hozunk létre a dokumentumokból, amelynek tagjai valamilyen
szempontból hasonlítanak egymásra. A csoportosítás legfőbb célja az,
hogy az egy csoportba kerülő szövegek minél inkább hasonlítsanak
egymásra, miközben a különböző csoportba kerülők minél inkább eltérjenek
egymástól. Azaz klaszterezésnél nem egy-egy szöveg jellemzőire vagyunk
kíváncsiak, hanem arra, hogy a szövegek egy-egy csoportja milyen
hasonlóságokkal bír \protect\hyperlink{ref-tikk2007}{Tikk}
(\protect\hyperlink{ref-tikk2007}{2007a}),
\protect\hyperlink{ref-burtejin2016}{Burtejin}
(\protect\hyperlink{ref-burtejin2016}{2016}). A gépi kódolással végzett
klaszterezés egy felügyelet nélküli tanulás, mely a szöveg
tulajdonságaiból tanul, anélkül, hogy előre meghatározott csoportokat
ismerne. Alkalmazása során a dokumentum tulajdonságait és a modell
becsléseit felhasználva jönnek létre a különböző kategóriák, melyekhez
később hozzárendeli a szöveget
\protect\hyperlink{ref-grimmer2013texta}{Grimmer and Stewart}
(\protect\hyperlink{ref-grimmer2013texta}{2013b}) . Az osztályozással
ellentétben a csoportosítás esetén tehát nincs ismert „címkékkel"
ellátott kategóriarendszer vagy olyan minta, mint az osztályozás
esetében a tanítókörnyezet, amiből tanulva a modellt fel lehet építeni
\protect\hyperlink{ref-tikk2007}{Tikk}
(\protect\hyperlink{ref-tikk2007}{2007a}). A gépi kódolással végzett
csoportosítás (klaszterezés) esetén a kutató feladata a megfelelő
csoportosító mechanizmus kiválasztása, mely alapján egy program végzi el
a szövegek különböző kategóriákba sorolását. Ezt követi a hasonló
szövegeket tömörítő csoportok elnevezésének lépése. A több dokumentumból
álló korpuszok esetében a gépi klaszterelemzés különösen eredményes és
költséghatékony lehet, mivel egy nagy korpusz vizsgálata sok erőforrást
igényel @grimmer2013texta:1.

A klaszterezés bemutatásához a rendszerváltás utáni magyar
miniszterelnökök egy-egy véletlenszerűen kiválasztott beszédét
használjuk.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(readr)}
\FunctionTok{library}\NormalTok{(dplyr)}
\FunctionTok{library}\NormalTok{(purrr)}
\FunctionTok{library}\NormalTok{(stringr)}
\FunctionTok{library}\NormalTok{(readtext)}
\FunctionTok{library}\NormalTok{(quanteda)}
\FunctionTok{library}\NormalTok{(tidytext)}
\FunctionTok{library}\NormalTok{(ggplot2)}
\FunctionTok{library}\NormalTok{(topicmodels)}
\FunctionTok{library}\NormalTok{(factoextra)}
\FunctionTok{library}\NormalTok{(stm)}
\FunctionTok{library}\NormalTok{(igraph)}
\end{Highlighting}
\end{Shaded}

A beszédek szövege meglehetősen tiszta, ezért az egyszerűség kedvéért a
most kihagyjuk a szövegtisztítás lépéseit. Az elemzés első lépéseként a
\texttt{quanteda} csomaggal egy korpusz kreálunk, majd abból egy
dokumentum-kifejezés mátrixot készítünk a \texttt{dfm()} függvénnyel.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{beszedek }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(}\StringTok{"data/miniszterelnokok.csv"}\NormalTok{)}

\NormalTok{beszedek\_corpus }\OtherTok{\textless{}{-}} \FunctionTok{corpus}\NormalTok{(beszedek)}

\NormalTok{beszedek\_dfm }\OtherTok{\textless{}{-}} \FunctionTok{dfm}\NormalTok{(beszedek\_corpus)}
\end{Highlighting}
\end{Shaded}

A beszédek klaszterekbe rendezését az R egyik alapfüggvénye végzi, a
\texttt{kmeans}. Első lépésben 3 klasztert készítünk. A \texttt{table()}
függvénnyel megnézhetjük hogy egy-egy csoportba hány dokumentum került.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{beszedek\_klaszter }\OtherTok{\textless{}{-}} \FunctionTok{kmeans}\NormalTok{(beszedek\_dfm, }\AttributeTok{centers =} \DecValTok{2}\NormalTok{)}


\FunctionTok{table}\NormalTok{(beszedek\_klaszter}\SpecialCharTok{$}\NormalTok{cluster)}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} 1 2 }
\CommentTok{\#\textgreater{} 5 2}
\end{Highlighting}
\end{Shaded}

A felügyelet nélküli klasszifikáció nagy kérdése, hogy hány klasztert
készítsünk, hogy megközelítsük a valóságot és ne csak mesterségesen
kreáljunk csoportokat abban az esetben is amikor ténylegesen nem
léteznek. A kvalitatív megközelítések mellett kvantitatív opciók is
vannak. A \texttt{factoextra} csomagban több ilyen módszer is van
implementálva. A lenti ábra azt mutatja hogy a klasztereken belüli
négyzetösszegek hogyan változnak a \emph{k} paraméter változásának
függvényében. A lenti ábra alapján az ideális klaszter szám 2.

\begin{Shaded}
\begin{Highlighting}[]

\FunctionTok{fviz\_nbclust}\NormalTok{(}\FunctionTok{as.matrix}\NormalTok{(beszedek\_dfm), kmeans, }\AttributeTok{method =} \StringTok{"wss"}\NormalTok{, }\AttributeTok{k.max =} \DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{_main_files/figure-latex/unnamed-chunk-93-1} \end{center}

Vizuálisan is megjeleníthetjük a kialakított csoportokat.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{fviz\_cluster}\NormalTok{(beszedek\_klaszter, }\AttributeTok{data =}\NormalTok{ beszedek\_dfm)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{_main_files/figure-latex/unnamed-chunk-94-1} \end{center}

\hypertarget{luxe1tens-dirichlet-allokuxe1ciuxf3-topik-modellekklasztering_topicmodellek-1}{%
\section[Látens Dirichlet Allokáció topik
modellek]{\texorpdfstring{Látens Dirichlet Allokáció topik
modellek\footnote{a kód részben az alábbiakon alapul:
  tidytextmining.com/topicmodeling.html Az általunk is használt
  \texttt{topicmodels} csomag interfészt biztosít az LDA modellek és a
  korrelált témamodellek (CTM) C kódjához, valamint az LDA modellek
  illesztéséhez szükséges C ++ kódhoz.}}{Látens Dirichlet Allokáció topik modellek}}\label{luxe1tens-dirichlet-allokuxe1ciuxf3-topik-modellekklasztering_topicmodellek-1}}

A topik-modellezés a dokumentumok téma-klasztereinek meghatározására
szolgáló valószínűség-alapú eljárás, amely szó-gyakoriságot állapít meg
minden témához, és minden dokumentumhoz hozzárendeli az adott témák
valószínűségét. A topik modellezés egy felügyelet nélküli tanulási
módszer, amely során az alkalmazott algoritmus a dokumentum
tulajdonságait és a modell becsléseit felhasználva hoz létre különböző
kategóriákat, melyekhez később hozzárendeli a szöveget
\protect\hyperlink{ref-tikk2007a}{Tikk}
(\protect\hyperlink{ref-tikk2007a}{2007b}),
\protect\hyperlink{ref-grimmer2013texta}{Grimmer and Stewart}
(\protect\hyperlink{ref-grimmer2013texta}{2013b}),
\protect\hyperlink{ref-burtejin2016}{Burtejin}
(\protect\hyperlink{ref-burtejin2016}{2016}) . Az egyik leggyakrabban
alkalmazott topik modellezési eljárás, a Látens Dirichlet Allokáció
(LDA) alapja az a feltételezés, hogy minden korpusz topikok/témák
keverékéből áll, ezen témák pedig statisztikailag a korpusz szókészlete
valószínűségi függvényeinek (eloszlásának) tekinthetőek
\protect\hyperlink{ref-blei2003}{Blei, Ng, and Jordan}
(\protect\hyperlink{ref-blei2003}{2003}) . Az LDA a korpusz
dokumentumainak csoportosítása során az egyes dokumentumokhoz topik
szavakat rendel, a topikok megbecsléséhez pedig a szavak együttes
megjelenését vizsgálja a dokumentum egészében. Az LDA algoritmusnak
előzetesen meg kell adni a keresett klaszterek (azaz a keresett topikok)
számát, ezt követően a dokumentumhalmazban szereplő szavak eloszlása
alapján az algoritmus azonosítja a kulcsszavakat, amelyek eloszlása
kirajzolja a topikokat \protect\hyperlink{ref-blei2003}{Blei, Ng, and
Jordan} (\protect\hyperlink{ref-blei2003}{2003}),
\protect\hyperlink{ref-burtejin2016}{Burtejin}
(\protect\hyperlink{ref-burtejin2016}{2016}),
\protect\hyperlink{ref-jacobi2016a}{Jacobi, Van Atteveldt, and Welbers}
(\protect\hyperlink{ref-jacobi2016a}{2016}) .

\begin{center}\includegraphics[width=0.9\linewidth]{figures/08-01_topik_modell} \end{center}

A következőkben a magyar törvények korpuszán szemléltetjük a topik
modellezés módszerét, hogy a mesterséges intelligencia segítségével
feltárjuk a korpuszon belüli rejtett összefüggéseket. A korábban leírtak
szerint tehát nincsenek előre meghatározott kategóriáink,
dokumentumainkat a klaszterezés segítségével szeretnénk csoportosítani.
Egy-egy dokumentumban keveredhetnek a témák és az azokat reprezentáló
szavak. Mivel ugyanaz a szó több topikhoz is kapcsolódhat, így az
eljárás komplex elemzési lehetőséget nyújt, az egy szövegen belül témák
és akár azok dokumentumon belüli súlyának azonosítására. Példánkban csak
a korpusz egy részén szemléltetjük a topik modellezést, a teljes korpusz
és annak elemzéséhez szükséges kód elérhető az alábbi github linken:
\url{https://github.com/poltextlab}

Az alábbiakban 1998-2002 és a 2002-2006-os parlamenti ciklus 1032
törvényszövegének topik modellezését és a szükséges előkészítő,
korpusztisztító lépéseket mutatjuk be. Az következőkben használt fájlok
letölthetőek az alábbi github linkről:
\url{https://github.com/poltextlab/text_mining_with_r} A fájlokat
töltsük be az R által használt munkakönyvtárba.\footnote{A teljes
  törvényeket és a metadatokat tartalmazó adatbázisokat a
  \url{https://cap.tk.hu/} honlapról lehet letölteni.}

Töltsük be az elemezni kívánt csv fájlt, megadva az elérési útvonalát.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{torvenyek }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(}\StringTok{"data/lawtext\_1998\_2006.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Az előző fejezetekben láthattuk hogy hogyan lehet használni a
\texttt{stringr} csomagot a szövegtisztításra. A lépések a már megismert
sztenderd folyamatot követik: számok, központozás, sortörések, extra
szóközök eltávolítása, illetve a szöveg kisbetűsítése. Az eddigieket
további szövegtisztító lépésekkel is kiegészíthetjük. Olyan elemek
esetében, amelyek nem feltétlenül különálló szavak és el akarjuk
távolítani őket a korpuszból szintén az \texttt{str\_remove\_all()} a
legegyszerűbb megoldás.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{torvenyek\_tiszta }\OtherTok{\textless{}{-}}\NormalTok{ torvenyek }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{text =} \FunctionTok{str\_remove\_all}\NormalTok{(}\AttributeTok{string =}\NormalTok{ text, }\AttributeTok{pattern =} \StringTok{"[:cntrl:]"}\NormalTok{),}
    \AttributeTok{text =} \FunctionTok{str\_remove\_all}\NormalTok{(}\AttributeTok{string =}\NormalTok{ text, }\AttributeTok{pattern =} \StringTok{"[:punct:]"}\NormalTok{),}
    \AttributeTok{text =} \FunctionTok{str\_remove\_all}\NormalTok{(}\AttributeTok{string =}\NormalTok{ text, }\AttributeTok{pattern =} \StringTok{"[:digit:]"}\NormalTok{),}
    \AttributeTok{text =} \FunctionTok{str\_to\_lower}\NormalTok{(text),}
    \AttributeTok{text =} \FunctionTok{str\_trim}\NormalTok{(text),}
    \AttributeTok{text =} \FunctionTok{str\_squish}\NormalTok{(text),}
    \AttributeTok{text =} \FunctionTok{str\_remove\_all}\NormalTok{(}\AttributeTok{string =}\NormalTok{ text, }\AttributeTok{pattern =} \StringTok{"’"}\NormalTok{),}
    \AttributeTok{text =} \FunctionTok{str\_remove\_all}\NormalTok{(}\AttributeTok{string =}\NormalTok{ text, }\AttributeTok{pattern =} \StringTok{"…"}\NormalTok{),}
    \AttributeTok{text =} \FunctionTok{str\_remove\_all}\NormalTok{(}\AttributeTok{string =}\NormalTok{ text, }\AttributeTok{pattern =} \StringTok{"–"}\NormalTok{),}
    \AttributeTok{text =} \FunctionTok{str\_remove\_all}\NormalTok{(}\AttributeTok{string =}\NormalTok{ text, }\AttributeTok{pattern =} \StringTok{"“"}\NormalTok{),}
    \AttributeTok{text =} \FunctionTok{str\_remove\_all}\NormalTok{(}\AttributeTok{string =}\NormalTok{ text, }\AttributeTok{pattern =} \StringTok{"”"}\NormalTok{),}
    \AttributeTok{text =} \FunctionTok{str\_remove\_all}\NormalTok{(}\AttributeTok{string =}\NormalTok{ text, }\AttributeTok{pattern =} \StringTok{"„"}\NormalTok{),}
    \AttributeTok{text =} \FunctionTok{str\_remove\_all}\NormalTok{(}\AttributeTok{string =}\NormalTok{ text, }\AttributeTok{pattern =} \StringTok{"«"}\NormalTok{),}
    \AttributeTok{text =} \FunctionTok{str\_remove\_all}\NormalTok{(}\AttributeTok{string =}\NormalTok{ text, }\AttributeTok{pattern =} \StringTok{"»"}\NormalTok{),}
    \AttributeTok{text =} \FunctionTok{str\_remove\_all}\NormalTok{(}\AttributeTok{string =}\NormalTok{ text, }\AttributeTok{pattern =} \StringTok{"§"}\NormalTok{),}
    \AttributeTok{text =} \FunctionTok{str\_remove\_all}\NormalTok{(}\AttributeTok{string =}\NormalTok{ text, }\AttributeTok{pattern =} \StringTok{"°"}\NormalTok{),}
    \AttributeTok{text =} \FunctionTok{str\_remove\_all}\NormalTok{(}\AttributeTok{string =}\NormalTok{ text, }\AttributeTok{pattern =} \StringTok{"\textless{}U+25A1\textgreater{}"}\NormalTok{),}
    \AttributeTok{text =} \FunctionTok{str\_remove\_all}\NormalTok{(}\AttributeTok{string =}\NormalTok{ text, }\AttributeTok{pattern =} \StringTok{"@"}\NormalTok{)}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

A dokumentum változókat egy külön fájlból adjuk hozzá, ami a törvények
keletkezési évét tartalmazza, illetve hogy melyik kormányzati ciklusban
születtek. Mindkét adatbázisban egy közös egyedi azonosító jelöli az
egyes törvényeket, így ki tudjuk használni a \texttt{dplyr}
\texttt{left\_join()} függvényét, ami hatékonyan és gyorsan kapcsol
össze adatbázisokat közös egyedi azonosító mentén. Jelen esetben ez az
egyedi azonosító a \texttt{txt\_filename} oszlopból fog elkészülni,
amely a torvenyek neveit tartalmazza. Első lépésben betöltjük a meta
adatokat tartalmazó .csv fájlt, majd a \texttt{.txt} rész előtti
törvényneveket tartjuk csak meg a létrehozott \texttt{doc\_id}-
oszlopban. A \texttt{{[}\^{}\textbackslash{}\textbackslash{}.{]}*}
regular expression itt a string elejétől indulva kijelöl mindent az elso
\texttt{.} karakterig. Az \texttt{str\_extract()} pedig ezt a kijelölt
string szakaszt (ami a törvények neve) menti át az új változónkba.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{torveny\_meta }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(}\StringTok{"data/cap\_law\_meta.csv"}\NormalTok{)}

\NormalTok{torveny\_meta }\OtherTok{\textless{}{-}}\NormalTok{ torveny\_meta }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{doc\_id =} \FunctionTok{str\_extract}\NormalTok{(txt\_filename, }\StringTok{"[\^{}}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{.]*"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{txt\_filename)}

\FunctionTok{head}\NormalTok{(torveny\_meta, }\DecValTok{5}\NormalTok{)}
\CommentTok{\#\textgreater{} \# A tibble: 5 x 4}
\CommentTok{\#\textgreater{}    year electoral\_cycle majortopic doc\_id     }
\CommentTok{\#\textgreater{}   \textless{}dbl\textgreater{} \textless{}chr\textgreater{}                \textless{}dbl\textgreater{} \textless{}chr\textgreater{}      }
\CommentTok{\#\textgreater{} 1  1998 1998{-}2002               13 1998XXXV   }
\CommentTok{\#\textgreater{} 2  1998 1998{-}2002               20 1998XXXVI  }
\CommentTok{\#\textgreater{} 3  1998 1998{-}2002                3 1998XXXVII }
\CommentTok{\#\textgreater{} 4  1998 1998{-}2002                6 1998XXXVIII}
\CommentTok{\#\textgreater{} 5  1998 1998{-}2002               13 1998XXXIX}
\end{Highlighting}
\end{Shaded}

Végül összefűzzük a dokumentumokat és a meta adatokat tartalmazó data
frameket.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{torveny\_final }\OtherTok{\textless{}{-}} \FunctionTok{left\_join}\NormalTok{(torvenyek\_tiszta, torveny\_meta, }\AttributeTok{by =} \StringTok{"doc\_id"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Majd hozzuk létre a korpuszt és ellenőrizzük azt.

\begin{verbatim}
#>       Text Types Tokens Sentences year electoral_cycle majortopic
#> 1    1998L  2879   9628         1 1998       1998-2002          3
#> 2   1998LI   352    680         1 1998       1998-2002         20
#> 3  1998LII   446    992         1 1998       1998-2002          9
#> 4 1998LIII   126    221         1 1998       1998-2002          9
#> 5  1998LIV   835   2013         1 1998       1998-2002          9
\end{verbatim}

Az RStudio environments fülén láthatjuk, hogy egy 1032 elemből álló
korpusz jött létre, amelynek tartalmát a \texttt{summary()} paranccsal
kiíratva a console ablakban megjelenik a dokumentumok listája és a főbb
leíró statisztikai adatok (egyedi szavak - types; szószám - tokens;
mondatok - sentences). Az előbbi fejezettől eltérően most a tokenizálás
során is végzünk még egy kis tisztítást: a felesleges stop szavakat
kitöröljük a \texttt{tokens\_remove()} és \texttt{stopwords()}
kombinálásával. A \texttt{quanteda} tartalmaz egy beépített magyar
stopszó szótárat. A második lépésben szótövesítjük a tokeneket a
\texttt{tokens\_words()} használatával, ami szintén képes a magyar
nyelvű szövegeket kezelni.

Szükség esetén a beépített magyar nyelvű stopszó szótárat saját
stopszavakkal is kiegészíthetjük. Ehhez először \texttt{csv} fájlba el
kell mentenünk a stopszavakat, majd a \texttt{csv} fájlt be kell
olvasnunk. Az \texttt{pull()} egy karaktervektort fog kreálni a data
frame \texttt{text} oszlopából.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{custom\_stopwords }\OtherTok{\textless{}{-}} \FunctionTok{readtext}\NormalTok{(}\StringTok{"data/custom\_legal\_stopwords.csv"}\NormalTok{, }\AttributeTok{encoding =} \StringTok{"UTF8"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{pull}\NormalTok{(text)}
\end{Highlighting}
\end{Shaded}

Mivel jogi szövegekről van szó, ezért még egy kis extra szószedetet is
készítűnk a felesleges szavakról.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{custom\_stopwords\_egyeb }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"lábjegyzet"}\NormalTok{, }\StringTok{"országgyulés"}\NormalTok{, }\StringTok{"ülésnap"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Aztán pedig a pipe használatával elkészítjük a token objektumunkat. A
szótövesített tokeneket egy külön objektumban tároljuk, mert gyakran
előfordul hogy

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{torvenyek\_tokens }\OtherTok{\textless{}{-}} \FunctionTok{tokens}\NormalTok{(torvenyek\_corpus) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{tokens\_remove}\NormalTok{(}\FunctionTok{stopwords}\NormalTok{(}\StringTok{"hungarian"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{tokens\_remove}\NormalTok{(custom\_stopwords) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{tokens\_remove}\NormalTok{(custom\_stopwords\_egyeb) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{tokens\_wordstem}\NormalTok{(}\AttributeTok{language =} \StringTok{"hun"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Végül eltávolítjuk a dokumentum kifejezés mátrixból a túl gyakori
kifejezéseket. A \texttt{dfm\_trim()} függvénnyel a nagyon ritka és
nagyon gyakori szavak megjelenését kontrollálhatjuk. A
\texttt{termfreq\_type} opció \texttt{"prop"} akkor 0 és 1.0 közötti
értéket vehetnek fel a \texttt{max\_termfreq/docfreq} és
\texttt{min\_termfreq/docfreq} paraméterek. A lenti példában azokat a
tokeneket tartjuk meg, amelyek legalább egyszer előfordulnak ezer
dokumentumonként (így kizárva a nagyon ritka kifejezéseket).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{torvenyek\_dfm }\OtherTok{\textless{}{-}} \FunctionTok{dfm}\NormalTok{(torvenyek\_tokens) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{dfm\_trim}\NormalTok{(}\AttributeTok{min\_termfreq =} \FloatTok{0.001}\NormalTok{, }\AttributeTok{termfreq\_type =} \StringTok{"prop"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

A szövegtisztító lépesek eredményét úgy ellenőrizhetjük, hogy az 2.
fejezetben bemutatottak szerint szógyakorisági listát készítünk a
korpuszban maradt kifejezésekről. Itt kihasználhatjuk a korpuszunkban
lévő meta adatokat és megnézhetjük ciklus szerinti bontásban a
szófrekvencia ábrát. Az ábránál figyeljünk arra hogy a tidytext
reorder\_within fuggvenyet használjuk, ami egy nagyon hasznos megoldás a
csoportosított sorrendbe rendezésre a ggplot ábránál.

\begin{Shaded}
\begin{Highlighting}[]


\NormalTok{top\_tokens }\OtherTok{\textless{}{-}} \FunctionTok{textstat\_frequency}\NormalTok{(torvenyek\_dfm, }\AttributeTok{n =} \DecValTok{15}\NormalTok{, }\AttributeTok{groups =} \FunctionTok{docvars}\NormalTok{(torvenyek\_dfm, }
    \AttributeTok{field =} \StringTok{"electoral\_cycle"}\NormalTok{))}

\FunctionTok{ggplot}\NormalTok{(top\_tokens, }\FunctionTok{aes}\NormalTok{(}\FunctionTok{reorder\_within}\NormalTok{(feature, frequency, group), frequency)) }\SpecialCharTok{+} \FunctionTok{geom\_point}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{shape =}\NormalTok{ group), }
    \AttributeTok{size =} \DecValTok{2}\NormalTok{) }\SpecialCharTok{+} \FunctionTok{coord\_flip}\NormalTok{() }\SpecialCharTok{+} \FunctionTok{labs}\NormalTok{(}\AttributeTok{y =} \ConstantTok{NULL}\NormalTok{, }\AttributeTok{x =} \StringTok{"szófrekvencia"}\NormalTok{) }\SpecialCharTok{+} \FunctionTok{facet\_wrap}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{group, }
    \AttributeTok{nrow =} \DecValTok{2}\NormalTok{, }\AttributeTok{scales =} \StringTok{"free"}\NormalTok{) }\SpecialCharTok{+}\NormalTok{ tidytext}\SpecialCharTok{::}\FunctionTok{scale\_x\_reordered}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{_main_files/figure-latex/unnamed-chunk-105-1} 

}

\caption{A 15 leggyakoribb token a korpuszban}\label{fig:unnamed-chunk-105}
\end{figure}

A szövegtisztító lépéseket később újabbakkal is kiegészíthetjük, ha
észrevesszük, hogy az elemzést zavaró tisztítási lépés maradt ki. Ilyen
esetben tovább tisztíthatjuk a korpuszt, majd újra lefuttathatjuk az
elemzést. Például, ha szükséges, további stopszavak eltávolítását is
elvégezhetjük egy újabb stopszólista hozzáadásával. Ilyenkor ugyanúgy
járunk el, mint az előző stopszólista esetén, vagyis beolvassuk a
munkakönyvtárban elhelyezett a \texttt{csv} fájlt, a beolvasott
stopszólistából karakter vektort majd objektumot hozunk létre, végezetül
pedig ezeket a szavakat is eltávolítjuk a kopuszból.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{custom\_stopwords2 }\OtherTok{\textless{}{-}} \FunctionTok{readtext}\NormalTok{(}\StringTok{"data/custom\_stopwords2.csv"}\NormalTok{, }\AttributeTok{encoding =} \StringTok{"UTF8"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{pull}\NormalTok{(text)}

\NormalTok{torvenyek\_tokens\_final }\OtherTok{\textless{}{-}}\NormalTok{ torvenyek\_tokens }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{tokens\_remove}\NormalTok{(custom\_stopwords2)}
\end{Highlighting}
\end{Shaded}

Ezután újra ellenőrízzük az eredményt.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{torvenyek\_dfm\_final }\OtherTok{\textless{}{-}} \FunctionTok{dfm}\NormalTok{(torvenyek\_tokens\_final) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{dfm\_trim}\NormalTok{(}\AttributeTok{min\_termfreq =} \FloatTok{0.001}\NormalTok{, }
    \AttributeTok{termfreq\_type =} \StringTok{"prop"}\NormalTok{)}

\NormalTok{top\_tokens\_final }\OtherTok{\textless{}{-}} \FunctionTok{textstat\_frequency}\NormalTok{(torvenyek\_dfm\_final, }\AttributeTok{n =} \DecValTok{15}\NormalTok{, }\AttributeTok{groups =} \FunctionTok{docvars}\NormalTok{(torvenyek\_dfm, }
    \AttributeTok{field =} \StringTok{"electoral\_cycle"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(top\_tokens\_final, }\FunctionTok{aes}\NormalTok{(}\FunctionTok{reorder\_within}\NormalTok{(feature, frequency, group), frequency)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{shape =}\NormalTok{ group), }\AttributeTok{size =} \DecValTok{2}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{coord\_flip}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{y =} \ConstantTok{NULL}\NormalTok{,}
    \AttributeTok{x =} \StringTok{"szófrekvencia"}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{group, }\AttributeTok{nrow =} \DecValTok{2}\NormalTok{, }\AttributeTok{scales =} \StringTok{"free"}\NormalTok{) }\SpecialCharTok{+}
\NormalTok{  tidytext}\SpecialCharTok{::}\FunctionTok{scale\_x\_reordered}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{_main_files/figure-latex/unnamed-chunk-108-1} 

}

\caption{A 15 leggyakoribb token a korpuszban, a bovített stop szó listával}\label{fig:unnamed-chunk-108}
\end{figure}

A szövegtisztító és korpusz előkészítő műveletek után következhet az LDA
illesztése. Az alábbiakban az LDA illesztés két módszerét a
\texttt{VEM}-et és a \texttt{Gibbs}-et mutatjuk be. A modell minkét
módszer esetén ugyanaz, a különbség a következtetés módjában van. A
\texttt{VEM} módszer variációs következtetés, míg a \texttt{Gibbs}
mintavételen alapuló következtetés.
(\protect\hyperlink{ref-blei2003}{Blei, Ng, and Jordan 2003};
\protect\hyperlink{ref-Griffiths2002}{\textbf{Griffiths2002?}};
\protect\hyperlink{ref-Phan2008}{\textbf{Phan2008?}})

A két modell illesztése nagyon hasonló, meg kell adnunk, az elemezni
kívánt \texttt{dfm} nevét, majd a \emph{„k"} értékét, ami egyenlő az
általunk létrehozni kívánt topikok számával, ezt követően meg kell
jelölnünk, hogy a \texttt{VEM} vagy a \texttt{Gibbs} módszert
alkalmazzuk. A \texttt{set.seed()} a funkció az R véletlen szám
generátor magjának beállítására szolgál, ami ahhoz kell, hogy az
eredmény, ábra, stb. pontosan reprodukálható legyen. A
\texttt{set.seed()} bármilyen tetszőleges egész szám lehet.
Kihasználhatjuk hogy minden dokumentumhoz tartozik egy kormányzati
ciklus azonosító, mivel ésszerű lehet a feltételezés, hogy különböző
parlamentek és kormányok más-más jogalkotási fokusszal rendelkeznek. A
dokumentum változók alapján a \texttt{dfm\_subset()}-el tudjuk
feldarabolni a már elkészült és tisztított mátrixunkat.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dfm\_98\_02 }\OtherTok{\textless{}{-}} \FunctionTok{dfm\_subset}\NormalTok{(torvenyek\_dfm\_final, electoral\_cycle }\SpecialCharTok{==} \StringTok{"1998{-}2002"}\NormalTok{)}

\NormalTok{dfm\_02\_06 }\OtherTok{\textless{}{-}} \FunctionTok{dfm\_subset}\NormalTok{(torvenyek\_dfm\_final, electoral\_cycle }\SpecialCharTok{==} \StringTok{"2002{-}2006"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{a-vem-muxf3dszer-alkalmazuxe1sa-a-magyar-tuxf6rvuxe9nyek-korpuszuxe1n}{%
\subsection{A „VEM" módszer alkalmazása a magyar törvények
korpuszán}\label{a-vem-muxf3dszer-alkalmazuxe1sa-a-magyar-tuxf6rvuxe9nyek-korpuszuxe1n}}

Saját korpuszunkon először a \texttt{VEM} a módszert alkalmazzuk, ahol
\texttt{k\ =\ 10} azaz a modell 10 témacsoportot alakít ki. Mint arról
korábban már volt szó a \texttt{k} értékét szabadon változtathatjuk,
aszerint hogy hány topik kialakítását szeretnénk. Bár a \texttt{k}
értékének meghatározása kutatói döntésen alapul, és a modell futtatása
során bevett gyakorlat a különböző \emph{„k"} értékekkel való
kísérletezés, miután elkészült az elemzés a \texttt{perplexity()}
funkció segítségével -- ahol a \emph{theta} az adott topikhoz való
tartozás valószínűsége -- lehetőségünk van az elkészült modell
kiértékelésére. A függvény a topikok által reprezentált elméleti
szóeloszlásokat hasonlítja össze a szavak tényleges eloszlásával a
dokumentumokban. A függvény értéke nem önmagában értelmezendő, hanem két
modell összehasonlításában, ahol a legalacsonyabb \emph{perplexity}
(zavarodottság) értékkel rendelkező modellt tekintik a
legjobbnak.{[}\^{}klaszeterzes-2{]} Az illusztráció kedvéért lefuttatunk
4 LDA modellt az 1998-2002 kormánzyati ciklushoz tartozó dfm-en. Az
iterációhoz a \texttt{purrr} csomag \texttt{map} függvényét használjuk
(ez a \texttt{lapply} \emph{tidyverse} ekvivalense). Fontos emlékezni
arra, hogy minél nagyobb a korpuszunk annál több számítási kapacitásra
van szükség (és annál tovább tart a számítás).

{[}\^{}klaszeterzes-2{]}
\url{http://brooksandrew.github.io/simpleblog/articles/latent-dirichlet-allocation-under-the-hood/}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{k\_topics }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{15}\NormalTok{, }\DecValTok{20}\NormalTok{)}

\NormalTok{lda\_98\_02 }\OtherTok{\textless{}{-}}\NormalTok{ k\_topics }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{map}\NormalTok{(LDA, }\AttributeTok{x =}\NormalTok{ dfm\_98\_02, }\AttributeTok{control =} \FunctionTok{list}\NormalTok{(}\AttributeTok{seed =} \DecValTok{1234}\NormalTok{))}


\NormalTok{perp\_df }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}
  \AttributeTok{k =}\NormalTok{ k\_topics,}
  \AttributeTok{perplexity =} \FunctionTok{map\_dbl}\NormalTok{(lda\_98\_02, perplexity)}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(perp\_df, }\FunctionTok{aes}\NormalTok{(k, perplexity)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{x =} \StringTok{"k"}\NormalTok{,}
    \AttributeTok{y =} \StringTok{"Perplexity"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{_main_files/figure-latex/unnamed-chunk-111-1} 

}

\caption{Perplexity változása a k függvényében}\label{fig:unnamed-chunk-111}
\end{figure}

A perplexity pontszám alapján a 20 topikos modell szerepel a legjobban,
de fontos emlékezni arra hogy a megfelelő \emph{k} kiválasztása a kutató
kvalitatív döntésén múlik. Ehhez természetesen kvantitatív szempontokat
is figyelembe vehetünk, mint például a perplexity indikátor.\footnote{A
  \texttt{ldatuning} R csomagban további indikátor implementációja
  található, ami a perplexityhez hasonlóan minimalizásra alapoz
  (\protect\hyperlink{ref-arun2010finding}{Arun et al.}
  (\protect\hyperlink{ref-arun2010finding}{2010}),
  \protect\hyperlink{ref-cao2009density}{Cao et al.}
  (\protect\hyperlink{ref-cao2009density}{2009})), illetve
  maximalizálásra (\protect\hyperlink{ref-deveaud2014accurate}{Deveaud,
  SanJuan, and Bellot}
  (\protect\hyperlink{ref-deveaud2014accurate}{2014}),
  \protect\hyperlink{ref-griffiths2004}{Griffiths and Steyvers}
  (\protect\hyperlink{ref-griffiths2004}{2004}))}

A reprodukálhatóság és futási sebesség érdekében a fejezet további
részeiben a \emph{k} paraméternek 10-es értéket adunk. Ezzel
lefututtatunk egy-egy modellt a két ciklusra.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vem\_98\_02 }\OtherTok{\textless{}{-}} \FunctionTok{LDA}\NormalTok{(dfm\_98\_02, }\AttributeTok{k =} \DecValTok{10}\NormalTok{, }\AttributeTok{method =} \StringTok{"VEM"}\NormalTok{, }\AttributeTok{control =} \FunctionTok{list}\NormalTok{(}\AttributeTok{seed =} \DecValTok{1234}\NormalTok{))}

\NormalTok{vem\_02\_06 }\OtherTok{\textless{}{-}} \FunctionTok{LDA}\NormalTok{(dfm\_02\_06, }\AttributeTok{k =} \DecValTok{10}\NormalTok{, }\AttributeTok{method =} \StringTok{"VEM"}\NormalTok{, }\AttributeTok{control =} \FunctionTok{list}\NormalTok{(}\AttributeTok{seed =} \DecValTok{1234}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

Ezt követően a modell által létrehozott topic-okat tidy formátumba
tesszük és egyesítjük egy data frameben.\footnote{a tidy formátumról
  bővebben:
  \url{https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{topics\_98\_02 }\OtherTok{\textless{}{-}} \FunctionTok{tidy}\NormalTok{(vem\_98\_02, }\AttributeTok{matrix =} \StringTok{"beta"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{electoral\_cycle =} \StringTok{"1998{-}2002"}\NormalTok{)}

\NormalTok{topics\_02\_06 }\OtherTok{\textless{}{-}} \FunctionTok{tidy}\NormalTok{(vem\_02\_06, }\AttributeTok{matrix =} \StringTok{"beta"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{electoral\_cycle =} \StringTok{"2002{-}2006"}\NormalTok{)}

\NormalTok{lda\_vem }\OtherTok{\textless{}{-}} \FunctionTok{bind\_rows}\NormalTok{(topics\_98\_02, topics\_02\_06)}
\end{Highlighting}
\end{Shaded}

Majd listázzuk az egyes topikokhoz tartozó leggyakoribb kifejezéseket.

\begin{Shaded}
\begin{Highlighting}[]

\NormalTok{top\_terms }\OtherTok{\textless{}{-}}\NormalTok{ lda\_vem }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(electoral\_cycle, topic) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{top\_n}\NormalTok{(}\DecValTok{5}\NormalTok{, beta) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{top\_n}\NormalTok{(}\DecValTok{5}\NormalTok{, term) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ungroup}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{arrange}\NormalTok{(topic, }\SpecialCharTok{{-}}\NormalTok{beta)}
\end{Highlighting}
\end{Shaded}

Majd a \texttt{ggplot2} csomag segítségével ábrán is megjeleníthetjük az
egyes topikok 10 legfontosabb kifejezését.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{top\_terms }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(electoral\_cycle }\SpecialCharTok{==} \StringTok{"1998{-}2002"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\FunctionTok{reorder\_within}\NormalTok{(term, beta, topic), beta)) }\SpecialCharTok{+}
  \FunctionTok{geom\_col}\NormalTok{(}\AttributeTok{show.legend =} \ConstantTok{FALSE}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{topic, }\AttributeTok{scales =} \StringTok{"free"}\NormalTok{, }\AttributeTok{ncol =} \DecValTok{2}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{coord\_flip}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{x =} \ConstantTok{NULL}\NormalTok{,}
    \AttributeTok{y =} \FunctionTok{expression}\NormalTok{(beta)}
\NormalTok{  ) }\SpecialCharTok{+}
\NormalTok{  tidytext}\SpecialCharTok{::}\FunctionTok{scale\_x\_reordered}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{_main_files/figure-latex/unnamed-chunk-115-1} 

}

\caption{1998-2002 ciklus topikok és kifejezések (VEM mintavételezéssel)}\label{fig:unnamed-chunk-115}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{top\_terms }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(electoral\_cycle }\SpecialCharTok{==} \StringTok{"2002{-}2006"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\FunctionTok{reorder\_within}\NormalTok{(term, beta, topic), beta)) }\SpecialCharTok{+}
  \FunctionTok{geom\_col}\NormalTok{(}\AttributeTok{show.legend =} \ConstantTok{FALSE}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{topic, }\AttributeTok{scales =} \StringTok{"free"}\NormalTok{, }\AttributeTok{ncol =} \DecValTok{2}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{coord\_flip}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{x =} \ConstantTok{NULL}\NormalTok{,}
    \AttributeTok{y =} \FunctionTok{expression}\NormalTok{(beta)}
\NormalTok{  ) }\SpecialCharTok{+}
\NormalTok{  tidytext}\SpecialCharTok{::}\FunctionTok{scale\_x\_reordered}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{_main_files/figure-latex/unnamed-chunk-116-1} 

}

\caption{2002-2006 ciklus topikok és kifejezések (VEM mintavételezéssel)}\label{fig:unnamed-chunk-116}
\end{figure}

\hypertarget{az-lda-gibbs-muxf3dszer-alkalmazuxe1sa-a-magyar-tuxf6rvuxe9nyek-korpuszuxe1n}{%
\subsection{Az „LDA Gibbs" módszer alkalmazása a magyar törvények
korpuszán}\label{az-lda-gibbs-muxf3dszer-alkalmazuxe1sa-a-magyar-tuxf6rvuxe9nyek-korpuszuxe1n}}

A következőkben ugyanazon a korpuszon az LDA Gibbs módszert alkalmazzuk.
A szövegelőkészítő és tisztító lépések ennél a módszernél is ugyanazok
mint a fentebb bemutatott ``VEM'' módszer esetében, így itt most csak a
modell illesztését mutatjuk be.

\begin{Shaded}
\begin{Highlighting}[]

\NormalTok{gibbs\_98\_02 }\OtherTok{\textless{}{-}} \FunctionTok{LDA}\NormalTok{(dfm\_98\_02, }\AttributeTok{k =} \DecValTok{10}\NormalTok{, }\AttributeTok{method =} \StringTok{"Gibbs"}\NormalTok{, }\AttributeTok{control =} \FunctionTok{list}\NormalTok{(}\AttributeTok{seed =} \DecValTok{1234}\NormalTok{))}

\NormalTok{gibbs\_02\_06 }\OtherTok{\textless{}{-}} \FunctionTok{LDA}\NormalTok{(dfm\_02\_06, }\AttributeTok{k =} \DecValTok{10}\NormalTok{, }\AttributeTok{method =} \StringTok{"Gibbs"}\NormalTok{, }\AttributeTok{control =} \FunctionTok{list}\NormalTok{(}\AttributeTok{seed =} \DecValTok{1234}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

Itt is elvégezzük a topikok tidy formátumra alakítását.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{topics\_g98\_02 }\OtherTok{\textless{}{-}} \FunctionTok{tidy}\NormalTok{(gibbs\_98\_02, }\AttributeTok{matrix =} \StringTok{"beta"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{electoral\_cycle =} \StringTok{"1998{-}2002"}\NormalTok{)}

\NormalTok{topics\_g02\_06 }\OtherTok{\textless{}{-}} \FunctionTok{tidy}\NormalTok{(gibbs\_02\_06, }\AttributeTok{matrix =} \StringTok{"beta"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{electoral\_cycle =} \StringTok{"2002{-}2006"}\NormalTok{)}

\NormalTok{lda\_gibbs }\OtherTok{\textless{}{-}} \FunctionTok{bind\_rows}\NormalTok{(topics\_g98\_02, topics\_g02\_06)}
\end{Highlighting}
\end{Shaded}

Majd listázzuk az egyes topikokhoz tartozó leggyakoribb kifejezéseket.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{top\_terms\_gibbs }\OtherTok{\textless{}{-}}\NormalTok{ lda\_gibbs }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(electoral\_cycle, topic) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{top\_n}\NormalTok{(}\DecValTok{5}\NormalTok{, beta) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{top\_n}\NormalTok{(}\DecValTok{5}\NormalTok{, term) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ungroup}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{arrange}\NormalTok{(topic, }\SpecialCharTok{{-}}\NormalTok{beta)}
\end{Highlighting}
\end{Shaded}

Majd a \texttt{ggplot2} csomag segítségével ábrán is megjeleníthetjük.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{top\_terms\_gibbs }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(electoral\_cycle }\SpecialCharTok{==} \StringTok{"1998{-}2002"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\FunctionTok{reorder\_within}\NormalTok{(term, beta, topic), beta)) }\SpecialCharTok{+}
  \FunctionTok{geom\_col}\NormalTok{(}\AttributeTok{show.legend =} \ConstantTok{FALSE}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{topic, }\AttributeTok{scales =} \StringTok{"free"}\NormalTok{, }\AttributeTok{ncol =} \DecValTok{2}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{coord\_flip}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{title =}\NormalTok{ ,}
    \AttributeTok{x =} \ConstantTok{NULL}\NormalTok{,}
    \AttributeTok{y =} \FunctionTok{expression}\NormalTok{(beta)}
\NormalTok{  ) }\SpecialCharTok{+}
\NormalTok{  tidytext}\SpecialCharTok{::}\FunctionTok{scale\_x\_reordered}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{_main_files/figure-latex/unnamed-chunk-120-1} 

}

\caption{1998-2002 ciklus topikok és kifejezések (Gibbs mintavétellel)}\label{fig:unnamed-chunk-120}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{top\_terms\_gibbs }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(electoral\_cycle }\SpecialCharTok{==} \StringTok{"2002{-}2006"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\FunctionTok{reorder\_within}\NormalTok{(term, beta, topic), beta)) }\SpecialCharTok{+}
  \FunctionTok{geom\_col}\NormalTok{(}\AttributeTok{show.legend =} \ConstantTok{FALSE}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{topic, }\AttributeTok{scales =} \StringTok{"free"}\NormalTok{, }\AttributeTok{ncol =} \DecValTok{2}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{coord\_flip}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{x =} \ConstantTok{NULL}\NormalTok{,}
    \AttributeTok{y =} \FunctionTok{expression}\NormalTok{(beta)}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{scale\_x\_reordered}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{_main_files/figure-latex/unnamed-chunk-121-1} 

}

\caption{2002-2006 ciklus topikok és kifejezések (Gibbs mintavétellel)}\label{fig:unnamed-chunk-121}
\end{figure}

\hypertarget{struktuxfaruxe1lis-topik-modellek}{%
\section{Struktúrális topik
modellek}\label{struktuxfaruxe1lis-topik-modellek}}

A kvantitatív szövegelemzés elterjedésével együtt megjelentek a
módszertani innovációk is és a probabilisztikus topic modellek esetében
ez a politikatudomány területéről érkezett.
\protect\hyperlink{ref-roberts2014structural}{Roberts et al.}
(\protect\hyperlink{ref-roberts2014structural}{2014}) egy kíváló cikkben
mutatta be a struktúrális topic modelleket (structural topic models,
stm) ahol a fő újítás az az hogy a dokumentumok metaadatai kovariánsként
tudják befolyásolni hogy egy-egy kifejezés mekkora valószínűséggel lesz
egy-egy téma része. A kovariánsok egyrészről megmagyarázhatják hogy
egy-egy dokumentum mennyire függ össze egy-egy témával (\emph{topical
prevalence}), illetve hogy egy-egy szó mennyire függ össze egy-egy témán
belül (t\emph{opical content}).

Az stm modell becslése során mindkét típusú kovariánst használhatjuk,
illetve hogyha nem adunk meg dokumentum meta adatot akkor az
\texttt{stm} csomag \texttt{stm} függvénye a Korrelált Topic Modell-t
fogja becsülni.

Az stm modelleket az R-ben az \texttt{stm} csomaggal tudjuk kivitelezni.
A csomag fejlesztői között van a módszer kidolgozója is, ami nem ritka
az R csomagok esetében.

A lenti lépésekben a csomag dokumentációjában szereplő ajánlásokat
követjük, habár a könyv írásakor a \texttt{stm} már képes volt a
\texttt{quanteda}-ban létrehozott dfm-ek kezelésére is. A kiinduló
adatbázisunk a \texttt{törvény\_final} amit a fejezet elején hoztunk
létre a dokuemntumokból és a metaadatokból. A javasolt munkafolyamat a
\texttt{textProcessor()}-használatával indul, ami szintén tartalmazza az
alap szöveg előkészítési lépéseket. Az egyszerűség és futási sebesség
érdekében itt most ezek többségétől eltekintünk, mivel a fejezet korábbi
részeiben részletesen tárgyaltuk őket.

Az előkészítés utolsó szakaszában az \texttt{out} objektumban tároljuk
el a dokumentumokat, egyedi szavakat, illetve a meta adatokat
(kovariánsokat).

\begin{Shaded}
\begin{Highlighting}[]

\NormalTok{data\_stm }\OtherTok{\textless{}{-}}\NormalTok{ torveny\_final}

\NormalTok{processed\_stm }\OtherTok{\textless{}{-}} \FunctionTok{textProcessor}\NormalTok{(}
\NormalTok{  torveny\_final}\SpecialCharTok{$}\NormalTok{text,}
  \AttributeTok{metadata =}\NormalTok{ torveny\_final,}
  \AttributeTok{lowercase =} \ConstantTok{FALSE}\NormalTok{,}
  \AttributeTok{removestopwords =} \ConstantTok{FALSE}\NormalTok{,}
  \AttributeTok{removenumbers =} \ConstantTok{FALSE}\NormalTok{,}
  \AttributeTok{removepunctuation =} \ConstantTok{FALSE}\NormalTok{,}
  \AttributeTok{ucp =} \ConstantTok{FALSE}\NormalTok{,}
  \AttributeTok{stem =} \ConstantTok{TRUE}\NormalTok{,}
  \AttributeTok{language =} \StringTok{"hungarian"}\NormalTok{,}
  \AttributeTok{verbose =} \ConstantTok{FALSE}
\NormalTok{)}


\NormalTok{out }\OtherTok{\textless{}{-}} \FunctionTok{prepDocuments}\NormalTok{(processed\_stm}\SpecialCharTok{$}\NormalTok{documents, processed\_stm}\SpecialCharTok{$}\NormalTok{vocab, processed\_stm}\SpecialCharTok{$}\NormalTok{meta)}
\end{Highlighting}
\end{Shaded}

A struktúrális topic modellünket az \texttt{stm} függvénnyel becsüljük
és a kovariánsokat a \texttt{prevalence} opciónál tudjuk formulaként
megadni. A lenti példában a Comparative Agendas Projekt kategóriáit
(pl.: gazdaság, egészségügy, stb.) és a kormányciklusokat használjuk. A
futási idő kicsit hosszabb mint az LDA modellek esetében.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{stm\_fit }\OtherTok{\textless{}{-}} \FunctionTok{stm}\NormalTok{(}
\NormalTok{  out}\SpecialCharTok{$}\NormalTok{documents,}
\NormalTok{  out}\SpecialCharTok{$}\NormalTok{vocab,}
  \AttributeTok{K =} \DecValTok{10}\NormalTok{,}
  \AttributeTok{prevalence =} \SpecialCharTok{\textasciitilde{}}\NormalTok{ majortopic }\SpecialCharTok{+}\NormalTok{ electoral\_cycle,}
  \AttributeTok{data =}\NormalTok{ out}\SpecialCharTok{$}\NormalTok{meta,}
  \AttributeTok{init.type =} \StringTok{"Spectral"}\NormalTok{,}
  \AttributeTok{seed =} \DecValTok{1234}\NormalTok{,}
  \AttributeTok{verbose =} \ConstantTok{FALSE}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Amennyiben a kutatási kérdés megkívánja, akkor megvizsálhatjuk hogy a
kategórikus változóinknak milyen hatása volt egyes topikok esetében.
Ehhez az \texttt{estimateEffect()} függvénnyel lefuttatunk egy lineáris
regressziót és a \texttt{summary()} használatával láthatjuk az egyes
kovariánsok koefficienseit. Itt az első topikkal illusztráljuk az
eredményt, ami azt mutatja hogy (a kategórikus változóink első
kategoriájához mérten) statisztikailag szignifikáns mint a téma mind
pedig a kormányzati ciklusok abban hogy egyes dokumentumok milyen
témákból épülnek fel.

\begin{Shaded}
\begin{Highlighting}[]

\NormalTok{out}\SpecialCharTok{$}\NormalTok{meta}\SpecialCharTok{$}\NormalTok{electoral\_cycle }\OtherTok{\textless{}{-}} \FunctionTok{as.factor}\NormalTok{(out}\SpecialCharTok{$}\NormalTok{meta}\SpecialCharTok{$}\NormalTok{electoral\_cycle)}
\NormalTok{out}\SpecialCharTok{$}\NormalTok{meta}\SpecialCharTok{$}\NormalTok{majortopic }\OtherTok{\textless{}{-}} \FunctionTok{as.factor}\NormalTok{(out}\SpecialCharTok{$}\NormalTok{meta}\SpecialCharTok{$}\NormalTok{majortopic)}

\NormalTok{cov\_estimate }\OtherTok{\textless{}{-}} \FunctionTok{estimateEffect}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{10} \SpecialCharTok{\textasciitilde{}}\NormalTok{ majortopic }\SpecialCharTok{+}\NormalTok{ electoral\_cycle, stm\_fit, }\AttributeTok{meta =}\NormalTok{ out}\SpecialCharTok{$}\NormalTok{meta, }
    \AttributeTok{uncertainty =} \StringTok{"Global"}\NormalTok{)}

\FunctionTok{summary}\NormalTok{(cov\_estimate, }\AttributeTok{topics =} \DecValTok{1}\NormalTok{)}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Call:}
\CommentTok{\#\textgreater{} estimateEffect(formula = 1:10 \textasciitilde{} majortopic + electoral\_cycle, }
\CommentTok{\#\textgreater{}     stmobj = stm\_fit, metadata = out$meta, uncertainty = "Global")}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Topic 1:}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Coefficients:}
\CommentTok{\#\textgreater{}                          Estimate Std. Error t value Pr(\textgreater{}|t|)    }
\CommentTok{\#\textgreater{} (Intercept)               0.30118    0.03083   9.770  \textless{} 2e{-}16 ***}
\CommentTok{\#\textgreater{} majortopic2              {-}0.20953    0.06474  {-}3.237 0.001249 ** }
\CommentTok{\#\textgreater{} majortopic3              {-}0.19942    0.05950  {-}3.352 0.000833 ***}
\CommentTok{\#\textgreater{} majortopic4              {-}0.21489    0.05733  {-}3.749 0.000188 ***}
\CommentTok{\#\textgreater{} majortopic5               0.10192    0.04651   2.191 0.028674 *  }
\CommentTok{\#\textgreater{} majortopic6              {-}0.21813    0.05763  {-}3.785 0.000163 ***}
\CommentTok{\#\textgreater{} majortopic7              {-}0.15750    0.06746  {-}2.335 0.019745 *  }
\CommentTok{\#\textgreater{} majortopic8              {-}0.20311    0.07402  {-}2.744 0.006177 ** }
\CommentTok{\#\textgreater{} majortopic9               0.49074    0.10776   4.554 5.91e{-}06 ***}
\CommentTok{\#\textgreater{} majortopic10             {-}0.11412    0.05360  {-}2.129 0.033508 *  }
\CommentTok{\#\textgreater{} majortopic12             {-}0.17535    0.04068  {-}4.311 1.79e{-}05 ***}
\CommentTok{\#\textgreater{} majortopic13             {-}0.14383    0.05538  {-}2.597 0.009540 ** }
\CommentTok{\#\textgreater{} majortopic14             {-}0.21523    0.07339  {-}2.933 0.003435 ** }
\CommentTok{\#\textgreater{} majortopic15             {-}0.14833    0.04171  {-}3.556 0.000393 ***}
\CommentTok{\#\textgreater{} majortopic16             {-}0.09580    0.05444  {-}1.760 0.078762 .  }
\CommentTok{\#\textgreater{} majortopic17             {-}0.22235    0.05728  {-}3.882 0.000110 ***}
\CommentTok{\#\textgreater{} majortopic18              0.21233    0.05565   3.816 0.000144 ***}
\CommentTok{\#\textgreater{} majortopic19              0.06358    0.04853   1.310 0.190472    }
\CommentTok{\#\textgreater{} majortopic20             {-}0.21211    0.03944  {-}5.378 9.37e{-}08 ***}
\CommentTok{\#\textgreater{} majortopic21             {-}0.21810    0.06868  {-}3.176 0.001541 ** }
\CommentTok{\#\textgreater{} majortopic23             {-}0.19028    0.09082  {-}2.095 0.036404 *  }
\CommentTok{\#\textgreater{} electoral\_cycle2002{-}2006 {-}0.10232    0.01946  {-}5.257 1.78e{-}07 ***}
\CommentTok{\#\textgreater{} {-}{-}{-}}
\CommentTok{\#\textgreater{} Signif. codes:  0 \textquotesingle{}***\textquotesingle{} 0.001 \textquotesingle{}**\textquotesingle{} 0.01 \textquotesingle{}*\textquotesingle{} 0.05 \textquotesingle{}.\textquotesingle{} 0.1 \textquotesingle{} \textquotesingle{} 1}
\end{Highlighting}
\end{Shaded}

Az LDA modelleknél már bemutatott munkafolyamat az stm modellünk
esetében is alkalmazható, hogy vizuálisan is megjelenítsük az
eredményeinket. A \texttt{tidy()} data frammé alakítja az stm
objektumot, amit aztán a már ismerős \texttt{dplyr} csomagban lévő
fügvényekkel tudunk átalakítani és végül vizualizálni a \texttt{ggplot2}
csomaggal. A lenti ábrán az egyes témákhoz tartozó 5 legvalószűbb szót
mutatjuk be.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tidy\_stm }\OtherTok{\textless{}{-}} \FunctionTok{tidy}\NormalTok{(stm\_fit)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tidy\_stm }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(topic) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{top\_n}\NormalTok{(}\DecValTok{5}\NormalTok{, beta) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ungroup}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{topic =} \FunctionTok{paste0}\NormalTok{(}\StringTok{"Topic "}\NormalTok{, topic),}
    \AttributeTok{term =} \FunctionTok{reorder\_within}\NormalTok{(term, beta, topic)}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(term, beta)) }\SpecialCharTok{+}
  \FunctionTok{geom\_col}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{topic, }\AttributeTok{scales =} \StringTok{"free\_y"}\NormalTok{, }\AttributeTok{ncol =} \DecValTok{3}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{coord\_flip}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{scale\_x\_reordered}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{x =} \ConstantTok{NULL}\NormalTok{,}
    \AttributeTok{y =} \FunctionTok{expression}\NormalTok{(beta)}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{_main_files/figure-latex/unnamed-chunk-126-1} 

}

\caption{Topikonkénti legmagasabb valószínuségu szavak}\label{fig:unnamed-chunk-126}
\end{figure}

Egy-egy topichoz tartozó meghatározó szavak annak függvényében
változhatnak hogy milyen algoritmust használunk. A
\texttt{labelTopics()} a már becsült stm modellünket alapul véve kínál 4
féle alternatív opciót. Az egyes algoritmusok részletes magyarázatáért
érdemes elolvasni a csomag részletes leírását.\footnote{Az \texttt{stm}
  csomaghoz tartozó leírás:
  \url{https://cran.r-project.org/web/packages/stm/vignettes/stmVignette.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{labelTopics}\NormalTok{(stm\_fit, }\FunctionTok{c}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{2}\NormalTok{))}
\CommentTok{\#\textgreater{} Topic 1 Top Words:}
\CommentTok{\#\textgreater{}       Highest Prob: szerzodo, vagi, egyezméni, fél, államban, nem, másik }
\CommentTok{\#\textgreater{}       FREX: megadóztatható, haszonhúzója, beruházóinak, segélycsapatok, adóztatást, jövedelemadók, kijelölések }
\CommentTok{\#\textgreater{}       Lift: árucikkeket, átalányösszegben, átléphetik, átszállítást, beruházóikat, célországban, cikktanulók }
\CommentTok{\#\textgreater{}       Score: szerzodo, államban, illetoségu, egyezméni, megadóztatható, adóztatható, cikka }
\CommentTok{\#\textgreater{} Topic 2 Top Words:}
\CommentTok{\#\textgreater{}       Highest Prob: muködési, célú, támogatások, költségvetésegyéb, felhalmozási, terhelo, beruházási }
\CommentTok{\#\textgreater{}       FREX: kiadásokfelújításegyéb, kiadásokintézményi, kiadásokközponti, költségvetésfelhalmozási, kiadásokkormányzati, felújításegyéb, rek }
\CommentTok{\#\textgreater{}       Lift: a+b+c, a+b+c+d, adago, adódóa, adósságállományából, adósságrendezésr, adótartozásának }
\CommentTok{\#\textgreater{}       Score: költségvetésegyéb, költségvetésszemélyi, kiadásokfelhalmozási, járulékokdolog, költségvetésintézményi, kiadásokegyéb, juttatásokmunkaadókat}
\end{Highlighting}
\end{Shaded}

A korpuszunkon belüli témák megoszlását a \texttt{plot.STM()}-el tudjuk
ábrázolni. Jól látszik hogy a Topic 6-ba tartozó szavak vannak jelen a
legnagyobb arányban a dokumentumaink között.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot.STM}\NormalTok{(stm\_fit, }\StringTok{"summary"}\NormalTok{, }\AttributeTok{main =} \StringTok{""}\NormalTok{, }\AttributeTok{labeltype =} \StringTok{"frex"}\NormalTok{, }\AttributeTok{xlab =} \StringTok{"Várható topic arányok"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{_main_files/figure-latex/unnamed-chunk-128-1} 

}

\caption{Leggyakoribb témák és kifejezések}\label{fig:unnamed-chunk-128}
\end{figure}

Végezetül, a témák közötti korrelációt a \texttt{topicCorr} függvénnyel
becsülhetjük és az \texttt{igraph} csomagot betöltve a \texttt{plot()}
paranccsal tudjuk vizualizálni. Az eredmény egy hálózat lesz amit
gráfként ábrázolunk. Az élei a gráfoknak a témák közötti összefüggést
(korrelációt) jelölik.

\begin{Shaded}
\begin{Highlighting}[]

\FunctionTok{plot}\NormalTok{(}\FunctionTok{topicCorr}\NormalTok{(stm\_fit))}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{_main_files/figure-latex/unnamed-chunk-129-1} 

}

\caption{Témák közötti korreláció hálózat}\label{fig:unnamed-chunk-129}
\end{figure}

\hypertarget{szuxf3beuxe1gyazuxe1sok}{%
\chapter{Szóbeágyazások}\label{szuxf3beuxe1gyazuxe1sok}}

Az eddigi fejezetekben elsősorban a szózsák (bag of words) alapú
módszerek voltak előtérben. Ez a reprezentálása a szövegnek szigorúan
véve nem felel meg a valóságnak a kotextuális tartalom elvesztése miatt,
de ezt az esetek többségében figyelmen kívül hagyhatjuk. A
szóbeágyazáson (word embedding) alapuló modellek viszont kimondottan a
kotextuális információt ragadják meg. A szóbeágyazás a topikmodellekhez
hasonlóan szintén a felügyelet nélküli tanulás módszerére épül, azonban
itt a dokumentum domináns kifejezéseinek és témáinak feltárása helyett a
szavak közötti szemantikai kapcsolat megértése a cél. Vagyis a modellnek
képesnek kell lennie az egyes szavak esetén szinonimáik, és
ellentétpárjaik megtalálására.

A hagyományos topikmodellezés esetén a modell a szavak dokumentumokon
belüli együttes megjelenési statisztikái alapján becsül
dokumentum-topik, illetve topik-szó eloszlásokat, azzal a céllal, hogy
koherens téma-csoportokat képezzen a modell, ezzel szemben a
szóbeágyazás legújabb iskolája már neurális halókon alapul. A neurális
háló a tanítási folyamata során az egyes szavak vektorreprezentációját
állítja elő. A vektorok jellemzően 100-300 dimenzióból állnak, a
távolságuk alapján pedig megállapítható, hogy az egyes kifejezések
milyen szemantikai kapcsolatban állnak egymással.

A szóbeágyazás célja tehát a szemantikai relációk feltárása. A szavak
vektorizálásának köszönhetően bármely (a korpuszunkban szereplő)
tetszőleges számú szóról eldönthetjük, hogy azok milyen szemantikai
kapcsolatban állnak egymással -- szinonimaként, vagy ellentétes
fogalompárként szerepelnek. A szóvektorokon dimenziócsökkentő eljárást
alkalmazva, s a multidimenzionális (100-300 dimenziós) teret 2
dimenziósra szűkítve könnyen vizualizálhatjuk is a korpuszunk
kifejezései között fennálló szemantikai távolságot, és ahogy a lenti
ábrákon is, láthatjuk, hogy az egyes kifejezések milyen relációban
állnak egymással -- a szemantikailag hasanló tartalmú kifejezések
egymáshoz közel, míg a távolabbi jelentéstartalmú kifejezések egymástól
távolabb foglalnak helyet. A klasszkus példa, amivel jól lehet
szemléltetni a szóvektorok közötti összefüggést:
\texttt{king\ -\ man\ +\ woman\ =\ queen}

\hypertarget{word2vec-glove-uxe9s-fasttext}{%
\section{Word2Vec, GloVe és
fastText}\label{word2vec-glove-uxe9s-fasttext}}

A szóbeágyazásra társadalomtudományokban a két legnépszerűbb algoritmus
-- Word2Vec és a GloVe -- a \emph{kontextuális szövegeloszláson}
(distributional similarity based representations) alapszik, vagyis abból
a feltevésből indul ki, hogy a hasonló kifejezések hasonló kontextusban
fordulnak elő, valamint mindkettő sekély neurális hálón (2 rejtett
réteg) alapuló modell.\footnote{Egy kíváló tanulmányban
  \protect\hyperlink{ref-spirlingword}{Spirling and Rodriguez}
  (\protect\hyperlink{ref-spirlingword}{n.d.a}) összehasonlítják a
  Word2Vec és GloVe módszereket, különbözö paraméterekkel,
  adatbázisokkal. Amennyiben valakit komolyabban érdekelnek a
  szóbeágyazás gyakorlati alkalmazásának a részletei annak mindenképp
  ajánljuk elolvasásra.} A Word2Vec-nek két verziója van: Continuous
Bag-of-words (CBOW) és SkipGram (SG) -- előbbi a kontextuális szavakból
jelzi előre (predicting) a kontextushoz legszorosabban kapcsolódó
kifejezést, míg utóbbi adott kifejezésből jelzi előre a kontextust
\protect\hyperlink{ref-mikolov2013efficient}{Mikolov et al.}
(\protect\hyperlink{ref-mikolov2013efficient}{2013}). A GloVe (Global
Vectors for Word Representation) a Word2Vec-hez hasonlóan neurális hálón
alapuló, szóvektorok előállítását célzó modell, a Word2Vec-kel szemben
azonban nem a meghatározott kontextus-ablakban (context window)
megjelenő kifejezések közti kapcsolatokat tárja fel, hanem a szöveg
globális jellemzőit igyekszik megragadni az egész szöveget jellemző
együttes előfordulási gyakoriságok (co-occurrance) meghatározásával
\protect\hyperlink{ref-pennington2014glove}{Pennington, Socher, and
Manning} (\protect\hyperlink{ref-pennington2014glove}{2014}). Míg a
Word2Vec modell prediktív jellegű, addig a GloVe egy statisztikai alapú
(count-based) modell, melyek gyakorlati hasznosításukat tekintve nagyon
hasonlóak.

A szóvektor modellek között érdemes megemlíteni a fastText-et is, mely
157 nyelvre kínál (köztük magyarra is) a szóbeágyazás módszeren alapuló,
előre tanított szóvektorokat, melyet tovább lehet tanítani speciális
szövegkorpuszokra, ezzel jelentősen lerövidítve a modell tanításához
szükséges idő-, és kapacitásszükségletet
\protect\hyperlink{ref-mikolov2018advances}{Mikolov et al.}
(\protect\hyperlink{ref-mikolov2018advances}{2018}). Habár a GloVe és
Word2Vec skip-gram módszerek hasonlóságát a szakirodalom adottnak veszi,
a tényleges kép ennél árnyaltabb. A GloVe esetében a ritkán előforduló
szavak kisebb súlyt kapnak a szóvektorok számításánal, míg a Word2Vec
alulsúlyozz a nagy frekvenciájú szavakat. Ennek a következménye, hogy a
Word2Vec esetében gyakori hogy a szemantikailag legközelebbi szó az egy
elütés, nem pedig valid találat. Ennek ellenére a két módszer
(amennyiben a Word2Vec algoritmusnál a kisfrekvenciájú tokeneket
kiszűrjük) az emberi validálás során nagyon hasonló eredményeket hozott
\protect\hyperlink{ref-spirlingworda}{Spirling and Rodriguez}
(\protect\hyperlink{ref-spirlingworda}{n.d.b}).

A fejezetben a gyakorlati példa során a GloVe algoritmust használjuk
majd, mivel véleményünk szerint az implementációt tartalmazó R csomagnak
jobb a dokumentációja mint a többi alternatívának.

\hypertarget{glove-hasznuxe1lata-magyar-muxe9dia-korpuszon}{%
\subsection{GloVe használata magyar média
korpuszon}\label{glove-hasznuxe1lata-magyar-muxe9dia-korpuszon}}

Az elemzéshez a \texttt{text2vec} csomagot fogjuk használni, ami a GloVe
implementációt tartalmazza. A lenti kód a csomag dokumentáción alapul és
a Társadalomtudományi Kutatóközpont által a \emph{Hungarian Comparative
Agendas Project (CAP)} adatbázisában tárolt Magyar Nemzet korpuszt
használja.\footnote{A Magyar CAP Projekt által kezelt adatbázisok itt
  megtalálhatóak: \url{https://cap.tk.hu/adatbazisok}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(text2vec)}
\FunctionTok{library}\NormalTok{(quanteda)}
\FunctionTok{library}\NormalTok{(readtext)}
\FunctionTok{library}\NormalTok{(readr)}
\FunctionTok{library}\NormalTok{(dplyr)}
\FunctionTok{library}\NormalTok{(tibble)}
\FunctionTok{library}\NormalTok{(stringr)}
\end{Highlighting}
\end{Shaded}

A lenti kód blokk azt mutatja be, hogy hogyan kell a betöltött korpuszt
tokenizálni és mátrix formátumba alakítani. A korpusz az a Magyar Nemzet
2004 és 2014 közötti címlapos cikkeit tartalmazza. Az eddigi előkészítő
lépéseket most is megtesszük: kitöröljük a központozást, számokat,
magyar töltelékszavakat, illetve kisbetűsítünk és eltávolítjuk a
felesleges szóközöket és tördeléseket.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mn }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(}\StringTok{"data/mn\_large.csv"}\NormalTok{)}

\NormalTok{mn\_clean }\OtherTok{\textless{}{-}}\NormalTok{ mn }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{text =} \FunctionTok{str\_remove\_all}\NormalTok{(}\AttributeTok{string =}\NormalTok{ text, }\AttributeTok{pattern =} \StringTok{"[:cntrl:]"}\NormalTok{),}
    \AttributeTok{text =} \FunctionTok{str\_remove\_all}\NormalTok{(}\AttributeTok{string =}\NormalTok{ text, }\AttributeTok{pattern =} \StringTok{"[:punct:]"}\NormalTok{),}
    \AttributeTok{text =} \FunctionTok{str\_remove\_all}\NormalTok{(}\AttributeTok{string =}\NormalTok{ text, }\AttributeTok{pattern =} \StringTok{"[:digit:]"}\NormalTok{),}
    \AttributeTok{text =} \FunctionTok{str\_to\_lower}\NormalTok{(text),}
    \AttributeTok{text =} \FunctionTok{str\_trim}\NormalTok{(text),}
    \AttributeTok{text =} \FunctionTok{str\_squish}\NormalTok{(text)}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

Fontos különbség hogy az eddigi munkafolyamatokkal ellentétben a GloVe
algoritmus nem egy dokumentum-kifejezés mátrixon dolgozik, hanem egy
kifejezések együttes előfordulását tartalmazó mátrixot (feature
co-occurence matrix) kell készíteni inputként. Ezt a \texttt{quanteda}
\texttt{fcm()} függvényével tudjuk előállítani, ami a tokenekből készíti
el a mátrixot. A tokenek sorrendiségét úgy tudjuk megőrízni, hogy egy
\texttt{dfm} objektumból csak a kifejezéseket tartjuk meg a
\texttt{featnames()} függvény segítségével, majd a teljes token
halmazból a \texttt{tokens\_select()} függvénnyel kiválasztjuk őket.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mn\_corpus }\OtherTok{\textless{}{-}} \FunctionTok{corpus}\NormalTok{(mn\_clean)}

\NormalTok{mn\_tokens }\OtherTok{\textless{}{-}} \FunctionTok{tokens}\NormalTok{(mn\_corpus) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{tokens\_remove}\NormalTok{(}\FunctionTok{stopwords}\NormalTok{(}\AttributeTok{language =} \StringTok{"hungarian"}\NormalTok{))}

\NormalTok{features }\OtherTok{\textless{}{-}} \FunctionTok{dfm}\NormalTok{(mn\_tokens) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{dfm\_trim}\NormalTok{(}\AttributeTok{min\_termfreq =} \DecValTok{5}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{featnames}\NormalTok{()}

\NormalTok{mn\_tokens }\OtherTok{\textless{}{-}} \FunctionTok{tokens\_select}\NormalTok{(mn\_tokens, features, }\AttributeTok{padding =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Az \texttt{fcm} megalkotása során a célkifejezéstől való távolság
függvényében súlyozzuk a tokeneket.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mn\_fcm }\OtherTok{\textless{}{-}} \FunctionTok{fcm}\NormalTok{(mn\_tokens, }\AttributeTok{context =} \StringTok{"window"}\NormalTok{, }\AttributeTok{count =} \StringTok{"weighted"}\NormalTok{, }\AttributeTok{weights =} \DecValTok{1}\SpecialCharTok{/}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{5}\NormalTok{), }
    \AttributeTok{tri =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

A tényleges szóbeágyazás a \texttt{text2vec} csomaggal történik. A
\texttt{GlobalVector} egy új ``környezetet'' (environment) hoz létre.
Itt adhatjuk meg az alapvető paramétereket. A \texttt{rank} a vektor
dimenziót adja meg (az irodalomban a 300-500 dimenzió a megszokott). A
többi paraméterrel is lehet kísérletezni, hogy mennyire változtatja meg
a kapott szóbeágyazásokat. A \texttt{fit\_transform} pedig a tényleges
becslést végzi. Itt az iterációk számát (a gépi tanulásos irodalomban
\emph{epoch}-nak is hívják a tanulási köröket) és a korai leállás
(\emph{early stopping}) kritériumát a \texttt{convergence\_tol}
megadásával. Minél több dimenziót szeretnénk és minél több iterációt,
annál tovább fog tartani a szóbeágyazás futtatása.

Az egyszerűség és gyorsaság miatt a lenti kód 10 körös tanulást ad meg,
ami a relatíve kicsi Magyar Nemzet korpuszon \textasciitilde3 perc alatt
fut le.\footnote{A futtatásra használt PC nem különösebben erős: 4 magos
  Intel Core i5-4460 (3.2GHz) CPU és 16GB RAM} Természetesen minél
nagyobb korpuszon, minél több iterációt futtatunk, annál pontosabb
eredményt fogunk kapni. A \texttt{text2vec} csomag képes a számítások
párhuzamosítására, így alapbeállításként a rendelkezésre álló összes CPU
magot teljesen kihasználja a számításhoz. Ennek ellenére egy százezres,
milliós korpusz esetén több óra is lehet a tanítás.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{glove }\OtherTok{\textless{}{-}}\NormalTok{ GlobalVectors}\SpecialCharTok{$}\FunctionTok{new}\NormalTok{(}\AttributeTok{rank =} \DecValTok{300}\NormalTok{, }\AttributeTok{x\_max =} \DecValTok{10}\NormalTok{, }\AttributeTok{learning\_rate =} \FloatTok{0.1}\NormalTok{)}

\NormalTok{mn\_main }\OtherTok{\textless{}{-}}\NormalTok{ glove}\SpecialCharTok{$}\FunctionTok{fit\_transform}\NormalTok{(mn\_fcm, }\AttributeTok{n\_iter =} \DecValTok{10}\NormalTok{, }\AttributeTok{convergence\_tol =} \FloatTok{0.01}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

A végleges szóvektorokat a becslés során elkészült két mátrix
összegeként kapjuk.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mn\_context }\OtherTok{\textless{}{-}}\NormalTok{ glove}\SpecialCharTok{$}\NormalTok{components}

\NormalTok{mn\_word\_vectors }\OtherTok{\textless{}{-}}\NormalTok{ mn\_main }\SpecialCharTok{+} \FunctionTok{t}\NormalTok{(mn\_context)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# saveRDS(mn\_word\_vectors, "data/temp/mn\_word\_vector.RDS")}

\NormalTok{mn\_word\_vectors }\OtherTok{\textless{}{-}} \FunctionTok{readRDS}\NormalTok{(}\StringTok{"data/temp/mn\_word\_vector.RDS"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Az egyes szavakhoz legközelebb álló szavakat a koszinusz hasonlóság
alapján kapjuk, a \texttt{sim2()} függvénnyel. A lenti példában ``l2''
normalizálást alkalmazunk, majd a kapott hasonlósági vektort csökkenő
sorrendbe rendezzük. Példaként a ``polgármester'' szónak a környezetét
nézzük meg. Mivel a korpuszunk egy politikai napilap, ezért nem meglepő,
hogy a legközelebbi szavak a politikához kapcsolódnak.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{teszt }\OtherTok{\textless{}{-}}\NormalTok{ mn\_word\_vectors[}\StringTok{"polgármester"}\NormalTok{, , drop }\OtherTok{=}\NormalTok{ F]}

\NormalTok{cos\_sim\_rom }\OtherTok{\textless{}{-}} \FunctionTok{sim2}\NormalTok{(}\AttributeTok{x =}\NormalTok{ mn\_word\_vectors, }\AttributeTok{y =}\NormalTok{ teszt, }\AttributeTok{method =} \StringTok{"cosine"}\NormalTok{, }\AttributeTok{norm =} \StringTok{"l2"}\NormalTok{)}

\FunctionTok{head}\NormalTok{(}\FunctionTok{sort}\NormalTok{(cos\_sim\_rom[, }\DecValTok{1}\NormalTok{], }\AttributeTok{decreasing =} \ConstantTok{TRUE}\NormalTok{), }\DecValTok{5}\NormalTok{)}
\CommentTok{\#\textgreater{} polgármester        mszps  szocialista     fideszes     elmondta }
\CommentTok{\#\textgreater{}    1.0000000    0.5059529    0.4339177    0.4204766    0.4024232}
\end{Highlighting}
\end{Shaded}

A lenti \texttt{show\_vector()} függvényt definiálva a kapott eredmény
egy data frame lesz, és az \texttt{n} változtatásával a kapcsolódó
szavak számát is könnyen változtathatjuk.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{show\_vector }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(vectors, pattern, }\AttributeTok{n =} \DecValTok{5}\NormalTok{) \{}
\NormalTok{  term }\OtherTok{\textless{}{-}}\NormalTok{ mn\_word\_vectors[pattern, , drop }\OtherTok{=}\NormalTok{ F]}
\NormalTok{  cos\_sim }\OtherTok{\textless{}{-}} \FunctionTok{sim2}\NormalTok{(}\AttributeTok{x =}\NormalTok{ vectors, }\AttributeTok{y =}\NormalTok{ term, }\AttributeTok{method =} \StringTok{"cosine"}\NormalTok{, }\AttributeTok{norm =} \StringTok{"l2"}\NormalTok{)}
\NormalTok{  cos\_sim\_head }\OtherTok{\textless{}{-}} \FunctionTok{head}\NormalTok{(}\FunctionTok{sort}\NormalTok{(cos\_sim[, }\DecValTok{1}\NormalTok{], }\AttributeTok{decreasing =} \ConstantTok{TRUE}\NormalTok{), n)}
\NormalTok{  output }\OtherTok{\textless{}{-}} \FunctionTok{enframe}\NormalTok{(cos\_sim\_head, }\AttributeTok{name =} \StringTok{"term"}\NormalTok{, }\AttributeTok{value =} \StringTok{"dist"}\NormalTok{)}
  \FunctionTok{return}\NormalTok{(output)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Példaként a ``barack'' nem gyümölcsöket fog adni, hanem az Egyesült
Államok elnökét és hozzá kapcsolódó szavakat.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{show\_vector}\NormalTok{(mn\_word\_vectors, }\StringTok{"barack"}\NormalTok{, }\DecValTok{10}\NormalTok{)}
\CommentTok{\#\textgreater{} \# A tibble: 10 x 2}
\CommentTok{\#\textgreater{}    term              dist}
\CommentTok{\#\textgreater{}    \textless{}chr\textgreater{}            \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{}  1 barack           1.00 }
\CommentTok{\#\textgreater{}  2 obama            0.691}
\CommentTok{\#\textgreater{}  3 elnök            0.372}
\CommentTok{\#\textgreater{}  4 amerikai         0.349}
\CommentTok{\#\textgreater{}  5 demokrata        0.339}
\CommentTok{\#\textgreater{}  6 republikánus     0.294}
\CommentTok{\#\textgreater{}  7 részesülhessenek 0.256}
\CommentTok{\#\textgreater{}  8 egyesült         0.253}
\CommentTok{\#\textgreater{}  9 elnököt          0.251}
\CommentTok{\#\textgreater{} 10 bush             0.239}
\end{Highlighting}
\end{Shaded}

Ugyanez működik magyar vezetőkkel is.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{show\_vector}\NormalTok{(mn\_word\_vectors, }\StringTok{"orbán"}\NormalTok{, }\DecValTok{10}\NormalTok{)}
\CommentTok{\#\textgreater{} \# A tibble: 10 x 2}
\CommentTok{\#\textgreater{}    term            dist}
\CommentTok{\#\textgreater{}    \textless{}chr\textgreater{}          \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{}  1 orbán          1.00 }
\CommentTok{\#\textgreater{}  2 viktor         0.937}
\CommentTok{\#\textgreater{}  3 miniszterelnök 0.743}
\CommentTok{\#\textgreater{}  4 mondta         0.701}
\CommentTok{\#\textgreater{}  5 jelentette     0.673}
\CommentTok{\#\textgreater{}  6 kormányfo      0.667}
\CommentTok{\#\textgreater{}  7 fogalmazott    0.661}
\CommentTok{\#\textgreater{}  8 fidesz         0.656}
\CommentTok{\#\textgreater{}  9 hangsúlyozta   0.655}
\CommentTok{\#\textgreater{} 10 beszélt        0.624}
\end{Highlighting}
\end{Shaded}

\hypertarget{szuxf6vegskuxe1luxe1zuxe1s-feluxfcgyelet-nuxe9lkuxfcli-uxe9s-feluxfcgyelt-megolduxe1sok}{%
\chapter{Szövegskálázás: felügyelet nélküli és felügyelt
megoldások}\label{szuxf6vegskuxe1luxe1zuxe1s-feluxfcgyelet-nuxe9lkuxfcli-uxe9s-feluxfcgyelt-megolduxe1sok}}

A szövegskálázás célja a politikai szereplők elhelyezése az ideológiai
térben. Ennek felügyelt tipusa a \texttt{wordscores}, amely a szótári
módszerekhez hasonlóan a szereplőket szavaik alapján helyezi el a
politikai térben, úgy hogy az ún.referencia dokumentumok szövegét
használja tanító halmazként. A \texttt{wordscores} kiindulópontja, hogy
pozíció pontszámokat kell rendelni referencia szövegekhez. A modell
számításba veszi szövegek szavainak súlyozott gyakoriságát és a
pozíciópontszám valamint a szógyakoriság alapján becsülni meg a
korpuszban lévő többi dokumentum pozícióját.
(\protect\hyperlink{ref-laver2003extracting}{Laver, Benoit, and Garry
2003}). A felügyelet nélküli \texttt{wordfish} módszer a skálázás során
nem a referencia dokumentumokra támaszkodik, hanem olyan kifejezéseket
keres a szövegben, amelyek megkülönböztetik egymástól a politikai
spektrum különböző pontjain elhelyezkedő beszélőket. Az IRT-n (item
response theory) alapuló módszer azt feltételezi, hogy a politikusok egy
kevés dimenziós politikai térben mozognak, amely tér leírható az i
politikus 𝝷\textsubscript{1} paraméterével. Egy politikus (vagy párt)
ezen a téren elfoglalt helyzete pedig befolyásolja a szavak szövegekben
történő használatát. A módszer erőssége, hogy kevés
erőforrás-befektetéssel megbízható becsléseket ad, ha a szövegek valóban
az ideológiák mentén különböznek, tehát ha a szereplők erősen ideológiai
tartalamú diskurzust folytatnak. Alkalmazásakor azonban tudnunk kell,
hogy a módszer nem képes kezelni, hogy a szövegek között nem csak
ideológiai különbség lehet. Mivel a modell nem felügyelt, ezért nehéz
garantálni, hogy valóban megbízhatóan azonosítja a szereplők
elhelyezkedését a politikai térben, így az eredményeket mindenképpen
körültekintően kell validálni.
{[}(\protect\hyperlink{ref-slapin2008}{\textbf{slapin2008?}});
(\protect\hyperlink{ref-hjorth2015}{\textbf{hjorth2015?}});
(\protect\hyperlink{ref-grimmer2013text}{Grimmer and Stewart 2013a}){]}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(readr)}
\FunctionTok{library}\NormalTok{(dplyr)}
\FunctionTok{library}\NormalTok{(stringr)}
\FunctionTok{library}\NormalTok{(ggplot2)}
\FunctionTok{library}\NormalTok{(quanteda)}
\FunctionTok{library}\NormalTok{(quanteda.textmodels)}
\end{Highlighting}
\end{Shaded}

A skálázási algoritmusokat egy kicsi korpuszon fogjuk bemutatni. A minta
dokumentumok a 2014-2018 parlamenti ciklusban frakcióvezető politikusok
egy-egy véletlenszerűen kiválasztott napirend előtti felszólalásai.
Ebben a ciklusban összesen 11 frakcióvezetője volt a két kormánypárti és
öt ellenzéki frakciónak.\footnote{A mintába nem került be Rogán Antal,
  akinek csak egy darab napirend előtti felszólalása volt.} A
dokumentumokon a rutin előkészítési lépéseket végezzük csak el
(tördelések, számok, központozás kitörlése, kisbetűsítés). Természetesen
minél alaposabbak vagyunk a szövegek tisztításával, annál pontosabb
végeredményt fogunk kapni.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{parl\_beszedek }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(}\StringTok{"data/ps\_sample.csv"}\NormalTok{)}

\NormalTok{beszedek\_tiszta }\OtherTok{\textless{}{-}}\NormalTok{ parl\_beszedek }\SpecialCharTok{\%\textgreater{}\%} 
    \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{text =} \FunctionTok{str\_remove\_all}\NormalTok{(}\AttributeTok{string =}\NormalTok{ text, }\AttributeTok{pattern =} \StringTok{"[:cntrl:]"}\NormalTok{),}
    \AttributeTok{text =} \FunctionTok{str\_remove\_all}\NormalTok{(}\AttributeTok{string =}\NormalTok{ text, }\AttributeTok{pattern =} \StringTok{"[:punct:]"}\NormalTok{),}
    \AttributeTok{text =} \FunctionTok{str\_remove\_all}\NormalTok{(}\AttributeTok{string =}\NormalTok{ text, }\AttributeTok{pattern =} \StringTok{"[:digit:]"}\NormalTok{),}
    \AttributeTok{text =} \FunctionTok{str\_to\_lower}\NormalTok{(text),}
    \AttributeTok{text =} \FunctionTok{str\_trim}\NormalTok{(text),}
    \AttributeTok{text =} \FunctionTok{str\_squish}\NormalTok{(text)}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

A \emph{Wordfish} és \emph{Wordscores} algoritmus is ugyanazt a kiinduló
corpus és dfm objektumot fogja használni, amit a szokásos módon a
\texttt{quanteda} csomag \texttt{corpus()} függvényével hozunk létre. A
leíró statisztikai tááblázatban látszik, hogy a beszédek hosszúsága nem
egységes, a leghosszabb 10267 szavas, a legrövidebb pedig 1976. Az
átlagos dokumentum hossz az 5135.5714286. A korpusz szemléltető célú, az
eddig megszokott módon minél több/hosszabb dokumentummal dolgozunk,
annál könnyebb dolga van az algoritmusoknak.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{beszedek\_corpus }\OtherTok{\textless{}{-}} \FunctionTok{corpus}\NormalTok{(beszedek\_tiszta)}

\FunctionTok{summary}\NormalTok{(beszedek\_corpus)}
\CommentTok{\#\textgreater{} Corpus consisting of 10 documents, showing 10 documents:}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}    Text Types Tokens Sentences                     id}
\CommentTok{\#\textgreater{}   text1   442    819         1 20142018\_024\_0002\_0002}
\CommentTok{\#\textgreater{}   text2   354    607         1 20142018\_055\_0002\_0002}
\CommentTok{\#\textgreater{}   text3   426    736         1 20142018\_064\_0002\_0002}
\CommentTok{\#\textgreater{}   text4   314    538         1 20142018\_115\_0002\_0002}
\CommentTok{\#\textgreater{}   text5   354    589         1 20142018\_158\_0002\_0002}
\CommentTok{\#\textgreater{}   text6   333    538         1 20142018\_172\_0002\_0002}
\CommentTok{\#\textgreater{}   text7   344    559         1 20142018\_206\_0002\_0002}
\CommentTok{\#\textgreater{}   text8   352    628         1 20142018\_212\_0002\_0002}
\CommentTok{\#\textgreater{}   text9   317    492         1 20142018\_236\_0002\_0002}
\CommentTok{\#\textgreater{}  text10   343    600         1 20142018\_249\_0002\_0002}
\CommentTok{\#\textgreater{}                   felszolalo   part}
\CommentTok{\#\textgreater{}          Vona Gábor (Jobbik) Jobbik}
\CommentTok{\#\textgreater{}    Dr. Schiffer András (LMP)    LMP}
\CommentTok{\#\textgreater{}     Dr. Szél Bernadett (LMP)    LMP}
\CommentTok{\#\textgreater{}         Tóbiás József (MSZP)   MSZP}
\CommentTok{\#\textgreater{}       Schmuck Erzsébet (LMP)    LMP}
\CommentTok{\#\textgreater{}     Dr. Tóth Bertalan (MSZP)   MSZP}
\CommentTok{\#\textgreater{}        Volner János (Jobbik) Jobbik}
\CommentTok{\#\textgreater{}          Kósa Lajos (Fidesz) Fidesz}
\CommentTok{\#\textgreater{}         Harrach Péter (KDNP)   KDNP}
\CommentTok{\#\textgreater{}  Dr. Gulyás Gergely (Fidesz) Fidesz}
\end{Highlighting}
\end{Shaded}

Végezetül elkészítjük a dfm mátrixot és a magyar stopszavakat
kitöröljük.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{beszedek\_dfm }\OtherTok{\textless{}{-}}\NormalTok{ beszedek\_corpus }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{tokens}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{tokens\_remove}\NormalTok{(}\FunctionTok{stopwords}\NormalTok{(}\StringTok{"hungarian"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{dfm}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\hypertarget{wordfish}{%
\section{Wordfish}\label{wordfish}}

A wordfish felügyelet nélküli skálázást a \texttt{quanteda\_textmodels}
csomagban implementált \texttt{textmodel\_wordfish()} függvény fogja
végezni. A megadott \texttt{dir\ =\ c(1,\ 2)} paraméterrel a két
dokumentum relatív \(\theta\) értékét tudjuk rögzíteni, mégpedig úgy
hogy \(\theta_{dir1} < \theta_{dir2}\). Alapbeállításként az első és
utolsó dokumentumot teszi ide be az algoritmus. A lenti példánál mi a
pártpozíciók alapján a Jobbikos Vona Gábor és az LMP-s Schiffer András
egy-egy beszédét használtuk. A \texttt{summary()} használható az
illesztett modellel, és a dokumentumonkénti \(\theta\) koefficienst
tudjuk így megnézni.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{beszedek\_wf }\OtherTok{\textless{}{-}} \FunctionTok{textmodel\_wordfish}\NormalTok{(beszedek\_dfm, }\AttributeTok{dir =} \FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{))}

\FunctionTok{summary}\NormalTok{(beszedek\_wf)}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Call:}
\CommentTok{\#\textgreater{} textmodel\_wordfish.dfm(x = beszedek\_dfm, dir = c(2, 1))}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Estimated Document Positions:}
\CommentTok{\#\textgreater{}           theta      se}
\CommentTok{\#\textgreater{} text1   1.79474 0.04219}
\CommentTok{\#\textgreater{} text2   0.08931 0.04001}
\CommentTok{\#\textgreater{} text3   1.00137 0.03908}
\CommentTok{\#\textgreater{} text4  {-}0.09988 0.04232}
\CommentTok{\#\textgreater{} text5   0.73596 0.04355}
\CommentTok{\#\textgreater{} text6   0.18572 0.04452}
\CommentTok{\#\textgreater{} text7  {-}0.72832 0.03590}
\CommentTok{\#\textgreater{} text8  {-}0.80587 0.03358}
\CommentTok{\#\textgreater{} text9  {-}0.52028 0.04005}
\CommentTok{\#\textgreater{} text10 {-}1.65273 0.03794}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Estimated Feature Scores:}
\CommentTok{\#\textgreater{}        vona  gábor  jobbik tisztelt    elnök      úr országgyulés tegnapi}
\CommentTok{\#\textgreater{} beta  3.675  2.321  1.9710   0.2391 {-}0.11149 0.02755       1.2286   4.372}
\CommentTok{\#\textgreater{} psi  {-}4.980 {-}2.734 {-}0.7531   0.4566 {-}0.05693 0.28721      {-}0.6705  {-}5.314}
\CommentTok{\#\textgreater{}       napon helyen tartottak idoközi önkormányzati választásokat     két}
\CommentTok{\#\textgreater{} beta  2.991  3.103     3.675   3.675         3.675         3.675  1.1894}
\CommentTok{\#\textgreater{} psi  {-}3.009 {-}2.630    {-}4.980  {-}4.980        {-}4.980        {-}4.980 {-}0.9439}
\CommentTok{\#\textgreater{}      érdekelt recsken  ózdon október nyertünk örömmel közlöm  ország}
\CommentTok{\#\textgreater{} beta    3.675   4.372  4.774   3.405    3.675   3.675  3.675  1.7470}
\CommentTok{\#\textgreater{} psi    {-}4.980  {-}5.314 {-}5.545  {-}3.230   {-}4.980  {-}4.980 {-}4.980 {-}0.3643}
\CommentTok{\#\textgreater{}      közvéleményével  amúgy     is tudnak mindkét jobbikos polgármester}
\CommentTok{\#\textgreater{} beta           3.675  3.675 0.9128  1.433   3.675    3.675        3.675}
\CommentTok{\#\textgreater{} psi           {-}4.980 {-}4.980 1.8345 {-}1.737  {-}4.980   {-}4.980       {-}4.980}
\end{Highlighting}
\end{Shaded}

Amennyiben szeretnénk a szavak szintjén is megnézni a \(\beta\) (a
szavakhoz társított súly, ami a relatív fontosságát mutatja) és \(\psi\)
(a szó fix effekt, ami az eltérő szófrekvencia kezeléséért felelős)
koefficiensekhez, akkor a \texttt{beszedek\_wf} objektumban tárolt
értékeket egy data frame-be tudjuk bemásolni. A dokumentumok hosszára és
a szófrekfenviát figyelembe véve, a negatív \(\beta\) értékű szavakat
gyakrabban használják a negatív \(\theta\) koefficienssel rendelkező
politikusok.

\begin{Shaded}
\begin{Highlighting}[]

\NormalTok{szavak\_wf }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{word =}\NormalTok{ beszedek\_wf}\SpecialCharTok{$}\NormalTok{features, }
  \AttributeTok{beta =}\NormalTok{ beszedek\_wf}\SpecialCharTok{$}\NormalTok{beta, }
  \AttributeTok{psi =}\NormalTok{ beszedek\_wf}\SpecialCharTok{$}\NormalTok{psi}
\NormalTok{  )}

\NormalTok{szavak\_wf }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{arrange}\NormalTok{(beta) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{head}\NormalTok{(}\AttributeTok{n =} \DecValTok{15}\NormalTok{)}
\CommentTok{\#\textgreater{}              word      beta       psi}
\CommentTok{\#\textgreater{} 1        czeglédy {-}5.900663 {-}6.222629}
\CommentTok{\#\textgreater{} 2           csaba {-}5.769959 {-}6.151399}
\CommentTok{\#\textgreater{} 3           human {-}5.438681 {-}5.975155}
\CommentTok{\#\textgreater{} 4        operator {-}5.438681 {-}5.975155}
\CommentTok{\#\textgreater{} 5             zrt {-}5.216835 {-}5.860931}
\CommentTok{\#\textgreater{} 6         fizette {-}4.927204 {-}5.717002}
\CommentTok{\#\textgreater{} 7           gyanú {-}4.927204 {-}5.717002}
\CommentTok{\#\textgreater{} 8     szocialista {-}4.927204 {-}5.717002}
\CommentTok{\#\textgreater{} 9      elkövetett {-}4.509192 {-}5.521276}
\CommentTok{\#\textgreater{} 10         tárgya {-}4.509192 {-}5.521276}
\CommentTok{\#\textgreater{} 11     céghálózat {-}4.509192 {-}5.521276}
\CommentTok{\#\textgreater{} 12         diákok {-}4.509192 {-}5.521276}
\CommentTok{\#\textgreater{} 13         májusi {-}4.509192 {-}5.521276}
\CommentTok{\#\textgreater{} 14        júniusi {-}4.509192 {-}5.521276}
\CommentTok{\#\textgreater{} 15 büntetoeljárás {-}4.509192 {-}5.521276}
\end{Highlighting}
\end{Shaded}

Ez a pozitív értékekre is igaz.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{szavak\_wf }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{arrange}\NormalTok{(}\FunctionTok{desc}\NormalTok{(beta)) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{head}\NormalTok{(}\AttributeTok{n =} \DecValTok{15}\NormalTok{)}
\CommentTok{\#\textgreater{}            word     beta       psi}
\CommentTok{\#\textgreater{} 1    nemzetközi 5.057078 {-}5.720709}
\CommentTok{\#\textgreater{} 2       önöknek 4.977502 {-}4.778607}
\CommentTok{\#\textgreater{} 3         ózdon 4.773523 {-}5.544626}
\CommentTok{\#\textgreater{} 4   kétharmados 4.773523 {-}5.544626}
\CommentTok{\#\textgreater{} 5        igenis 4.773523 {-}5.544626}
\CommentTok{\#\textgreater{} 6    választási 4.773523 {-}5.544626}
\CommentTok{\#\textgreater{} 7  geopolitikai 4.773523 {-}5.544626}
\CommentTok{\#\textgreater{} 8   ártatlanság 4.773523 {-}5.544626}
\CommentTok{\#\textgreater{} 9       vélelme 4.773523 {-}5.544626}
\CommentTok{\#\textgreater{} 10      tegnapi 4.372320 {-}5.314088}
\CommentTok{\#\textgreater{} 11      recsken 4.372320 {-}5.314088}
\CommentTok{\#\textgreater{} 12       lássuk 4.372320 {-}5.314088}
\CommentTok{\#\textgreater{} 13       tolünk 4.372320 {-}5.314088}
\CommentTok{\#\textgreater{} 14     janiczak 4.372320 {-}5.314088}
\CommentTok{\#\textgreater{} 15  szavazattal 4.372320 {-}5.314088}
\end{Highlighting}
\end{Shaded}

Az eredményeinket mind a szavak és mind a dokumentumok szintjén tudjuk
vizualizálni. Elsőként a klasszikus ``Eiffel-torony'' ábrát
reprodukáljuk, ami a szavak gyakorisága és skálára gyakorolt
befolyásának az illusztrálására szolgál. Ehhez a már elkészült
\texttt{szavak\_wf} data framet és a \texttt{ggplot2} csomagot fogjuk
használni. Mivel a korpuszunk nagyon kicsi ezért csak 2410 kifejezést
fogunk ábrázolni. Ennek ellenére a lényeg kirajzolódik a lenti ábrán
is.\footnote{A \texttt{quanteda.textplots} csomag több megoldást is
  kínál az ábrák elkészítésére. Mivel ezek a megoldások kifejezetten a
  quanteda elemzések ábrázolására készültek, ezért rövid egysoros
  függvényekkel tudunk gyorsan ábrákat készíteni. A hátrányuk, hogy
  kevésbé tudjuk ``személyre szabni'' az ábráinkat, mint a
  \texttt{ggplot2} példák esetében. A \texttt{quanteda.textplots}
  megoldásokat ezen a linken demonstrálják a csomag készítői:
  \url{https://quanteda.io/articles/pkgdown/examples/plotting.html}}

Kihasználhatjuk, hogy a \texttt{ggplot} ábra definiálása közben a
felhasznált bemeneti data frame-t különböző szempontok alapján lehet
szűrni. így ábrázolni tudjuk a gyakran használt ám semleges szavakat
(magas \(\psi\), alacsony \(\beta\)), illetve a ritkább de meghatározóbb
szavakat (magas \(\beta\), alacsony \(\psi\)).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(szavak\_wf, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ beta, }\AttributeTok{y =}\NormalTok{ psi)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{color =} \StringTok{"grey"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_text}\NormalTok{(}
    \AttributeTok{data =} \FunctionTok{filter}\NormalTok{(szavak\_wf, beta }\SpecialCharTok{\textgreater{}} \DecValTok{5} \SpecialCharTok{|}\NormalTok{ beta }\SpecialCharTok{\textless{}} \SpecialCharTok{{-}}\FloatTok{4.5} \SpecialCharTok{|}\NormalTok{ psi }\SpecialCharTok{\textgreater{}} \DecValTok{0}\NormalTok{),}
    \FunctionTok{aes}\NormalTok{(beta, psi, }\AttributeTok{label =}\NormalTok{ word),}
    \AttributeTok{alpha =} \FloatTok{0.7}
\NormalTok{    ) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{x =} \FunctionTok{expression}\NormalTok{(beta),}
    \AttributeTok{y =} \FunctionTok{expression}\NormalTok{(psi)}
\NormalTok{    )}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{_main_files/figure-latex/unnamed-chunk-149-1} \end{center}

A dokumentumok szintjén is érdemes megvizsgálni az eredményeket. Ehhez a
dokumentum szintű paramétereket fogjuk egy data framebe gyűjteni: a
\(\theta\) ideológiai pozíciót, illetve a beszélő nevét. A vizualizáció
kedvéért a párttagságot is hozzáadjuk. A data frame összerakása után az
alsó és felső határát is kiszámoljuk a konfidencia intervallumnak és azt
is ábrázoljuk.

\begin{Shaded}
\begin{Highlighting}[]

\NormalTok{dokumentumok\_wf }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{speaker =}\NormalTok{ beszedek\_wf}\SpecialCharTok{$}\NormalTok{x}\SpecialCharTok{@}\NormalTok{docvars}\SpecialCharTok{$}\NormalTok{felszolalo,}
  \AttributeTok{part =}\NormalTok{ beszedek\_wf}\SpecialCharTok{$}\NormalTok{x}\SpecialCharTok{@}\NormalTok{docvars}\SpecialCharTok{$}\NormalTok{part,}
  \AttributeTok{theta =}\NormalTok{ beszedek\_wf}\SpecialCharTok{$}\NormalTok{theta,}
  \AttributeTok{theta\_se =}\NormalTok{ beszedek\_wf}\SpecialCharTok{$}\NormalTok{se.theta}
\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{lower =}\NormalTok{ theta }\SpecialCharTok{{-}} \FloatTok{1.96} \SpecialCharTok{*}\NormalTok{ theta\_se,}
    \AttributeTok{upper =}\NormalTok{ theta }\SpecialCharTok{+} \FloatTok{1.96} \SpecialCharTok{*}\NormalTok{ theta\_se}
\NormalTok{  )}

\FunctionTok{ggplot}\NormalTok{(dokumentumok\_wf, }\FunctionTok{aes}\NormalTok{(theta, }\FunctionTok{reorder}\NormalTok{(speaker, theta))) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_errorbarh}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{xmin =}\NormalTok{ lower, }\AttributeTok{xmax =}\NormalTok{ upper), }\AttributeTok{height =} \DecValTok{0}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{y =} \ConstantTok{NULL}\NormalTok{,}
    \AttributeTok{x =} \FunctionTok{expression}\NormalTok{(theta)}
\NormalTok{  ) }
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{_main_files/figure-latex/unnamed-chunk-150-1} \end{center}

A párt metaadattal összehasonlíthatjuk az egy párthoz tartozó
frakcióvezetők értékeit a \texttt{facet\_wrap()} használatával.
Figzeljünk arra hogy az \texttt{y} tengelyen szabadon

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(dokumentumok\_wf, }\FunctionTok{aes}\NormalTok{(theta, }\FunctionTok{reorder}\NormalTok{(speaker, theta))) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_errorbarh}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{xmin =}\NormalTok{ lower, }\AttributeTok{xmax =}\NormalTok{ upper), }\AttributeTok{height =} \DecValTok{0}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{y =} \ConstantTok{NULL}\NormalTok{,}
    \AttributeTok{x =} \FunctionTok{expression}\NormalTok{(theta)}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{part, }\AttributeTok{ncol =} \DecValTok{1}\NormalTok{, }\AttributeTok{scales =} \StringTok{"free\_y"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{_main_files/figure-latex/unnamed-chunk-151-1} \end{center}

\hypertarget{wordscores}{%
\section{Wordscores}\label{wordscores}}

A modell illesztést a wordfish-ez hasonlóan a
\texttt{quanteda.textmodels} csomagban található
\texttt{textmodel\_wordscores()} függvény végzi. A kiinduló dfm ugyanaz
mint amit a fejezet elején elkészítettünk, a \texttt{beszedek\_dfm}.

A referencia pontokat dokumentumváltozóként hozzáadjuk a dfm-hez a
\texttt{refrencia\_pont} oszlopot, ami \texttt{NA} értéket kap
alapértelmezetten. A kiválasztott referencia dokumentumoknál pedig
egyenként hozzáadjuk az értékeket. Erre több megoldás is van, az
egyszerűbb út, hogy az egyik és másik végletet a \texttt{-1;\ 1}
intervallummal jelöljük. Ennek a lehetséges alternatívája, hogy egy
külső, már validált forrást használunk. Pártok esetén ilyen lehet a
Chapel Hill szakértői kérdőívének a pontszámai, a Manifesto projekt
által kódolt jobb-bal (\emph{rile}) dimenzó. A lenti példánál mi
maradunk az egyszerűbb bináris kódolásnál. A wordfish eredményt alapul
véve a két referencia pont a Gulyás Gergely és Szél Bernadett beszédei
lesznek.\footnote{Azért nem a Vona Gábor beszédét választottuk, mert az
  gyaníthatóan egy kiugró érték ami nem reprezentálja a sokaságot
  megfelően.} Ezek a 3. és 10. dokumentumok.

\begin{Shaded}
\begin{Highlighting}[]

\FunctionTok{docvars}\NormalTok{(beszedek\_dfm, }\StringTok{"referencia\_pont"}\NormalTok{) }\OtherTok{\textless{}{-}} \ConstantTok{NA}
\FunctionTok{docvars}\NormalTok{(beszedek\_dfm, }\StringTok{"referencia\_pont"}\NormalTok{)[}\DecValTok{3}\NormalTok{] }\OtherTok{\textless{}{-}} \SpecialCharTok{{-}}\DecValTok{1}
\FunctionTok{docvars}\NormalTok{(beszedek\_dfm, }\StringTok{"referencia\_pont"}\NormalTok{)[}\DecValTok{10}\NormalTok{] }\OtherTok{\textless{}{-}} \DecValTok{1}

\FunctionTok{docvars}\NormalTok{(beszedek\_dfm)}
\CommentTok{\#\textgreater{}                        id                  felszolalo   part referencia\_pont}
\CommentTok{\#\textgreater{} 1  20142018\_024\_0002\_0002         Vona Gábor (Jobbik) Jobbik              NA}
\CommentTok{\#\textgreater{} 2  20142018\_055\_0002\_0002   Dr. Schiffer András (LMP)    LMP              NA}
\CommentTok{\#\textgreater{} 3  20142018\_064\_0002\_0002    Dr. Szél Bernadett (LMP)    LMP              {-}1}
\CommentTok{\#\textgreater{} 4  20142018\_115\_0002\_0002        Tóbiás József (MSZP)   MSZP              NA}
\CommentTok{\#\textgreater{} 5  20142018\_158\_0002\_0002      Schmuck Erzsébet (LMP)    LMP              NA}
\CommentTok{\#\textgreater{} 6  20142018\_172\_0002\_0002    Dr. Tóth Bertalan (MSZP)   MSZP              NA}
\CommentTok{\#\textgreater{} 7  20142018\_206\_0002\_0002       Volner János (Jobbik) Jobbik              NA}
\CommentTok{\#\textgreater{} 8  20142018\_212\_0002\_0002         Kósa Lajos (Fidesz) Fidesz              NA}
\CommentTok{\#\textgreater{} 9  20142018\_236\_0002\_0002        Harrach Péter (KDNP)   KDNP              NA}
\CommentTok{\#\textgreater{} 10 20142018\_249\_0002\_0002 Dr. Gulyás Gergely (Fidesz) Fidesz               1}
\end{Highlighting}
\end{Shaded}

A lenti wordscore model specifikáció követi a
\protect\hyperlink{ref-laver2003extracting}{Laver, Benoit, and Garry}
(\protect\hyperlink{ref-laver2003extracting}{2003}) - ben leírtakat.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{beszedek\_ws }\OtherTok{\textless{}{-}} \FunctionTok{textmodel\_wordscores}\NormalTok{(}
  \AttributeTok{x =}\NormalTok{ beszedek\_dfm,}
  \AttributeTok{y =} \FunctionTok{docvars}\NormalTok{(beszedek\_dfm, }\StringTok{"referencia\_pont"}\NormalTok{),}
  \AttributeTok{scale =} \StringTok{"linear"}\NormalTok{,}
  \AttributeTok{smooth =} \DecValTok{0}
\NormalTok{  )}

\FunctionTok{summary}\NormalTok{(beszedek\_ws, }\DecValTok{10}\NormalTok{)}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Call:}
\CommentTok{\#\textgreater{} textmodel\_wordscores.dfm(x = beszedek\_dfm, y = docvars(beszedek\_dfm, }
\CommentTok{\#\textgreater{}     "referencia\_pont"), scale = "linear", smooth = 0)}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Reference Document Statistics:}
\CommentTok{\#\textgreater{}        score total min max   mean median}
\CommentTok{\#\textgreater{} text1     NA   486   0  18 0.2017      0}
\CommentTok{\#\textgreater{} text2     NA   395   0  12 0.1639      0}
\CommentTok{\#\textgreater{} text3     {-}1   439   0  12 0.1822      0}
\CommentTok{\#\textgreater{} text4     NA   330   0   7 0.1369      0}
\CommentTok{\#\textgreater{} text5     NA   360   0   8 0.1494      0}
\CommentTok{\#\textgreater{} text6     NA   328   0   5 0.1361      0}
\CommentTok{\#\textgreater{} text7     NA   349   0   5 0.1448      0}
\CommentTok{\#\textgreater{} text8     NA   387   0  10 0.1606      0}
\CommentTok{\#\textgreater{} text9     NA   307   0  13 0.1274      0}
\CommentTok{\#\textgreater{} text10     1   383   0   8 0.1589      0}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Wordscores:}
\CommentTok{\#\textgreater{} (showing first 10 elements)}
\CommentTok{\#\textgreater{}     tisztelt        elnök           úr országgyulés       ország           is }
\CommentTok{\#\textgreater{}     {-}0.07547      0.39255      0.06813      0.06813     {-}1.00000     {-}0.19859 }
\CommentTok{\#\textgreater{}          sot      nemhogy        tette       fidesz }
\CommentTok{\#\textgreater{}     {-}1.00000     {-}1.00000     {-}1.00000      1.00000}
\end{Highlighting}
\end{Shaded}

Az illesztett wordscores modellünkkel ezek után már meg tudjuk becsülni
a korpuszban lévő többi dokumentum pozícióját. Ehhez az R beépített
\texttt{predict()} megoldását használjuk. A kiegészítő opciókkal a
konfidencia intervallum alsó és felső határát is meg tudjuk becsülni,
ami jól jön hogyha szeretnénk ábrázolni az eredményt.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{beszedek\_ws\_pred }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(}
\NormalTok{  beszedek\_ws, }
  \AttributeTok{newdata =}\NormalTok{ beszedek\_dfm,}
  \AttributeTok{interval =} \StringTok{"confidence"}\NormalTok{)}

\NormalTok{beszedek\_ws\_pred }\OtherTok{\textless{}{-}} \FunctionTok{as.data.frame}\NormalTok{(beszedek\_ws\_pred}\SpecialCharTok{$}\NormalTok{fit)}

\NormalTok{beszedek\_ws\_pred}
\CommentTok{\#\textgreater{}                 fit         lwr         upr}
\CommentTok{\#\textgreater{} text1  {-}0.489860579 {-}0.62138707 {-}0.35833409}
\CommentTok{\#\textgreater{} text2  {-}0.234609623 {-}0.39658117 {-}0.07263807}
\CommentTok{\#\textgreater{} text3  {-}0.909048451 {-}0.93507086 {-}0.88302605}
\CommentTok{\#\textgreater{} text4  {-}0.296528588 {-}0.47539855 {-}0.11765863}
\CommentTok{\#\textgreater{} text5  {-}0.259074418 {-}0.44948427 {-}0.06866457}
\CommentTok{\#\textgreater{} text6   0.006320468 {-}0.23056645  0.24320738}
\CommentTok{\#\textgreater{} text7   0.165042014 {-}0.06144022  0.39152425}
\CommentTok{\#\textgreater{} text8  {-}0.077739857 {-}0.27645536  0.12097565}
\CommentTok{\#\textgreater{} text9  {-}0.123985348 {-}0.31176579  0.06379509}
\CommentTok{\#\textgreater{} text10  0.909048451  0.87934394  0.93875296}
\end{Highlighting}
\end{Shaded}

A kapott modellünket a wordfishez hasonlóan tudjuk ábrázolni, miután a
\texttt{beszedek\_ws\_pred} objektumból egy data framet csinálunk és a
\texttt{ggplot2}-vel elkészítjük a vizualizációt. A
\texttt{dokumentumok\_ws} két részből áll össze. Először a wordscores
modell objektumunkból a frakcióvezetők neveit és pártjaikat emeljük ki
(kicsit körülményes a dolog mert egy komplexebb objektumban tárolja őket
a \texttt{quanteda}, de az \texttt{str()} függvény tud segíteni ilyen
esetekben). A dokumentumok becsült pontszámait pedig a
\texttt{beszedek\_ws\_pred} objektumból készített data frame
hozzácsatolásával tesszük meg. Ehhez a \texttt{dplyr} csomag
\texttt{bind\_cols} függvényét használjuk. Fontos, hogy itt teljesen
biztosnak kell lennünk abban, hogy a sorok a két data frame esetében
ugyanarra a dokumentumra vonatkoznak.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dokumentumok\_ws }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{speaker =}\NormalTok{ beszedek\_ws}\SpecialCharTok{$}\NormalTok{x}\SpecialCharTok{@}\NormalTok{docvars}\SpecialCharTok{$}\NormalTok{felszolalo,}
  \AttributeTok{part =}\NormalTok{ beszedek\_ws}\SpecialCharTok{$}\NormalTok{x}\SpecialCharTok{@}\NormalTok{docvars}\SpecialCharTok{$}\NormalTok{part}
\NormalTok{)}

\NormalTok{dokumentumok\_ws }\OtherTok{\textless{}{-}} \FunctionTok{bind\_cols}\NormalTok{(dokumentumok\_ws, beszedek\_ws\_pred)}

\NormalTok{dokumentumok\_ws}
\CommentTok{\#\textgreater{}                            speaker   part          fit         lwr         upr}
\CommentTok{\#\textgreater{} text1          Vona Gábor (Jobbik) Jobbik {-}0.489860579 {-}0.62138707 {-}0.35833409}
\CommentTok{\#\textgreater{} text2    Dr. Schiffer András (LMP)    LMP {-}0.234609623 {-}0.39658117 {-}0.07263807}
\CommentTok{\#\textgreater{} text3     Dr. Szél Bernadett (LMP)    LMP {-}0.909048451 {-}0.93507086 {-}0.88302605}
\CommentTok{\#\textgreater{} text4         Tóbiás József (MSZP)   MSZP {-}0.296528588 {-}0.47539855 {-}0.11765863}
\CommentTok{\#\textgreater{} text5       Schmuck Erzsébet (LMP)    LMP {-}0.259074418 {-}0.44948427 {-}0.06866457}
\CommentTok{\#\textgreater{} text6     Dr. Tóth Bertalan (MSZP)   MSZP  0.006320468 {-}0.23056645  0.24320738}
\CommentTok{\#\textgreater{} text7        Volner János (Jobbik) Jobbik  0.165042014 {-}0.06144022  0.39152425}
\CommentTok{\#\textgreater{} text8          Kósa Lajos (Fidesz) Fidesz {-}0.077739857 {-}0.27645536  0.12097565}
\CommentTok{\#\textgreater{} text9         Harrach Péter (KDNP)   KDNP {-}0.123985348 {-}0.31176579  0.06379509}
\CommentTok{\#\textgreater{} text10 Dr. Gulyás Gergely (Fidesz) Fidesz  0.909048451  0.87934394  0.93875296}
\end{Highlighting}
\end{Shaded}

A lenti példánál a párton belüli bontást illusztráljuk, a
\texttt{facet\_wrap()} segítségével.

\begin{Shaded}
\begin{Highlighting}[]

\FunctionTok{ggplot}\NormalTok{(dokumentumok\_ws, }\FunctionTok{aes}\NormalTok{(fit, }\FunctionTok{reorder}\NormalTok{(speaker, fit))) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_errorbarh}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{xmin =}\NormalTok{ lwr, }\AttributeTok{xmax =}\NormalTok{ upr), }\AttributeTok{height =} \DecValTok{0}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{y =} \ConstantTok{NULL}\NormalTok{,}
    \AttributeTok{x =} \StringTok{"Wordscore"}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{part, }\AttributeTok{ncol =} \DecValTok{1}\NormalTok{, }\AttributeTok{scales =} \StringTok{"free\_y"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{_main_files/figure-latex/unnamed-chunk-156-1} \end{center}

\hypertarget{szuxf6veguxf6sszehasonluxedtuxe1s}{%
\chapter{Szövegösszehasonlítás}\label{szuxf6veguxf6sszehasonluxedtuxe1s}}

tba

\hypertarget{termuxe9szetes-nyelv-feldolgozuxe1s-nlp}{%
\chapter{Természetes-nyelv feldolgozás
(NLP)}\label{termuxe9szetes-nyelv-feldolgozuxe1s-nlp}}

tizenegyedik fejezet

\hypertarget{osztuxe1lyozuxe1s-uxe9s-feluxfcgyelt-tanuluxe1s}{%
\chapter{Osztályozás és felügyelt
tanulás}\label{osztuxe1lyozuxe1s-uxe9s-feluxfcgyelt-tanuluxe1s}}

tizenkeddik fejezet

\hypertarget{fuxfcggeluxe9k}{%
\chapter{Függelék}\label{fuxfcggeluxe9k}}

\hypertarget{az-r-uxe9s-az-rstudio-hasznuxe1lata}{%
\section{Az R és az RStudio
használata}\label{az-r-uxe9s-az-rstudio-hasznuxe1lata}}

Az R egy programozási nyelv, amely alkalmas statisztikai számítások
elvégzésére és ezek eredményeinek grafikus megjelenítésére. Az R
ingyenes, nyílt forráskódú szoftver, mely telepíthető mind Windows, mind
Linux, mind MacOS operációs rendszerek alatt, az alábbi oldalról:
\url{https://cran.r-project.org/} Az RStudio az R integrált fejlesztői
környezete (\emph{integrated development environment, IDE}), mely egy
olyan felhasználóbarát felületet biztosít, ami egyszerűbb és átláthatóbb
munkát tesz lehetővé. Az RStudio az alábbi oldalról tölthető le:
\url{https://rstudio.com/products/rstudio/download/}

A „point and click" szoftverekkel szemben az R használata során kódot
kell írni, ami bizonyos programozási jártasságot feltételez, de a
későbbiekben lehetővé teszi azt adott kutatási kérdéshez maximálisan
illeszkedő kódok összeállítását, melyek segítségével az elemzések mások
számára is megbízhatóan reprodukálhatóak lesznek. Ugyancsak az R
használata mellett szól, hogy komoly fejlesztői és felhasználói
közösséggel rendelkezik, így a használat során felmerülő problémákra
általában gyorsan megoldást találhatunk.

\hypertarget{az-rstudio-kezdux151feluxfclete}{%
\subsection{Az RStudio
kezdőfelülete}\label{az-rstudio-kezdux151feluxfclete}}

Az RStudio kezdőfelülete négy panelből, eszközsorból és menüsorból áll:

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{figures/13-01_layout} 

}

\caption{RStudio felhasználói felület}\label{fig:unnamed-chunk-158}
\end{figure}

Az \textbf{\emph{(1) editor}} ablak szolgál a kód beírására, futtatására
és mentésére. A \textbf{\emph{(2) console}} ablakban jelenik meg a
lefuttatott kód és az eredmények. A jobb felső ablak \textbf{\emph{(3)
environment}} fülén láthatóak a memóriában tárolt adatállományok,
változók és felhasználói függvények. A \textbf{\emph{history}} fül
mutatja a korábban lefuttatott utasításokat. A jobb alsó ablak
\textbf{\emph{(4) files}} fülén az aktuális munkakönyvtárban levő
mappákat és fájlok találjuk, míg a \textbf{\emph{plot}} fülön az
elemzéseink során elkészített ábrák jelennek meg. A
\textbf{\emph{packages}} fülön frissíthetjük a meglévő r csomagokat és
telepíthetünk újakat. A \textbf{\emph{help}} fülön a különböző
függvények, parancsok leírását, és használatát találjuk meg. A
\texttt{Tools\ -\textgreater{}\ Global\ Options} menüpont végezhetjük el
az RStudio testreszabását. Így például beállíthatjuk az ablaktér
elrendezését (\emph{Pane layout}), vagy a színvilágot
(\emph{Appearance}), illetve azt hogy a kódok ne fussanak ki az ablakból
(\texttt{Code\ -\textgreater{}\ Editing\ -\textgreater{}\ Soft\ wrap\ R\ source\ files})

\hypertarget{projektmunka}{%
\subsection{Projekt alapú munka}\label{projektmunka}}

Bár nem kötelező, de javasolt, hogy az RStudio-ban projekt alapon
dolgozzunk, mivel így az összes -- az adott projekttel kapcsolatos fájlt
-- egy mappában tárolhatjuk. Új projekt beállítását a
\texttt{File-\textgreater{}New\ Project} menüben tehetjük meg, ahol a
saját gépünk egy könyvtárát kell kiválasztani, ahová az R scripteket, az
adat- és előzményfájlokat menti. Ezenkívül a
\texttt{Tools-\textgreater{}Global\ Options-\textgreater{}General}
menüpont alatt le kell tiltani a \emph{„Restore most recently opened
project at startup''} és a \emph{„Restore .RData ino workspace at
startup''} beállítást, valamint \emph{„Save workspace to .RData on
exit''} értékre be kell állítani a \emph{„Never''} értéket.

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{figures/13-02_project_options} 

}

\caption{RStudio projekt beállítások}\label{fig:unnamed-chunk-159}
\end{figure}

A szükséges beállítások után a
\texttt{File\ -\textgreater{}\ New\ Project} menüben hozhatjuk létre a
projektet. Itt arra is lehetőségünk van, hogy kiválasszuk, hogy a
projektünket egy teljesen új könyvtárba, vagy egy meglévőbe kívánjuk
menteni, esetleg egy meglévő projekt új verzióját szeretnénk létrehozni.
Ha sikeresen létrehoztuk a projektet, az RStudio jobb felső sarkában
látnunk kell annak nevét.

\hypertarget{scriptek-szerkesztuxe9se-fuxfcggvuxe9nyek-hasznuxe1lata}{%
\subsection{Scriptek szerkesztése, függvények
használata}\label{scriptek-szerkesztuxe9se-fuxfcggvuxe9nyek-hasznuxe1lata}}

Új script a
\texttt{File\ -\textgreater{}\ New\ -\textgreater{}\ File\ -\textgreater{}\ R}
Script menüpontban hozható létre, mentésére a File-\textgreater Save
menüpontban egy korábbi script megnyitására
\texttt{File\ -\textgreater{}\ Open} menüpontban van lehetőségünk.
Script bármilyen szövegszerkesztővel írható és beilleszthető az editor
ablakba. A scripteket érdemes magyarázatokkal (kommentekkel) ellátni,
hogy a későbbiekben pontosan követhető legyen, hogy melyik parancs
segítségével pontosan milyen lépéseket hajtottunk végre. A
magyarázatokat vagy más néven kommenteket kettőskereszt (\texttt{\#})
karakterrel vezetjük be. A scriptbeli utasítások az azokat tartalmazó
sorokra állva vagy több sort kijelölve a Run feliratra kattintva vagy a
\texttt{Ctrl+Enter} billentyűparanccsal futtathatók le. A lefuttatott
parancsok és azok eredményei ezután a bal alsó sarokban lévő console
ablakban jelennek meg és ugyanitt kapunk hibaüzenetet is, ha valamilyen
hibát vétettünk a scriptben.

A munkafolyamat során létrehozott állományok (ábrák, fájlok) ebbe az ún.
munkakönyvtárba (\emph{working directory}) mentődnek. Az aktuális
munkakönyvtár neve, elérési útja a \texttt{getwd()} utasítással
jeleníthető meg. A könyvtárban található állományok listázására a
\texttt{list.files()} utasítással van lehetőségünk. Ha a korábbiaktól
eltérő munkakönyvtárat akarunk megadni, azt a \texttt{setwd()}
függvénnyel tehetjük meg, ahol a ()-ben az adott mappa elérési útját
kell megadnunk. Az elérési útban a meghajtó azonosítóját, majd a mappák,
almappák nevét vagy egy normál irányú perjel (\texttt{/}), vagy két
fordított perjel (\texttt{\textbackslash{}\textbackslash{}}) választja
el, mivel az elérési út karakterlánc, ezért azt idézőjelek vagy
aposztrófok közé kell tennünk. Az aktuális munkakönyvtárba beléphetünk a
jobb alsó ablak file lapján a
\texttt{„More\ -\textgreater{}\ Go\ To\ Working\ Directory”}
segítségével. Ugyanitt a \texttt{„Set\ Working\ Directory”}-val
munkakönyvtárnak állíthatjuk be az a mappát, amelyben épp benne vagyunk.

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{figures/13-03_working_directory} 

}

\caption{Working directory beállítások}\label{fig:unnamed-chunk-160}
\end{figure}

A munkafolyamat befejezésére a \texttt{q()} vagy \texttt{quit()}
függvényel van lehetőségünk. A munkafolyamat során különböző
objektumokat hozunk létre, melyek az RStudio jobb felső ablakának
environment fülén jelennek meg, a mentett objektumokat a fent látható
seprű ikonra kattintva törölhetjük a memóriából. Az environment ablakra
érdemes úgy gondolni hogy ott jelennek meg a memóriában tárolt értékek.
Az R-ben objektumokkal dolgozunk, amik a teljesség igénye nélkül
lehetnek egyszerű szám vektortok, vagy akár komplex listák, illetve
függvények, ábrák.

Az RStudio jobb alsó ablakának plots fülén láthatjuk azon parancsok
eredményét, melyek kimenete valamilyen ábra. A packages fülnél a már
telepített és a letölthető kiegészítő csomagokat jeleníthetjük meg. A
help fülön a korábban említettek szerint a súgó érhető el. Az
RStudio-ban használható billentyűparancsok teljes listáját Alt+Shift+K
billentyűkombinációval tekinthetjük meg. Néhány gyakrabban használt,
hasznos billentyűparancs:

\begin{itemize}
\tightlist
\item
  \texttt{Ctrl+Enter}: futtassa a kódot az aktuális sorban
\item
  \texttt{Ctrl+Alt+B}: futtassa a kódot az elejétől az aktuális sorig
\item
  \texttt{Ctrl+Alt+E}: futtassa a kódot az aktuális sortól a forrásfájl
  végéig
\item
  \texttt{Ctrl+D}: törölje az aktuális sort
\end{itemize}

Az R-ben beépített \textbf{függvények (function)} állnak
rendelkezésünkre a számítások végrehajtására, emellett több
\textbf{csomag (package)} is letölthető, amelyek különböző függvényeket
tartalmaznak. A függvények a következőképpen épülnek fel:
\texttt{függvénynév(paraméter)}. Például tartalom képernyőre való
kiíratását a \texttt{print()} függvénnyel tehetjük, amelynek gömbölyű
zárójelekkel határolt részébe írhatjuk a megjelenítendő szöveget. A
\texttt{citation()} függvénnyel lekérdezhetjük az egyes beépített
csomagokra való hivatkozást is: a \texttt{citation(quanteda)} függvény a
quanteda csomag hivatkozását adja meg. Az R súgórendszere a
\texttt{help.start()} utasítással indítható el. Egy adott függvényre
vonatkozó súgórészlet a függvények neve elé kérdőjel írásával, vagy a
\texttt{help()} argumentumába a kérdéses függvény nevének beírásával
jeleníthető meg (pl.: \texttt{help(sum)}).

\hypertarget{packages}{%
\subsection{R csomagok}\label{packages}}

Az R-ben telepíthetők kiegészítő csomagok (packages), amelyek
alapértelmezetten el nem érhető algoritmusokat, függvényeket
tartalmaznak. A csomagok saját dokumentációval rendelkeznek, amelyeket
fel kell tüntetni a használatukkal készült publikációink
hivatkozáslistájában. A csomagok telepítésre több lehetőségünk is van:
használhatjuk a menüsor
\texttt{Tools\ -\textgreater{}\ Install\ Packages} menüpontját, vagy a
jobb alsó ablak \emph{Packages} fül Install menüpontját, illetve az
editor ablakban az \texttt{install.packages()} parancsot futtatva, ahol
a ()-be a telepíteni kívánt csomag nevét kell beírnunk (pl.:
\texttt{install.packages(dplyr)}).

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{figures/13-04_packages} 

}

\caption{Packages fül}\label{fig:unnamed-chunk-161}
\end{figure}

\hypertarget{objektumok-tuxe1roluxe1sa-uxe9rtuxe9kaduxe1s}{%
\subsection{Objektumok tárolása,
értékadás}\label{objektumok-tuxe1roluxe1sa-uxe9rtuxe9kaduxe1s}}

Az objektumok lehetnek például \emph{vektorok}, \emph{mátrixok}
(matrix), \emph{tömbök} (array), \emph{adat táblák} (data frame).
Értékadás nélkül az R csak megjeleníti a műveletek eredményét, de nem
tárolja el azokat. Az eredmények eltárolásához azokat egy objektumba
kell elmentenünk. Ehhez meg kell adnunk az objektum nevét majd az
\texttt{\textless{}-} után adjuk meg annak értékét:
\texttt{a\ \textless{}-\ 12\ +\ 3}.Futtatás után az environments fülön
megjelenik az a objektum, melynek értéke \texttt{15}. Az objektumok
elnevezésénél figyelnünk kell arra, hogy az R különbséget tesz a kis és
nagybetűk között, valamint, hogy az ugyanolyan nevű objektumokat kérdés
nélkül felülírja és ezt a felülírást nem lehet visszavonni.

\hypertarget{vektorok}{%
\subsection{Vektorok}\label{vektorok}}

Az R-ben kétféle típusú vektort különböztetünk meg:

\begin{itemize}
\tightlist
\item
  egyedüli vektor (atomic vector)
\item
  lista (list)
\end{itemize}

Az egyedüli vektornak hat típusa van, \textbf{logikai} (logical),
\textbf{egész szám} (integer), \textbf{természetes szám} (double),
\textbf{karakter} (character), \textbf{komplex szám} (complex) és
\textbf{nyers adat} (raw). A leggyakrabban valamilyen numerikus, logikai
vagy karakter vektorral használjuk. Az egyedüli vektorok onnan kapták a
nevüket hogy csak egy féle adattípust tudnak tárolni. A listák ezzel
szemben gyakorlatilag bármit tudnak tárolni, akár több listát is
egybeágyazhatunk.

A vektorok és listák azok az építőelemek amikből felépülnek az R
objektumaink. Több érték vagy azonos típusú objektum összefűzését a
\texttt{c()} függvénnyel végezhetjük el. A lenti példában három
különböző objektumot kreálunk, egy numerikusat, egy karaktert és egy
logikait. A karakter vektorban az elemeket időzőjellel és vesszővel
szeparáljuk. A logikai vektor csak \texttt{TRUE}, illetve \texttt{FALSE}
értékeket tartalmazhat.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{numerikus }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{5}\NormalTok{)}

\NormalTok{karakter }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"kutya"}\NormalTok{,}\StringTok{"macska"}\NormalTok{,}\StringTok{"ló"}\NormalTok{)}

\NormalTok{logikai }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\ConstantTok{TRUE}\NormalTok{, }\ConstantTok{TRUE}\NormalTok{, }\ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

A létrehozott vektorokkal különböző műveleteket végezhetünk el, például
összeadhatjuk numerikus vektorainkat. Ebben az esetben az első vektor
első eleme a második vektor első eleméhez adódik.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{c}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{4}\NormalTok{) }\SpecialCharTok{+} \FunctionTok{c}\NormalTok{(}\DecValTok{10}\NormalTok{,}\DecValTok{20}\NormalTok{,}\DecValTok{30}\NormalTok{,}\DecValTok{40}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 11 22 33 44}
\end{Highlighting}
\end{Shaded}

A karaktervektorokat összefűzhetjük egymással. Itt egy új objektumot is
létrehoztunk, a jobb felső ablakban, az environment fülön láthatjuk,
hogy a létrejött karakter\_kombinalt objektum egy négy elemű
(hosszúságú) karaktervektor (\texttt{chr\ {[}1:4{]}}), melynek elemei a
\texttt{"kutya","macska","ló","nyúl"}. Az objektumként tárolt vektorok
tartalmát a lefuttatva írathatjuk ki a console ablakba. Habár van
\texttt{print()} függvény az R-ben, azt ilyenkor nem szükséges
használni.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{karakter1 }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"kutya"}\NormalTok{,}\StringTok{"macska"}\NormalTok{,}\StringTok{"ló"}\NormalTok{)}
\NormalTok{karakter2 }\OtherTok{\textless{}{-}}\FunctionTok{c}\NormalTok{(}\StringTok{"nyúl"}\NormalTok{)}

\NormalTok{karakter\_kombinalt }\OtherTok{\textless{}{-}}\FunctionTok{c}\NormalTok{(karakter1, karakter2)}

\NormalTok{karakter\_kombinalt}
\CommentTok{\#\textgreater{} [1] "kutya"  "macska" "ló"     "nyúl"}
\end{Highlighting}
\end{Shaded}

Ha egy vektorról szeretnénk megtudni, hogy milyen típusú azt a
\texttt{typeof()} vagy a \texttt{class()} paranccsal tehetjük meg, ahol
()-ben az adott objektumként tárolt vektor nevét kell megadnunk:
\texttt{typeof(karakter1)}. A vektor hosszúságát (benne tárolt elemek
száma vektorok esetén) a \texttt{lenght()} függvénnyel tudhatjuk meg.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{typeof}\NormalTok{(karakter1)}
\CommentTok{\#\textgreater{} [1] "character"}

\FunctionTok{length}\NormalTok{(karakter1)}
\CommentTok{\#\textgreater{} [1] 3}
\end{Highlighting}
\end{Shaded}

\hypertarget{faktorok}{%
\subsection{Faktorok}\label{faktorok}}

A faktorok a kategórikus adatok tárolására szolgálnak. Faktor típusú
változó a \texttt{factor()} függvénnyel hozható létre. A faktor
szintjeit (igen, semleges, nem), a \texttt{levels()} függvénnyel
kaphatjuk meg míg az adatok címkéit (tehát a kapott válaszok száma), a
\texttt{labels()} paranccsal érhetjük el.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{survey\_response }\OtherTok{\textless{}{-}} \FunctionTok{factor}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"igen"}\NormalTok{, }\StringTok{"semleges"}\NormalTok{, }\StringTok{"nem"}\NormalTok{, }\StringTok{"semleges"}\NormalTok{, }\StringTok{"nem"}\NormalTok{, }\StringTok{"nem"}\NormalTok{, }\StringTok{"igen"}\NormalTok{), }\AttributeTok{ordered =} \ConstantTok{TRUE}\NormalTok{)}


\FunctionTok{levels}\NormalTok{(survey\_response)}
\CommentTok{\#\textgreater{} [1] "igen"     "nem"      "semleges"}

\FunctionTok{labels}\NormalTok{(survey\_response)}
\CommentTok{\#\textgreater{} [1] "1" "2" "3" "4" "5" "6" "7"}
\end{Highlighting}
\end{Shaded}

\hypertarget{data-frame}{%
\subsection{Data frame}\label{data-frame}}

Az adat táblák (data frame) a statisztikai és adatelemzési folyamatok
egyik leggyakrabban használt adattárolási formája. Amikor lehetséges
akkor a `hosszú' formátumban használjuk (az R közösség a `tidy' jelzővel
illeti), aholtéglalap alakú adatszerkezetek, ahol minden sor egy
megfigyelés és minden oszlop egy változó {[}TIDY CITATION{]}. Egy data
frame többféle típusú adatot tartalmazhat. A data frame-k különféle
oszlopokból állhatnak, amelyek különféle típusú adatokat
tartalmazhatnak, de egy oszlop csak egy típusú adatból állhat. A lent
bemutatott data frame 7 megfigyelést és 4 féle változót tartalmaz (id,
country, pop, continent).

\begin{verbatim}
#>   id      orszag nepesseg     kontinens
#> 1  1    Thailand     68.7          Asia
#> 2  2      Norway      5.2        Europe
#> 3  3 North Korea     24.0          Asia
#> 4  4      Canada     47.8 North America
#> 5  5    Slovenia      2.0        Europe
#> 6  6      France     63.6        Europe
#> 7  7   Venezuela     31.6 South America
\end{verbatim}

A data frame-be rendezett adatokhoz különböző módon férhetünk hozzá,
például a data frame nevének majd {[}{]}-ben a kívánt sor megadásával,
kiírathatjuk a console ablakba annak tetszőleges sorát ás oszlopát:
\texttt{orszag\_adatok{[}1,\ 1{]}}. Az R több különböző módot kínál a
data frame sorainak és oszlopainak eléréséhez. A \texttt{{[}} általános
használata: \texttt{data\_frame{[}sor,\ oszlop{]}}. Egy másik megoldás a
\texttt{\$} haszálata: \texttt{data\_frame\$oszlop}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{orszag\_adatok[}\DecValTok{1}\NormalTok{, }\DecValTok{4}\NormalTok{]}
\CommentTok{\#\textgreater{} [1] Asia}
\CommentTok{\#\textgreater{} Levels: Asia Europe North America South America}

\NormalTok{orszag\_adatok}\SpecialCharTok{$}\NormalTok{orszag}
\CommentTok{\#\textgreater{} [1] "Thailand"    "Norway"      "North Korea" "Canada"      "Slovenia"   }
\CommentTok{\#\textgreater{} [6] "France"      "Venezuela"}
\end{Highlighting}
\end{Shaded}

\hypertarget{vizualizuxe1ciuxf3}{%
\section{Vizualizáció}\label{vizualizuxe1ciuxf3}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(ggplot2)}
\FunctionTok{library}\NormalTok{(gapminder)}
\end{Highlighting}
\end{Shaded}

Az elemzéseinkhez használt data frame adatainak alapján a
\texttt{ggplot2} csomag segítségével lehetőségünk van különböző
vizualizációk készítésére is.

A \texttt{ggplot2} használata során különböző témákat alkalmazhatunk,
melyek részletes leírása megtalálható:
\url{https://ggplot2.tidyverse.org/reference/ggtheme.html}

Abban az esetben, ha nem választunk témát, a \texttt{ggplot2} a
következő ábrán is látható alaptémát használja. Ha például a szürke
helyett fehér hátteret szeretnénk, alkalmazhatjuk a
\texttt{theme\_minmal()}parancsot. Szintén gyakran alkalmazott ábra alap
a \texttt{thema\_bw()}, ami az előzőtől az ábra keretezésében
különbözik. Ha fehér alapon, de a beosztások vonalait feketén szeretnénk
megjeleníteni, alkalmazhatjuk a \texttt{theme\_linedraw()} függvényt, a
\texttt{theme\_void()} segítségével pedig egy fehér alapon,
beosztásoktól mentes alapot kapunk, a \texttt{theme\_dark()} pedig sötét
hátteret eredményez. A \texttt{theme\_classic()} segítségével az x és y
tengelyt jeleníthetjük meg fehér alapon.

Egy ábra készítésének alapja mindig a használni kívánt adatkészlet
beolvasása, illetve az ábrázolni kiíván változtót vagy változók
megadása.

Ezt követi a megfelelő alakzat kiválasztása, attól függően például, hogy
eloszlást, változást, adatok közötti kapcsolatot, vagy elétéseket
akarunk ábrázolni. A \texttt{geom} az a geometriai objektum, a mit a
diagram az adatok megjelenítésére használ. A\texttt{gglpot2} több mint
40 féle alakzat alkalmazására ad lehetőséget, ezek közül néhány
gyakoribbat mutatunk be az alábbiakban. Az alakzatokról részletes
leírása található például az alábbi linken:
\url{https://r4ds.had.co.nz/data-visualisation.html}

A következőkben a már korábban is használt \texttt{gapminder} adatok
segítségével, személetetjük az adatok vizualizálásának alapjait. Először
egyszerű alapbeállítások mellett egy histogram típusú vizualizációt
készítünk.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}
  \AttributeTok{data =}\NormalTok{ gapminder, }
  \AttributeTok{mapping =} \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ gdpPercap)}
\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{geom\_histogram}\NormalTok{() }
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{_main_files/figure-latex/unnamed-chunk-171-1} \end{center}

Lehetőségünk van arra, hogy az alakzat színét megváltoztatássuk. A
használható színek és színkódok megtalálhatóak a \texttt{ggplot2}
leírásában: \url{https://ggplot2-book.org/scale-colour.html}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}
  \AttributeTok{data =}\NormalTok{ gapminder,}
  \AttributeTok{mapping =} \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ gdpPercap)}
\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{fill =} \StringTok{"yellow"}\NormalTok{, }\AttributeTok{colour =} \StringTok{"green"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{_main_files/figure-latex/unnamed-chunk-172-1} \end{center}

Meghatározhatjuk külön-külön a histogram x és y tengelyén ábrázolni
kívánt adatokat és választhatjuk azok pontszerű ábrázolását is.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}
  \AttributeTok{data =}\NormalTok{ gapminder,}
  \AttributeTok{mapping =} \FunctionTok{aes}\NormalTok{(}
    \AttributeTok{x =}\NormalTok{ gdpPercap,}
    \AttributeTok{y =}\NormalTok{ lifeExp}
\NormalTok{  )}
\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{_main_files/figure-latex/unnamed-chunk-173-1} \end{center}

Ahogy az előzőekben, itt is megváltoztathatjuk az ábra színét.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}
  \AttributeTok{data =}\NormalTok{ gapminder,}
  \AttributeTok{mapping =} \FunctionTok{aes}\NormalTok{(}
    \AttributeTok{x =}\NormalTok{ gdpPercap,}
    \AttributeTok{y =}\NormalTok{ lifeExp}
\NormalTok{  )}
\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{colour =} \StringTok{"blue"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{_main_files/figure-latex/unnamed-chunk-174-1} \end{center}

Az fenti script kibővítésével az egyes kontinensek adatait különböző
színnel ábrázolhatjuk, az x és y tengelyt elnevezhetjük, a histogramnak
címet és alcímet adhatunk, illetve az adataink forrását is
feltüntethetjük az alábbi módon:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}
  \AttributeTok{data =}\NormalTok{ gapminder,}
  \AttributeTok{mapping =} \FunctionTok{aes}\NormalTok{(}
    \AttributeTok{x =}\NormalTok{ gdpPercap,}
    \AttributeTok{y =}\NormalTok{ lifeExp,}
    \AttributeTok{color =}\NormalTok{ continent}
\NormalTok{  )}
\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{x =} \StringTok{"GDP per capita (log $)"}\NormalTok{, }
    \AttributeTok{y =} \StringTok{"Life expectancy"}\NormalTok{,}
    \AttributeTok{title =} \StringTok{"Connection between GDP and Life expectancy"}\NormalTok{,}
    \AttributeTok{subtitle =} \StringTok{"Points are country{-}years"}\NormalTok{,}
    \AttributeTok{caption =} \StringTok{"Source: Gapminder dataset"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{_main_files/figure-latex/unnamed-chunk-175-1} \end{center}

Az ábrán található feliratok méretének, betűtípusának és betűszínének
megválasztásra is lehetőségünk van.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}
  \AttributeTok{data =}\NormalTok{ gapminder,}
  \AttributeTok{mapping =} \FunctionTok{aes}\NormalTok{(}
    \AttributeTok{x =}\NormalTok{ gdpPercap,}
    \AttributeTok{y =}\NormalTok{ lifeExp,}
    \AttributeTok{color =}\NormalTok{ continent}
\NormalTok{  )}
\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{x =} \StringTok{"GDP per capita (log $)"}\NormalTok{, }
    \AttributeTok{y =} \StringTok{"Life expectancy"}\NormalTok{,}
    \AttributeTok{title =} \StringTok{"Connection between GDP and Life expectancy"}\NormalTok{,}
    \AttributeTok{subtitle =} \StringTok{"Points are country{-}years"}\NormalTok{,}
    \AttributeTok{caption =} \StringTok{"Source: Gapminder dataset"}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{plot.title =} \FunctionTok{element\_text}\NormalTok{(}
    \AttributeTok{size =} \DecValTok{12}\NormalTok{, }
    \AttributeTok{colour =} \StringTok{"red"}
\NormalTok{  ))}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{_main_files/figure-latex/unnamed-chunk-176-1} \end{center}

Készíthetünk oszlopdiagramot is, amit a \texttt{ggplot2} diamonds
adatkészletén személtetünk

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ diamonds) }\SpecialCharTok{+}
  \FunctionTok{geom\_bar}\NormalTok{(}\AttributeTok{mapping =} \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ cut))}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{_main_files/figure-latex/unnamed-chunk-177-1} \end{center}

Itt is lehetőségünk van arra, hogy a diagram színét megváltoztassuk.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ diamonds) }\SpecialCharTok{+}
  \FunctionTok{geom\_bar}\NormalTok{(}\AttributeTok{mapping =} \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ cut), }\AttributeTok{fill =} \StringTok{"darkgreen"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{_main_files/figure-latex/unnamed-chunk-178-1} \end{center}

De arra is lehetőségünk van, hogy az egyes oszlopok eltérő színűek
legyenek.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ diamonds) }\SpecialCharTok{+}
  \FunctionTok{geom\_bar}\NormalTok{(}\AttributeTok{mapping =} \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ cut, }\AttributeTok{fill =}\NormalTok{ cut))}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{_main_files/figure-latex/unnamed-chunk-179-1} \end{center}

Arra is van lehetőségünk, hogy egyszerre több változót is ábrázoljunk.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ diamonds) }\SpecialCharTok{+}
  \FunctionTok{geom\_bar}\NormalTok{(}\AttributeTok{mapping =} \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ cut, }\AttributeTok{fill =}\NormalTok{ clarity))}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{_main_files/figure-latex/unnamed-chunk-180-1} \end{center}

Arra ggplot2 segítségével arra is lehetőségünk van, hogy csv-ből
beolvasott adatainkat vizualizáljuk.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plot\_cap\_1 }\OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{"data/plot\_cap\_1.csv"}\NormalTok{, }\AttributeTok{head =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{sep =} \StringTok{";"}\NormalTok{) }
\FunctionTok{ggplot}\NormalTok{(plot\_cap\_1, }\FunctionTok{aes}\NormalTok{(Year, }\AttributeTok{fill =}\NormalTok{ Subtopic)) }\SpecialCharTok{+} 
  \FunctionTok{scale\_x\_discrete}\NormalTok{(}\AttributeTok{limits =} \FunctionTok{c}\NormalTok{(}\DecValTok{1957}\NormalTok{, }\DecValTok{1958}\NormalTok{, }\DecValTok{1959}\NormalTok{, }\DecValTok{1960}\NormalTok{, }\DecValTok{1961}\NormalTok{, }\DecValTok{1962}\NormalTok{, }\DecValTok{1963}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{geom\_bar}\NormalTok{(}\AttributeTok{position =} \StringTok{"dodge"}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{x =} \ConstantTok{NULL}\NormalTok{, }\AttributeTok{y =} \ConstantTok{NULL}\NormalTok{, }
    \AttributeTok{title =} \StringTok{"A Magyar Közlönyben kihirdetett agrárpolitikai jogszabályok"}\NormalTok{, }
    \AttributeTok{subtitle =} \StringTok{"N=445"}
\NormalTok{  ) }\SpecialCharTok{+} 
  \FunctionTok{coord\_flip}\NormalTok{() }\SpecialCharTok{+} \CommentTok{\# az ábra tipusa}
  \FunctionTok{theme\_minimal}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{plot.title =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{size =} \DecValTok{12}\NormalTok{)) }
\end{Highlighting}
\end{Shaded}

A csv-ből belolvasott adatainkból kördiagramot is készíthetünk

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pie }\OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{"data/pie.csv"}\NormalTok{, }\AttributeTok{head =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{sep =} \StringTok{";"}\NormalTok{)}

\FunctionTok{ggplot}\NormalTok{(pie, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =} \StringTok{""}\NormalTok{, }\AttributeTok{y =}\NormalTok{ value, }\AttributeTok{fill =}\NormalTok{ Type)) }\SpecialCharTok{+}
  \FunctionTok{geom\_bar}\NormalTok{(}\AttributeTok{stat =} \StringTok{"identity"}\NormalTok{, }\AttributeTok{width =} \DecValTok{1}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{coord\_polar}\NormalTok{(}\StringTok{"y"}\NormalTok{, }\AttributeTok{start =} \DecValTok{0}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_fill\_brewer}\NormalTok{(}\AttributeTok{palette =} \StringTok{"GnBu"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{title =} \StringTok{"A Magyar Közlönyben megjelent jogszabályok típusai"}\NormalTok{,}
    \AttributeTok{subtitle =} \StringTok{"N = 445"}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{theme\_void}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\hypertarget{refs}{}
\begin{CSLReferences}{1}{0}
\leavevmode\hypertarget{ref-arun2010finding}{}%
Arun, Rajkumar, Venkatasubramaniyan Suresh, CE Veni Madhavan, and MN
Narasimha Murthy. 2010. {``On Finding the Natural Number of Topics with
Latent Dirichlet Allocation: Some Observations.''} In, 391402.

\leavevmode\hypertarget{ref-blei2003}{}%
Blei, David M, Andrew Y Ng, and Michael I Jordan. 2003. {``Latent
Dirichlet Allocation.''} \emph{Journal of Machine Learning Research} 3
(Jan): 993--1022.

\leavevmode\hypertarget{ref-burtejin2016}{}%
Burtejin, Zorgit. 2016. {``Csoportosítás (Klaszterezés).''} In, edited
by Miklós Sebők, 85--101. Budapest: L'Harmattan.

\leavevmode\hypertarget{ref-cao2009density}{}%
Cao, Juan, Tian Xia, Jintao Li, Yongdong Zhang, and Sheng Tang. 2009.
{``A Density-Based Method for Adaptive LDA Model Selection.''}
\emph{Neurocomputing} 72 (7-9): 17751781.

\leavevmode\hypertarget{ref-deveaud2014accurate}{}%
Deveaud, Romain, Eric SanJuan, and Patrice Bellot. 2014. {``Accurate and
Effective Latent Concept Modeling for Ad Hoc Information Retrieval.''}
\emph{Document Numérique} 17 (1): 6184.

\leavevmode\hypertarget{ref-griffiths2004}{}%
Griffiths, T. L., and M. Steyvers. 2004. {``Finding Scientific
Topics.''} \emph{Proceedings of the National Academy of Sciences} 101
(Supplement 1): 5228--35. \url{https://doi.org/10.1073/pnas.0307752101}.

\leavevmode\hypertarget{ref-grimmer2013text}{}%
Grimmer, Justin, and Brandon M Stewart. 2013a. {``Text as Data: The
Promise and Pitfalls of Automatic Content Analysis Methods for Political
Texts.''} \emph{Political Analysis} 21 (3): 267297.

\leavevmode\hypertarget{ref-grimmer2013texta}{}%
---------. 2013b. {``Text as Data: The Promise and Pitfalls of Automatic
Content Analysis Methods for Political Texts.''} \emph{Political
Analysis} 21 (3): 267297.

\leavevmode\hypertarget{ref-jacobi2016a}{}%
Jacobi, Carina, Wouter Van Atteveldt, and Kasper Welbers. 2016.
{``Quantitative Analysis of Large Amounts of Journalistic Texts Using
Topic Modelling.''} \emph{Digital Journalism} 4 (1): 89--106.

\leavevmode\hypertarget{ref-laver2003extracting}{}%
Laver, Michael, Kenneth Benoit, and John Garry. 2003. {``Extracting
Policy Positions from Political Texts Using Words as Data.''}
\emph{American Political Science Review}, 311331.

\leavevmode\hypertarget{ref-laver2000estimating}{}%
Laver, Michael, and John Garry. 2000. {``Estimating Policy Positions
from Political Texts.''} \emph{American Journal of Political Science},
619634.

\leavevmode\hypertarget{ref-loughran2011}{}%
Loughran, Tim, and Bill McDonald. 2011. {``When Is a Liability Not a
Liability? Textual Analysis, Dictionaries, and 10-Ks.''} \emph{The
Journal of Finance} 66 (1): 35--65.

\leavevmode\hypertarget{ref-muxe1tuxe92021}{}%
Máté, Ákos, Miklós Sebők, and Tamás Barczikay. 2021. {``The Effect of
Central Bank Communication on Sovereign Bond Yields: The Case of
Hungary.''} Edited by Hiranya K. Nath. \emph{PLOS ONE} 16 (2): e0245515.
\url{https://doi.org/10.1371/journal.pone.0245515}.

\leavevmode\hypertarget{ref-mikolov2013efficient}{}%
Mikolov, Tomas, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013.
{``Efficient Estimation of Word Representations in Vector Space.''}
\emph{arXiv Preprint arXiv:1301.3781}.

\leavevmode\hypertarget{ref-mikolov2018advances}{}%
Mikolov, Tomas, Edouard Grave, Piotr Bojanowski, Christian Puhrsch, and
Armand Joulin. 2018. {``Advances in Pre-Training Distributed Word
Representations.''} In.

\leavevmode\hypertarget{ref-pennington2014glove}{}%
Pennington, Jeffrey, Richard Socher, and Christopher D Manning. 2014.
{``Glove: Global Vectors for Word Representation.''} In, 15321543.

\leavevmode\hypertarget{ref-roberts2014structural}{}%
Roberts, Margaret E, Brandon M Stewart, Dustin Tingley, Christopher
Lucas, Jetson Leder-Luis, Shana Kushner Gadarian, Bethany Albertson, and
David G Rand. 2014. {``Structural Topic Models for Open-Ended Survey
Responses.''} \emph{American Journal of Political Science} 58 (4):
10641082.

\leavevmode\hypertarget{ref-silge2017text}{}%
Silge, Julia, and David Robinson. 2017. \emph{Text Mining with r: A Tidy
Approach}. {"} O'Reilly Media, Inc.{"}.

\leavevmode\hypertarget{ref-spirlingword}{}%
Spirling, Arthur, and Pedro L Rodriguez. n.d.a. {``Word Embeddings.''}
\url{https://polmeth.mit.edu/sites/default/files/documents/Pedro_Rodriguez.pdf}.

\leavevmode\hypertarget{ref-spirlingworda}{}%
---------. n.d.b. {``Word Embeddings.''}
\url{https://polmeth.mit.edu/sites/default/files/documents/Pedro_Rodriguez.pdf}.

\leavevmode\hypertarget{ref-tan2011a}{}%
Tan, Pang-Ning, Michael Steinbach, and Vipin Kumar. 2011.
\emph{Bevezetés Az Adatbányászatba}. Panem Kft.

\leavevmode\hypertarget{ref-tikk2007}{}%
Tikk, Domonkos. 2007a. \emph{Szövegbányászat}. Budapest: Typotext.

\leavevmode\hypertarget{ref-tikk2007a}{}%
---------. 2007b. \emph{Szövegbányászat}. Budapest: Typotext.

\leavevmode\hypertarget{ref-wickham2016r}{}%
Wickham, Hadley, and Garrett Grolemund. 2016. \emph{R for Data Science:
Import, Tidy, Transform, Visualize, and Model Data}. {"} O'Reilly Media,
Inc.{"}.

\leavevmode\hypertarget{ref-young2012affective}{}%
Young, Lori, and Stuart Soroka. 2012. {``Affective News: The Automated
Coding of Sentiment in Political Texts.''} \emph{Political
Communication} 29 (2): 205231.

\end{CSLReferences}

\backmatter
\end{document}
